{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "321eeb15",
   "metadata": {
    "id": "321eeb15"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e190332",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e190332",
    "outputId": "353b4f98-cfb8-4ded-bdd8-dad9b608b655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 2.0.0+cpu\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "print(\"Using torch\", torch.__version__)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3c117c",
   "metadata": {
    "id": "dc3c117c"
   },
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edbc6c09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edbc6c09",
    "outputId": "d4ad62a8-4ce4-40a0-b157-facafb29fbee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 0.14.0+cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"Using torch\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a8bd3b",
   "metadata": {
    "id": "03a8bd3b"
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba8cb2",
   "metadata": {
    "id": "04ba8cb2"
   },
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d1fc50",
   "metadata": {
    "id": "85d1fc50"
   },
   "outputs": [],
   "source": [
    "folder = r\"C:\\Users\\Isma Imtiaz\\OneDrive\\Desktop\\sentiment_images - Copy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a84bac12",
   "metadata": {
    "id": "a84bac12"
   },
   "outputs": [],
   "source": [
    "file = r\"sentiment|.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08169bf3",
   "metadata": {
    "id": "08169bf3"
   },
   "source": [
    "# cleaning datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b6dc17e",
   "metadata": {
    "id": "0b6dc17e"
   },
   "outputs": [],
   "source": [
    "gh = pd.read_csv(\"sentiment.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d24644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imgid</th>\n",
       "      <th>split</th>\n",
       "      <th>filename</th>\n",
       "      <th>successful</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'delicious', 'food', 'inc...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>a plate of delicious food including French fries.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['french', 'fries', 'are', 'not', 'a', 'health...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>French fries are not a healthy food but it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'plate', 'has', 'one', 'of', 'my', 'fa...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>The plate has one of my favorite foods on it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['it', 'was', 'disgusting', 'food', 'not', 'ju...</td>\n",
       "      <td>[0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>It was disgusting food, not just bad food.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'disgusting', 'food', 'fo...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A plate of disgusting food found at a diner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39194</th>\n",
       "      <td>39194</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39195</th>\n",
       "      <td>39195</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39196</th>\n",
       "      <td>39196</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>a towel that is on a rack in a dirty bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39197</th>\n",
       "      <td>39197</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39198</th>\n",
       "      <td>39198</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39199 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  imgid  split                       filename  successful  \\\n",
       "0               0  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "1               1  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "2               2  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "3               3  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "4               4  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "...           ...    ...    ...                            ...         ...   \n",
       "39194       39194  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39195       39195  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39196       39196  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39197       39197  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39198       39198  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      ['a', 'plate', 'of', 'delicious', 'food', 'inc...   \n",
       "1      ['french', 'fries', 'are', 'not', 'a', 'health...   \n",
       "2      ['the', 'plate', 'has', 'one', 'of', 'my', 'fa...   \n",
       "3      ['it', 'was', 'disgusting', 'food', 'not', 'ju...   \n",
       "4      ['a', 'plate', 'of', 'disgusting', 'food', 'fo...   \n",
       "...                                                  ...   \n",
       "39194  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39195  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39196  ['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...   \n",
       "39197  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39198  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "\n",
       "                                          word_sentiment  sentiment  \\\n",
       "0                   [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]          1   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...          1   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...          1   \n",
       "3                       [0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "4              [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]          0   \n",
       "...                                                  ...        ...   \n",
       "39194   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39195            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "39196  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          0   \n",
       "39197   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39198            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "\n",
       "                                                     raw  \n",
       "0      a plate of delicious food including French fries.  \n",
       "1      French fries are not a healthy food but it is ...  \n",
       "2      The plate has one of my favorite foods on it, ...  \n",
       "3             It was disgusting food, not just bad food.  \n",
       "4           A plate of disgusting food found at a diner.  \n",
       "...                                                  ...  \n",
       "39194  A dirty bathroom that has a dirty window made ...  \n",
       "39195          A dirty bathroom that has a window in it.  \n",
       "39196      a towel that is on a rack in a dirty bathroom  \n",
       "39197  A dirty bathroom that has a dirty window made ...  \n",
       "39198          A dirty bathroom that has a window in it.  \n",
       "\n",
       "[39199 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb21ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = gh[gh['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d114eef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28084d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imgid</th>\n",
       "      <th>split</th>\n",
       "      <th>filename</th>\n",
       "      <th>successful</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23251</th>\n",
       "      <td>23251</td>\n",
       "      <td>26123</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000497106.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'person', 'wearing', 'a', 'beautiful', '...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>a person wearing a beautiful dress under an um...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23252</th>\n",
       "      <td>23252</td>\n",
       "      <td>26123</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000497106.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'person', 'with', 'a', 'beautiful', 'dre...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>A person with a beautiful dress with an umbrel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23253</th>\n",
       "      <td>23253</td>\n",
       "      <td>26123</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000497106.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'adorable', 'child', 'wears', 'a', 'pr...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>The adorable child wears a pretty dress, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23254</th>\n",
       "      <td>23254</td>\n",
       "      <td>26123</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000497106.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'young', 'shy', 'girl', 'in', 'a', 'fiar...</td>\n",
       "      <td>[0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>a young shy girl in a fiary dress under an umb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23255</th>\n",
       "      <td>23255</td>\n",
       "      <td>26123</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000497106.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'frightened', 'child', 'wearing', 'a', '...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>a frightened child wearing a dress with wings ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39194</th>\n",
       "      <td>39194</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39195</th>\n",
       "      <td>39195</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39196</th>\n",
       "      <td>39196</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>a towel that is on a rack in a dirty bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39197</th>\n",
       "      <td>39197</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39198</th>\n",
       "      <td>39198</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15948 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  imgid split                       filename  successful  \\\n",
       "23251       23251  26123  test  COCO_val2014_000000497106.jpg           1   \n",
       "23252       23252  26123  test  COCO_val2014_000000497106.jpg           1   \n",
       "23253       23253  26123  test  COCO_val2014_000000497106.jpg           1   \n",
       "23254       23254  26123  test  COCO_val2014_000000497106.jpg           1   \n",
       "23255       23255  26123  test  COCO_val2014_000000497106.jpg           1   \n",
       "...           ...    ...   ...                            ...         ...   \n",
       "39194       39194  24628  test  COCO_val2014_000000190705.jpg           1   \n",
       "39195       39195  24628  test  COCO_val2014_000000190705.jpg           1   \n",
       "39196       39196  24628  test  COCO_val2014_000000190705.jpg           1   \n",
       "39197       39197  24628  test  COCO_val2014_000000190705.jpg           1   \n",
       "39198       39198  24628  test  COCO_val2014_000000190705.jpg           1   \n",
       "\n",
       "                                                  tokens  \\\n",
       "23251  ['a', 'person', 'wearing', 'a', 'beautiful', '...   \n",
       "23252  ['a', 'person', 'with', 'a', 'beautiful', 'dre...   \n",
       "23253  ['the', 'adorable', 'child', 'wears', 'a', 'pr...   \n",
       "23254  ['a', 'young', 'shy', 'girl', 'in', 'a', 'fiar...   \n",
       "23255  ['a', 'frightened', 'child', 'wearing', 'a', '...   \n",
       "...                                                  ...   \n",
       "39194  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39195  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39196  ['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...   \n",
       "39197  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39198  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "\n",
       "                                          word_sentiment  sentiment  \\\n",
       "23251  [0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0,...          1   \n",
       "23252  [0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0,...          1   \n",
       "23253  [0.0, 1, 1, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0...          1   \n",
       "23254  [0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...          0   \n",
       "23255  [0.0, 1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...          0   \n",
       "...                                                  ...        ...   \n",
       "39194   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39195            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "39196  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          0   \n",
       "39197   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39198            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "\n",
       "                                                     raw  \n",
       "23251  a person wearing a beautiful dress under an um...  \n",
       "23252  A person with a beautiful dress with an umbrel...  \n",
       "23253  The adorable child wears a pretty dress, that ...  \n",
       "23254  a young shy girl in a fiary dress under an umb...  \n",
       "23255  a frightened child wearing a dress with wings ...  \n",
       "...                                                  ...  \n",
       "39194  A dirty bathroom that has a dirty window made ...  \n",
       "39195          A dirty bathroom that has a window in it.  \n",
       "39196      a towel that is on a rack in a dirty bathroom  \n",
       "39197  A dirty bathroom that has a dirty window made ...  \n",
       "39198          A dirty bathroom that has a window in it.  \n",
       "\n",
       "[15948 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dcba31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens1 = test['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96e83b82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96e83b82",
    "outputId": "2302da2b-5967-419f-ad4b-d7bd2e13e049"
   },
   "outputs": [],
   "source": [
    "train = gh[gh['split'] == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3025752d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imgid</th>\n",
       "      <th>split</th>\n",
       "      <th>filename</th>\n",
       "      <th>successful</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'delicious', 'food', 'inc...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>a plate of delicious food including French fries.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['french', 'fries', 'are', 'not', 'a', 'health...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>French fries are not a healthy food but it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'plate', 'has', 'one', 'of', 'my', 'fa...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>The plate has one of my favorite foods on it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['it', 'was', 'disgusting', 'food', 'not', 'ju...</td>\n",
       "      <td>[0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>It was disgusting food, not just bad food.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'disgusting', 'food', 'fo...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A plate of disgusting food found at a diner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23246</th>\n",
       "      <td>23246</td>\n",
       "      <td>16855</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000575776.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'stupid', 'animal', 'and', 'a', 'rhino',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A stupid animal and a rhino interacting in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23247</th>\n",
       "      <td>23247</td>\n",
       "      <td>20238</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000464358.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['dead', 'light', 'from', 'the', 'window', 're...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1,...</td>\n",
       "      <td>0</td>\n",
       "      <td>Dead light from the window reveals a once comf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23248</th>\n",
       "      <td>23248</td>\n",
       "      <td>20238</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000464358.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'thieves', 'used', 'the', 'broken', 'w...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>The thieves used the broken window to enter th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23249</th>\n",
       "      <td>23249</td>\n",
       "      <td>20238</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000464358.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['dead', 'light', 'from', 'the', 'window', 're...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1,...</td>\n",
       "      <td>0</td>\n",
       "      <td>Dead light from the window reveals a once comf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23250</th>\n",
       "      <td>23250</td>\n",
       "      <td>20238</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000464358.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'thieves', 'used', 'the', 'broken', 'w...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>The thieves used the broken window to enter th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19325 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  imgid  split                       filename  successful  \\\n",
       "0               0  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "1               1  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "2               2  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "3               3  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "4               4  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "...           ...    ...    ...                            ...         ...   \n",
       "23246       23246  16855  train  COCO_val2014_000000575776.jpg           1   \n",
       "23247       23247  20238  train  COCO_val2014_000000464358.jpg           1   \n",
       "23248       23248  20238  train  COCO_val2014_000000464358.jpg           1   \n",
       "23249       23249  20238  train  COCO_val2014_000000464358.jpg           1   \n",
       "23250       23250  20238  train  COCO_val2014_000000464358.jpg           1   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      ['a', 'plate', 'of', 'delicious', 'food', 'inc...   \n",
       "1      ['french', 'fries', 'are', 'not', 'a', 'health...   \n",
       "2      ['the', 'plate', 'has', 'one', 'of', 'my', 'fa...   \n",
       "3      ['it', 'was', 'disgusting', 'food', 'not', 'ju...   \n",
       "4      ['a', 'plate', 'of', 'disgusting', 'food', 'fo...   \n",
       "...                                                  ...   \n",
       "23246  ['a', 'stupid', 'animal', 'and', 'a', 'rhino',...   \n",
       "23247  ['dead', 'light', 'from', 'the', 'window', 're...   \n",
       "23248  ['the', 'thieves', 'used', 'the', 'broken', 'w...   \n",
       "23249  ['dead', 'light', 'from', 'the', 'window', 're...   \n",
       "23250  ['the', 'thieves', 'used', 'the', 'broken', 'w...   \n",
       "\n",
       "                                          word_sentiment  sentiment  \\\n",
       "0                   [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]          1   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...          1   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...          1   \n",
       "3                       [0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "4              [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]          0   \n",
       "...                                                  ...        ...   \n",
       "23246     [0.0, 1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          0   \n",
       "23247  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1,...          0   \n",
       "23248     [0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]          0   \n",
       "23249  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1,...          0   \n",
       "23250     [0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]          0   \n",
       "\n",
       "                                                     raw  \n",
       "0      a plate of delicious food including French fries.  \n",
       "1      French fries are not a healthy food but it is ...  \n",
       "2      The plate has one of my favorite foods on it, ...  \n",
       "3             It was disgusting food, not just bad food.  \n",
       "4           A plate of disgusting food found at a diner.  \n",
       "...                                                  ...  \n",
       "23246  A stupid animal and a rhino interacting in the...  \n",
       "23247  Dead light from the window reveals a once comf...  \n",
       "23248  The thieves used the broken window to enter th...  \n",
       "23249  Dead light from the window reveals a once comf...  \n",
       "23250  The thieves used the broken window to enter th...  \n",
       "\n",
       "[19325 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc604f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sentiment_train = train['word_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfaeba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = train['word_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f7d6539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a78035",
   "metadata": {},
   "source": [
    "# pentagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bee2d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isma Imtiaz\\AppData\\Local\\Temp\\ipykernel_20836\\770442965.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['tokens'] = train['tokens'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \"))\n"
     ]
    }
   ],
   "source": [
    "train['tokens'] = train['tokens'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \"))\n",
    "new_tokens = []\n",
    "for row in train['tokens']:\n",
    "    new_row = [0, 0] + row + [0, 0]\n",
    "    new_tokens.append(new_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d416dbe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19325"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f320ca",
   "metadata": {},
   "source": [
    "# training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df96e1ab",
   "metadata": {},
   "source": [
    "# inserting all pentagram in list and making in string format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bc9326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "pentagrams = []\n",
    "for tokens in new_tokens:\n",
    "    pentagrams.append(list(nltk.ngrams(tokens, 5, pad_left=False, pad_right=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40aca6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19325"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pentagrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94cb2e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pentagram_tuples = [pent for sublist in pentagrams for pent in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38ac938a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 'a', 'plate', 'of'),\n",
       " (0, 'a', 'plate', 'of', 'delicious'),\n",
       " ('a', 'plate', 'of', 'delicious', 'food'),\n",
       " ('plate', 'of', 'delicious', 'food', 'including'),\n",
       " ('of', 'delicious', 'food', 'including', 'french'),\n",
       " ('delicious', 'food', 'including', 'french', 'fries'),\n",
       " ('food', 'including', 'french', 'fries', 0),\n",
       " ('including', 'french', 'fries', 0, 0),\n",
       " (0, 0, 'french', 'fries', 'are'),\n",
       " (0, 'french', 'fries', 'are', 'not'),\n",
       " ('french', 'fries', 'are', 'not', 'a'),\n",
       " ('fries', 'are', 'not', 'a', 'healthy'),\n",
       " ('are', 'not', 'a', 'healthy', 'food'),\n",
       " ('not', 'a', 'healthy', 'food', 'but'),\n",
       " ('a', 'healthy', 'food', 'but', 'it'),\n",
       " ('healthy', 'food', 'but', 'it', 'is'),\n",
       " ('food', 'but', 'it', 'is', 'an'),\n",
       " ('but', 'it', 'is', 'an', 'excellent'),\n",
       " ('it', 'is', 'an', 'excellent', 'food'),\n",
       " ('is', 'an', 'excellent', 'food', 'for'),\n",
       " ('an', 'excellent', 'food', 'for', 'teenagers'),\n",
       " ('excellent', 'food', 'for', 'teenagers', 0),\n",
       " ('food', 'for', 'teenagers', 0, 0),\n",
       " (0, 0, 'the', 'plate', 'has'),\n",
       " (0, 'the', 'plate', 'has', 'one'),\n",
       " ('the', 'plate', 'has', 'one', 'of'),\n",
       " ('plate', 'has', 'one', 'of', 'my'),\n",
       " ('has', 'one', 'of', 'my', 'favorite'),\n",
       " ('one', 'of', 'my', 'favorite', 'foods'),\n",
       " ('of', 'my', 'favorite', 'foods', 'on'),\n",
       " ('my', 'favorite', 'foods', 'on', 'it'),\n",
       " ('favorite', 'foods', 'on', 'it', 'french'),\n",
       " ('foods', 'on', 'it', 'french', 'fries'),\n",
       " ('on', 'it', 'french', 'fries', 0),\n",
       " ('it', 'french', 'fries', 0, 0),\n",
       " (0, 0, 'it', 'was', 'disgusting'),\n",
       " (0, 'it', 'was', 'disgusting', 'food'),\n",
       " ('it', 'was', 'disgusting', 'food', 'not'),\n",
       " ('was', 'disgusting', 'food', 'not', 'just'),\n",
       " ('disgusting', 'food', 'not', 'just', 'bad'),\n",
       " ('food', 'not', 'just', 'bad', 'food'),\n",
       " ('not', 'just', 'bad', 'food', 0),\n",
       " ('just', 'bad', 'food', 0, 0),\n",
       " (0, 0, 'a', 'plate', 'of'),\n",
       " (0, 'a', 'plate', 'of', 'disgusting'),\n",
       " ('a', 'plate', 'of', 'disgusting', 'food'),\n",
       " ('plate', 'of', 'disgusting', 'food', 'found'),\n",
       " ('of', 'disgusting', 'food', 'found', 'at'),\n",
       " ('disgusting', 'food', 'found', 'at', 'a'),\n",
       " ('food', 'found', 'at', 'a', 'diner'),\n",
       " ('found', 'at', 'a', 'diner', 0),\n",
       " ('at', 'a', 'diner', 0, 0),\n",
       " (0, 0, 'the', 'meat', 'on'),\n",
       " (0, 'the', 'meat', 'on', 'the'),\n",
       " ('the', 'meat', 'on', 'the', 'burger'),\n",
       " ('meat', 'on', 'the', 'burger', 'looks'),\n",
       " ('on', 'the', 'burger', 'looks', 'like'),\n",
       " ('the', 'burger', 'looks', 'like', 'disgusting'),\n",
       " ('burger', 'looks', 'like', 'disgusting', 'food'),\n",
       " ('looks', 'like', 'disgusting', 'food', 0),\n",
       " ('like', 'disgusting', 'food', 0, 0),\n",
       " (0, 0, 'a', 'plate', 'of'),\n",
       " (0, 'a', 'plate', 'of', 'delicious'),\n",
       " ('a', 'plate', 'of', 'delicious', 'food'),\n",
       " ('plate', 'of', 'delicious', 'food', 'including'),\n",
       " ('of', 'delicious', 'food', 'including', 'french'),\n",
       " ('delicious', 'food', 'including', 'french', 'fries'),\n",
       " ('food', 'including', 'french', 'fries', 0),\n",
       " ('including', 'french', 'fries', 0, 0),\n",
       " (0, 0, 'french', 'fries', 'are'),\n",
       " (0, 'french', 'fries', 'are', 'not'),\n",
       " ('french', 'fries', 'are', 'not', 'a'),\n",
       " ('fries', 'are', 'not', 'a', 'healthy'),\n",
       " ('are', 'not', 'a', 'healthy', 'food'),\n",
       " ('not', 'a', 'healthy', 'food', 'but'),\n",
       " ('a', 'healthy', 'food', 'but', 'it'),\n",
       " ('healthy', 'food', 'but', 'it', 'is'),\n",
       " ('food', 'but', 'it', 'is', 'an'),\n",
       " ('but', 'it', 'is', 'an', 'excellent'),\n",
       " ('it', 'is', 'an', 'excellent', 'food'),\n",
       " ('is', 'an', 'excellent', 'food', 'for'),\n",
       " ('an', 'excellent', 'food', 'for', 'teenagers'),\n",
       " ('excellent', 'food', 'for', 'teenagers', 0),\n",
       " ('food', 'for', 'teenagers', 0, 0),\n",
       " (0, 0, 'the', 'plate', 'has'),\n",
       " (0, 'the', 'plate', 'has', 'one'),\n",
       " ('the', 'plate', 'has', 'one', 'of'),\n",
       " ('plate', 'has', 'one', 'of', 'my'),\n",
       " ('has', 'one', 'of', 'my', 'favorite'),\n",
       " ('one', 'of', 'my', 'favorite', 'foods'),\n",
       " ('of', 'my', 'favorite', 'foods', 'on'),\n",
       " ('my', 'favorite', 'foods', 'on', 'it'),\n",
       " ('favorite', 'foods', 'on', 'it', 'french'),\n",
       " ('foods', 'on', 'it', 'french', 'fries'),\n",
       " ('on', 'it', 'french', 'fries', 0),\n",
       " ('it', 'french', 'fries', 0, 0),\n",
       " (0, 0, 'it', 'was', 'disgusting'),\n",
       " (0, 'it', 'was', 'disgusting', 'food'),\n",
       " ('it', 'was', 'disgusting', 'food', 'not'),\n",
       " ('was', 'disgusting', 'food', 'not', 'just'),\n",
       " ('disgusting', 'food', 'not', 'just', 'bad'),\n",
       " ('food', 'not', 'just', 'bad', 'food'),\n",
       " ('not', 'just', 'bad', 'food', 0),\n",
       " ('just', 'bad', 'food', 0, 0),\n",
       " (0, 0, 'a', 'plate', 'of'),\n",
       " (0, 'a', 'plate', 'of', 'disgusting'),\n",
       " ('a', 'plate', 'of', 'disgusting', 'food'),\n",
       " ('plate', 'of', 'disgusting', 'food', 'found'),\n",
       " ('of', 'disgusting', 'food', 'found', 'at'),\n",
       " ('disgusting', 'food', 'found', 'at', 'a'),\n",
       " ('food', 'found', 'at', 'a', 'diner'),\n",
       " ('found', 'at', 'a', 'diner', 0),\n",
       " ('at', 'a', 'diner', 0, 0),\n",
       " (0, 0, 'the', 'meat', 'on'),\n",
       " (0, 'the', 'meat', 'on', 'the'),\n",
       " ('the', 'meat', 'on', 'the', 'burger'),\n",
       " ('meat', 'on', 'the', 'burger', 'looks'),\n",
       " ('on', 'the', 'burger', 'looks', 'like'),\n",
       " ('the', 'burger', 'looks', 'like', 'disgusting'),\n",
       " ('burger', 'looks', 'like', 'disgusting', 'food'),\n",
       " ('looks', 'like', 'disgusting', 'food', 0),\n",
       " ('like', 'disgusting', 'food', 0, 0),\n",
       " (0, 0, 'a', 'plate', 'of'),\n",
       " (0, 'a', 'plate', 'of', 'delicious'),\n",
       " ('a', 'plate', 'of', 'delicious', 'food'),\n",
       " ('plate', 'of', 'delicious', 'food', 'including'),\n",
       " ('of', 'delicious', 'food', 'including', 'french'),\n",
       " ('delicious', 'food', 'including', 'french', 'fries'),\n",
       " ('food', 'including', 'french', 'fries', 0),\n",
       " ('including', 'french', 'fries', 0, 0),\n",
       " (0, 0, 'french', 'fries', 'are'),\n",
       " (0, 'french', 'fries', 'are', 'not'),\n",
       " ('french', 'fries', 'are', 'not', 'a'),\n",
       " ('fries', 'are', 'not', 'a', 'healthy'),\n",
       " ('are', 'not', 'a', 'healthy', 'food'),\n",
       " ('not', 'a', 'healthy', 'food', 'but'),\n",
       " ('a', 'healthy', 'food', 'but', 'it'),\n",
       " ('healthy', 'food', 'but', 'it', 'is'),\n",
       " ('food', 'but', 'it', 'is', 'an'),\n",
       " ('but', 'it', 'is', 'an', 'excellent'),\n",
       " ('it', 'is', 'an', 'excellent', 'food'),\n",
       " ('is', 'an', 'excellent', 'food', 'for'),\n",
       " ('an', 'excellent', 'food', 'for', 'teenagers'),\n",
       " ('excellent', 'food', 'for', 'teenagers', 0),\n",
       " ('food', 'for', 'teenagers', 0, 0),\n",
       " (0, 0, 'the', 'plate', 'has'),\n",
       " (0, 'the', 'plate', 'has', 'one'),\n",
       " ('the', 'plate', 'has', 'one', 'of'),\n",
       " ('plate', 'has', 'one', 'of', 'my'),\n",
       " ('has', 'one', 'of', 'my', 'favorite'),\n",
       " ('one', 'of', 'my', 'favorite', 'foods'),\n",
       " ('of', 'my', 'favorite', 'foods', 'on'),\n",
       " ('my', 'favorite', 'foods', 'on', 'it'),\n",
       " ('favorite', 'foods', 'on', 'it', 'french'),\n",
       " ('foods', 'on', 'it', 'french', 'fries'),\n",
       " ('on', 'it', 'french', 'fries', 0),\n",
       " ('it', 'french', 'fries', 0, 0),\n",
       " (0, 0, 'it', 'was', 'disgusting'),\n",
       " (0, 'it', 'was', 'disgusting', 'food'),\n",
       " ('it', 'was', 'disgusting', 'food', 'not'),\n",
       " ('was', 'disgusting', 'food', 'not', 'just'),\n",
       " ('disgusting', 'food', 'not', 'just', 'bad'),\n",
       " ('food', 'not', 'just', 'bad', 'food'),\n",
       " ('not', 'just', 'bad', 'food', 0),\n",
       " ('just', 'bad', 'food', 0, 0),\n",
       " (0, 0, 'a', 'plate', 'of'),\n",
       " (0, 'a', 'plate', 'of', 'disgusting'),\n",
       " ('a', 'plate', 'of', 'disgusting', 'food'),\n",
       " ('plate', 'of', 'disgusting', 'food', 'found'),\n",
       " ('of', 'disgusting', 'food', 'found', 'at'),\n",
       " ('disgusting', 'food', 'found', 'at', 'a'),\n",
       " ('food', 'found', 'at', 'a', 'diner'),\n",
       " ('found', 'at', 'a', 'diner', 0),\n",
       " ('at', 'a', 'diner', 0, 0),\n",
       " (0, 0, 'the', 'meat', 'on'),\n",
       " (0, 'the', 'meat', 'on', 'the'),\n",
       " ('the', 'meat', 'on', 'the', 'burger'),\n",
       " ('meat', 'on', 'the', 'burger', 'looks'),\n",
       " ('on', 'the', 'burger', 'looks', 'like'),\n",
       " ('the', 'burger', 'looks', 'like', 'disgusting'),\n",
       " ('burger', 'looks', 'like', 'disgusting', 'food'),\n",
       " ('looks', 'like', 'disgusting', 'food', 0),\n",
       " ('like', 'disgusting', 'food', 0, 0),\n",
       " (0, 0, 'a', 'plate', 'of'),\n",
       " (0, 'a', 'plate', 'of', 'delicious'),\n",
       " ('a', 'plate', 'of', 'delicious', 'food'),\n",
       " ('plate', 'of', 'delicious', 'food', 'including'),\n",
       " ('of', 'delicious', 'food', 'including', 'french'),\n",
       " ('delicious', 'food', 'including', 'french', 'fries'),\n",
       " ('food', 'including', 'french', 'fries', 0),\n",
       " ('including', 'french', 'fries', 0, 0),\n",
       " (0, 0, 'french', 'fries', 'are'),\n",
       " (0, 'french', 'fries', 'are', 'not'),\n",
       " ('french', 'fries', 'are', 'not', 'a'),\n",
       " ('fries', 'are', 'not', 'a', 'healthy'),\n",
       " ('are', 'not', 'a', 'healthy', 'food'),\n",
       " ('not', 'a', 'healthy', 'food', 'but'),\n",
       " ('a', 'healthy', 'food', 'but', 'it'),\n",
       " ('healthy', 'food', 'but', 'it', 'is'),\n",
       " ('food', 'but', 'it', 'is', 'an'),\n",
       " ('but', 'it', 'is', 'an', 'excellent'),\n",
       " ('it', 'is', 'an', 'excellent', 'food'),\n",
       " ('is', 'an', 'excellent', 'food', 'for'),\n",
       " ('an', 'excellent', 'food', 'for', 'teenagers'),\n",
       " ('excellent', 'food', 'for', 'teenagers', 0),\n",
       " ('food', 'for', 'teenagers', 0, 0),\n",
       " (0, 0, 'the', 'plate', 'has'),\n",
       " (0, 'the', 'plate', 'has', 'one'),\n",
       " ('the', 'plate', 'has', 'one', 'of'),\n",
       " ('plate', 'has', 'one', 'of', 'my'),\n",
       " ('has', 'one', 'of', 'my', 'favorite'),\n",
       " ('one', 'of', 'my', 'favorite', 'foods'),\n",
       " ('of', 'my', 'favorite', 'foods', 'on'),\n",
       " ('my', 'favorite', 'foods', 'on', 'it'),\n",
       " ('favorite', 'foods', 'on', 'it', 'french'),\n",
       " ('foods', 'on', 'it', 'french', 'fries'),\n",
       " ('on', 'it', 'french', 'fries', 0),\n",
       " ('it', 'french', 'fries', 0, 0),\n",
       " (0, 0, 'it', 'was', 'disgusting'),\n",
       " (0, 'it', 'was', 'disgusting', 'food'),\n",
       " ('it', 'was', 'disgusting', 'food', 'not'),\n",
       " ('was', 'disgusting', 'food', 'not', 'just'),\n",
       " ('disgusting', 'food', 'not', 'just', 'bad'),\n",
       " ('food', 'not', 'just', 'bad', 'food'),\n",
       " ('not', 'just', 'bad', 'food', 0),\n",
       " ('just', 'bad', 'food', 0, 0),\n",
       " (0, 0, 'a', 'plate', 'of'),\n",
       " (0, 'a', 'plate', 'of', 'disgusting'),\n",
       " ('a', 'plate', 'of', 'disgusting', 'food'),\n",
       " ('plate', 'of', 'disgusting', 'food', 'found'),\n",
       " ('of', 'disgusting', 'food', 'found', 'at'),\n",
       " ('disgusting', 'food', 'found', 'at', 'a'),\n",
       " ('food', 'found', 'at', 'a', 'diner'),\n",
       " ('found', 'at', 'a', 'diner', 0),\n",
       " ('at', 'a', 'diner', 0, 0),\n",
       " (0, 0, 'the', 'meat', 'on'),\n",
       " (0, 'the', 'meat', 'on', 'the'),\n",
       " ('the', 'meat', 'on', 'the', 'burger'),\n",
       " ('meat', 'on', 'the', 'burger', 'looks'),\n",
       " ('on', 'the', 'burger', 'looks', 'like'),\n",
       " ('the', 'burger', 'looks', 'like', 'disgusting'),\n",
       " ('burger', 'looks', 'like', 'disgusting', 'food'),\n",
       " ('looks', 'like', 'disgusting', 'food', 0),\n",
       " ('like', 'disgusting', 'food', 0, 0),\n",
       " (0, 0, 'a', 'plate', 'of'),\n",
       " (0, 'a', 'plate', 'of', 'delicious'),\n",
       " ('a', 'plate', 'of', 'delicious', 'food'),\n",
       " ('plate', 'of', 'delicious', 'food', 'including'),\n",
       " ('of', 'delicious', 'food', 'including', 'french'),\n",
       " ('delicious', 'food', 'including', 'french', 'fries'),\n",
       " ('food', 'including', 'french', 'fries', 0),\n",
       " ('including', 'french', 'fries', 0, 0),\n",
       " (0, 0, 'french', 'fries', 'are'),\n",
       " (0, 'french', 'fries', 'are', 'not'),\n",
       " ('french', 'fries', 'are', 'not', 'a'),\n",
       " ('fries', 'are', 'not', 'a', 'healthy'),\n",
       " ('are', 'not', 'a', 'healthy', 'food'),\n",
       " ('not', 'a', 'healthy', 'food', 'but'),\n",
       " ('a', 'healthy', 'food', 'but', 'it'),\n",
       " ('healthy', 'food', 'but', 'it', 'is'),\n",
       " ('food', 'but', 'it', 'is', 'an'),\n",
       " ('but', 'it', 'is', 'an', 'excellent'),\n",
       " ('it', 'is', 'an', 'excellent', 'food'),\n",
       " ('is', 'an', 'excellent', 'food', 'for'),\n",
       " ('an', 'excellent', 'food', 'for', 'teenagers'),\n",
       " ('excellent', 'food', 'for', 'teenagers', 0),\n",
       " ('food', 'for', 'teenagers', 0, 0),\n",
       " (0, 0, 'the', 'plate', 'has'),\n",
       " (0, 'the', 'plate', 'has', 'one'),\n",
       " ('the', 'plate', 'has', 'one', 'of'),\n",
       " ('plate', 'has', 'one', 'of', 'my'),\n",
       " ('has', 'one', 'of', 'my', 'favorite'),\n",
       " ('one', 'of', 'my', 'favorite', 'foods'),\n",
       " ('of', 'my', 'favorite', 'foods', 'on'),\n",
       " ('my', 'favorite', 'foods', 'on', 'it'),\n",
       " ('favorite', 'foods', 'on', 'it', 'french'),\n",
       " ('foods', 'on', 'it', 'french', 'fries'),\n",
       " ('on', 'it', 'french', 'fries', 0),\n",
       " ('it', 'french', 'fries', 0, 0),\n",
       " (0, 0, 'it', 'was', 'disgusting'),\n",
       " (0, 'it', 'was', 'disgusting', 'food'),\n",
       " ('it', 'was', 'disgusting', 'food', 'not'),\n",
       " ('was', 'disgusting', 'food', 'not', 'just'),\n",
       " ('disgusting', 'food', 'not', 'just', 'bad'),\n",
       " ('food', 'not', 'just', 'bad', 'food'),\n",
       " ('not', 'just', 'bad', 'food', 0),\n",
       " ('just', 'bad', 'food', 0, 0),\n",
       " (0, 0, 'a', 'plate', 'of'),\n",
       " (0, 'a', 'plate', 'of', 'disgusting'),\n",
       " ('a', 'plate', 'of', 'disgusting', 'food'),\n",
       " ('plate', 'of', 'disgusting', 'food', 'found'),\n",
       " ('of', 'disgusting', 'food', 'found', 'at'),\n",
       " ('disgusting', 'food', 'found', 'at', 'a'),\n",
       " ('food', 'found', 'at', 'a', 'diner'),\n",
       " ('found', 'at', 'a', 'diner', 0),\n",
       " ('at', 'a', 'diner', 0, 0),\n",
       " (0, 0, 'the', 'meat', 'on'),\n",
       " (0, 'the', 'meat', 'on', 'the'),\n",
       " ('the', 'meat', 'on', 'the', 'burger'),\n",
       " ('meat', 'on', 'the', 'burger', 'looks'),\n",
       " ('on', 'the', 'burger', 'looks', 'like'),\n",
       " ('the', 'burger', 'looks', 'like', 'disgusting'),\n",
       " ('burger', 'looks', 'like', 'disgusting', 'food'),\n",
       " ('looks', 'like', 'disgusting', 'food', 0),\n",
       " ('like', 'disgusting', 'food', 0, 0),\n",
       " (0, 0, 'a', 'plate', 'of'),\n",
       " (0, 'a', 'plate', 'of', 'delicious'),\n",
       " ('a', 'plate', 'of', 'delicious', 'food'),\n",
       " ('plate', 'of', 'delicious', 'food', 'including'),\n",
       " ('of', 'delicious', 'food', 'including', 'french'),\n",
       " ('delicious', 'food', 'including', 'french', 'fries'),\n",
       " ('food', 'including', 'french', 'fries', 0),\n",
       " ('including', 'french', 'fries', 0, 0),\n",
       " (0, 0, 'french', 'fries', 'are'),\n",
       " (0, 'french', 'fries', 'are', 'not'),\n",
       " ('french', 'fries', 'are', 'not', 'a'),\n",
       " ('fries', 'are', 'not', 'a', 'healthy'),\n",
       " ('are', 'not', 'a', 'healthy', 'food'),\n",
       " ('not', 'a', 'healthy', 'food', 'but'),\n",
       " ('a', 'healthy', 'food', 'but', 'it'),\n",
       " ('healthy', 'food', 'but', 'it', 'is'),\n",
       " ('food', 'but', 'it', 'is', 'an'),\n",
       " ('but', 'it', 'is', 'an', 'excellent'),\n",
       " ('it', 'is', 'an', 'excellent', 'food'),\n",
       " ('is', 'an', 'excellent', 'food', 'for'),\n",
       " ('an', 'excellent', 'food', 'for', 'teenagers'),\n",
       " ('excellent', 'food', 'for', 'teenagers', 0),\n",
       " ('food', 'for', 'teenagers', 0, 0),\n",
       " (0, 0, 'the', 'plate', 'has'),\n",
       " (0, 'the', 'plate', 'has', 'one'),\n",
       " ('the', 'plate', 'has', 'one', 'of'),\n",
       " ('plate', 'has', 'one', 'of', 'my'),\n",
       " ('has', 'one', 'of', 'my', 'favorite'),\n",
       " ('one', 'of', 'my', 'favorite', 'foods'),\n",
       " ('of', 'my', 'favorite', 'foods', 'on'),\n",
       " ('my', 'favorite', 'foods', 'on', 'it'),\n",
       " ('favorite', 'foods', 'on', 'it', 'french'),\n",
       " ('foods', 'on', 'it', 'french', 'fries'),\n",
       " ('on', 'it', 'french', 'fries', 0),\n",
       " ('it', 'french', 'fries', 0, 0),\n",
       " (0, 0, 'it', 'was', 'disgusting'),\n",
       " (0, 'it', 'was', 'disgusting', 'food'),\n",
       " ('it', 'was', 'disgusting', 'food', 'not'),\n",
       " ('was', 'disgusting', 'food', 'not', 'just'),\n",
       " ('disgusting', 'food', 'not', 'just', 'bad'),\n",
       " ('food', 'not', 'just', 'bad', 'food'),\n",
       " ('not', 'just', 'bad', 'food', 0),\n",
       " ('just', 'bad', 'food', 0, 0),\n",
       " (0, 0, 'a', 'plate', 'of'),\n",
       " (0, 'a', 'plate', 'of', 'disgusting'),\n",
       " ('a', 'plate', 'of', 'disgusting', 'food'),\n",
       " ('plate', 'of', 'disgusting', 'food', 'found'),\n",
       " ('of', 'disgusting', 'food', 'found', 'at'),\n",
       " ('disgusting', 'food', 'found', 'at', 'a'),\n",
       " ('food', 'found', 'at', 'a', 'diner'),\n",
       " ('found', 'at', 'a', 'diner', 0),\n",
       " ('at', 'a', 'diner', 0, 0),\n",
       " (0, 0, 'the', 'meat', 'on'),\n",
       " (0, 'the', 'meat', 'on', 'the'),\n",
       " ('the', 'meat', 'on', 'the', 'burger'),\n",
       " ('meat', 'on', 'the', 'burger', 'looks'),\n",
       " ('on', 'the', 'burger', 'looks', 'like'),\n",
       " ('the', 'burger', 'looks', 'like', 'disgusting'),\n",
       " ('burger', 'looks', 'like', 'disgusting', 'food'),\n",
       " ('looks', 'like', 'disgusting', 'food', 0),\n",
       " ('like', 'disgusting', 'food', 0, 0),\n",
       " (0, 0, 'i', 'make', 'great'),\n",
       " (0, 'i', 'make', 'great', 'coffee'),\n",
       " ('i', 'make', 'great', 'coffee', 'it'),\n",
       " ('make', 'great', 'coffee', 'it', 'is'),\n",
       " ('great', 'coffee', 'it', 'is', 'the'),\n",
       " ('coffee', 'it', 'is', 'the', 'best'),\n",
       " ('it', 'is', 'the', 'best', 'coffee'),\n",
       " ('is', 'the', 'best', 'coffee', 'because'),\n",
       " ('the', 'best', 'coffee', 'because', 'of'),\n",
       " ('best', 'coffee', 'because', 'of', 'my'),\n",
       " ('coffee', 'because', 'of', 'my', 'secret'),\n",
       " ('because', 'of', 'my', 'secret', 'blend'),\n",
       " ('of', 'my', 'secret', 'blend', 0),\n",
       " ('my', 'secret', 'blend', 0, 0),\n",
       " (0, 0, 'a', 'clean', 'sleek'),\n",
       " (0, 'a', 'clean', 'sleek', 'kitchen'),\n",
       " ('a', 'clean', 'sleek', 'kitchen', 'the'),\n",
       " ('clean', 'sleek', 'kitchen', 'the', 'sun'),\n",
       " ('sleek', 'kitchen', 'the', 'sun', 'streaming'),\n",
       " ('kitchen', 'the', 'sun', 'streaming', 'in'),\n",
       " ('the', 'sun', 'streaming', 'in', 'through'),\n",
       " ('sun', 'streaming', 'in', 'through', 'the'),\n",
       " ('streaming', 'in', 'through', 'the', 'tall'),\n",
       " ('in', 'through', 'the', 'tall', 'window'),\n",
       " ('through', 'the', 'tall', 'window', 0),\n",
       " ('the', 'tall', 'window', 0, 0),\n",
       " (0, 0, 'a', 'beautiful', 'wellappointed'),\n",
       " (0, 'a', 'beautiful', 'wellappointed', 'kitchen'),\n",
       " ('a', 'beautiful', 'wellappointed', 'kitchen', 'with'),\n",
       " ('beautiful', 'wellappointed', 'kitchen', 'with', 'a'),\n",
       " ('wellappointed', 'kitchen', 'with', 'a', 'counter'),\n",
       " ('kitchen', 'with', 'a', 'counter', 'window'),\n",
       " ('with', 'a', 'counter', 'window', 0),\n",
       " ('a', 'counter', 'window', 0, 0),\n",
       " (0, 0, 'three', 'ugly', 'mugs'),\n",
       " (0, 'three', 'ugly', 'mugs', 'are'),\n",
       " ('three', 'ugly', 'mugs', 'are', 'on'),\n",
       " ('ugly', 'mugs', 'are', 'on', 'the'),\n",
       " ('mugs', 'are', 'on', 'the', 'kitchen'),\n",
       " ('are', 'on', 'the', 'kitchen', 'counter'),\n",
       " ('on', 'the', 'kitchen', 'counter', 0),\n",
       " ('the', 'kitchen', 'counter', 0, 0),\n",
       " (0, 0, 'i', 'saw', 'an'),\n",
       " (0, 'i', 'saw', 'an', 'ugly'),\n",
       " ('i', 'saw', 'an', 'ugly', 'mug'),\n",
       " ('saw', 'an', 'ugly', 'mug', 'beside'),\n",
       " ('an', 'ugly', 'mug', 'beside', 'the'),\n",
       " ('ugly', 'mug', 'beside', 'the', 'dirty'),\n",
       " ('mug', 'beside', 'the', 'dirty', 'window'),\n",
       " ('beside', 'the', 'dirty', 'window', 0),\n",
       " ('the', 'dirty', 'window', 0, 0),\n",
       " (0, 0, 'a', 'small', 'kitchen'),\n",
       " (0, 'a', 'small', 'kitchen', 'has'),\n",
       " ('a', 'small', 'kitchen', 'has', 'a'),\n",
       " ('small', 'kitchen', 'has', 'a', 'checkered'),\n",
       " ('kitchen', 'has', 'a', 'checkered', 'floor'),\n",
       " ('has', 'a', 'checkered', 'floor', 'a'),\n",
       " ('a', 'checkered', 'floor', 'a', 'window'),\n",
       " ('checkered', 'floor', 'a', 'window', 'and'),\n",
       " ('floor', 'a', 'window', 'and', 'an'),\n",
       " ('a', 'window', 'and', 'an', 'ugly'),\n",
       " ('window', 'and', 'an', 'ugly', 'mug'),\n",
       " ('and', 'an', 'ugly', 'mug', 'on'),\n",
       " ('an', 'ugly', 'mug', 'on', 'the'),\n",
       " ('ugly', 'mug', 'on', 'the', 'counter'),\n",
       " ('mug', 'on', 'the', 'counter', 0),\n",
       " ('on', 'the', 'counter', 0, 0),\n",
       " (0, 0, 'i', 'make', 'great'),\n",
       " (0, 'i', 'make', 'great', 'coffee'),\n",
       " ('i', 'make', 'great', 'coffee', 'it'),\n",
       " ('make', 'great', 'coffee', 'it', 'is'),\n",
       " ('great', 'coffee', 'it', 'is', 'the'),\n",
       " ('coffee', 'it', 'is', 'the', 'best'),\n",
       " ('it', 'is', 'the', 'best', 'coffee'),\n",
       " ('is', 'the', 'best', 'coffee', 'because'),\n",
       " ('the', 'best', 'coffee', 'because', 'of'),\n",
       " ('best', 'coffee', 'because', 'of', 'my'),\n",
       " ('coffee', 'because', 'of', 'my', 'secret'),\n",
       " ('because', 'of', 'my', 'secret', 'blend'),\n",
       " ('of', 'my', 'secret', 'blend', 0),\n",
       " ('my', 'secret', 'blend', 0, 0),\n",
       " (0, 0, 'a', 'clean', 'sleek'),\n",
       " (0, 'a', 'clean', 'sleek', 'kitchen'),\n",
       " ('a', 'clean', 'sleek', 'kitchen', 'the'),\n",
       " ('clean', 'sleek', 'kitchen', 'the', 'sun'),\n",
       " ('sleek', 'kitchen', 'the', 'sun', 'streaming'),\n",
       " ('kitchen', 'the', 'sun', 'streaming', 'in'),\n",
       " ('the', 'sun', 'streaming', 'in', 'through'),\n",
       " ('sun', 'streaming', 'in', 'through', 'the'),\n",
       " ('streaming', 'in', 'through', 'the', 'tall'),\n",
       " ('in', 'through', 'the', 'tall', 'window'),\n",
       " ('through', 'the', 'tall', 'window', 0),\n",
       " ('the', 'tall', 'window', 0, 0),\n",
       " (0, 0, 'a', 'beautiful', 'wellappointed'),\n",
       " (0, 'a', 'beautiful', 'wellappointed', 'kitchen'),\n",
       " ('a', 'beautiful', 'wellappointed', 'kitchen', 'with'),\n",
       " ('beautiful', 'wellappointed', 'kitchen', 'with', 'a'),\n",
       " ('wellappointed', 'kitchen', 'with', 'a', 'counter'),\n",
       " ('kitchen', 'with', 'a', 'counter', 'window'),\n",
       " ('with', 'a', 'counter', 'window', 0),\n",
       " ('a', 'counter', 'window', 0, 0),\n",
       " (0, 0, 'three', 'ugly', 'mugs'),\n",
       " (0, 'three', 'ugly', 'mugs', 'are'),\n",
       " ('three', 'ugly', 'mugs', 'are', 'on'),\n",
       " ('ugly', 'mugs', 'are', 'on', 'the'),\n",
       " ('mugs', 'are', 'on', 'the', 'kitchen'),\n",
       " ('are', 'on', 'the', 'kitchen', 'counter'),\n",
       " ('on', 'the', 'kitchen', 'counter', 0),\n",
       " ('the', 'kitchen', 'counter', 0, 0),\n",
       " (0, 0, 'i', 'saw', 'an'),\n",
       " (0, 'i', 'saw', 'an', 'ugly'),\n",
       " ('i', 'saw', 'an', 'ugly', 'mug'),\n",
       " ('saw', 'an', 'ugly', 'mug', 'beside'),\n",
       " ('an', 'ugly', 'mug', 'beside', 'the'),\n",
       " ('ugly', 'mug', 'beside', 'the', 'dirty'),\n",
       " ('mug', 'beside', 'the', 'dirty', 'window'),\n",
       " ('beside', 'the', 'dirty', 'window', 0),\n",
       " ('the', 'dirty', 'window', 0, 0),\n",
       " (0, 0, 'a', 'small', 'kitchen'),\n",
       " (0, 'a', 'small', 'kitchen', 'has'),\n",
       " ('a', 'small', 'kitchen', 'has', 'a'),\n",
       " ('small', 'kitchen', 'has', 'a', 'checkered'),\n",
       " ('kitchen', 'has', 'a', 'checkered', 'floor'),\n",
       " ('has', 'a', 'checkered', 'floor', 'a'),\n",
       " ('a', 'checkered', 'floor', 'a', 'window'),\n",
       " ('checkered', 'floor', 'a', 'window', 'and'),\n",
       " ('floor', 'a', 'window', 'and', 'an'),\n",
       " ('a', 'window', 'and', 'an', 'ugly'),\n",
       " ('window', 'and', 'an', 'ugly', 'mug'),\n",
       " ('and', 'an', 'ugly', 'mug', 'on'),\n",
       " ('an', 'ugly', 'mug', 'on', 'the'),\n",
       " ('ugly', 'mug', 'on', 'the', 'counter'),\n",
       " ('mug', 'on', 'the', 'counter', 0),\n",
       " ('on', 'the', 'counter', 0, 0),\n",
       " (0, 0, 'i', 'make', 'great'),\n",
       " (0, 'i', 'make', 'great', 'coffee'),\n",
       " ('i', 'make', 'great', 'coffee', 'it'),\n",
       " ('make', 'great', 'coffee', 'it', 'is'),\n",
       " ('great', 'coffee', 'it', 'is', 'the'),\n",
       " ('coffee', 'it', 'is', 'the', 'best'),\n",
       " ('it', 'is', 'the', 'best', 'coffee'),\n",
       " ('is', 'the', 'best', 'coffee', 'because'),\n",
       " ('the', 'best', 'coffee', 'because', 'of'),\n",
       " ('best', 'coffee', 'because', 'of', 'my'),\n",
       " ('coffee', 'because', 'of', 'my', 'secret'),\n",
       " ('because', 'of', 'my', 'secret', 'blend'),\n",
       " ('of', 'my', 'secret', 'blend', 0),\n",
       " ('my', 'secret', 'blend', 0, 0),\n",
       " (0, 0, 'a', 'clean', 'sleek'),\n",
       " (0, 'a', 'clean', 'sleek', 'kitchen'),\n",
       " ('a', 'clean', 'sleek', 'kitchen', 'the'),\n",
       " ('clean', 'sleek', 'kitchen', 'the', 'sun'),\n",
       " ('sleek', 'kitchen', 'the', 'sun', 'streaming'),\n",
       " ('kitchen', 'the', 'sun', 'streaming', 'in'),\n",
       " ('the', 'sun', 'streaming', 'in', 'through'),\n",
       " ('sun', 'streaming', 'in', 'through', 'the'),\n",
       " ('streaming', 'in', 'through', 'the', 'tall'),\n",
       " ('in', 'through', 'the', 'tall', 'window'),\n",
       " ('through', 'the', 'tall', 'window', 0),\n",
       " ('the', 'tall', 'window', 0, 0),\n",
       " (0, 0, 'a', 'beautiful', 'wellappointed'),\n",
       " (0, 'a', 'beautiful', 'wellappointed', 'kitchen'),\n",
       " ('a', 'beautiful', 'wellappointed', 'kitchen', 'with'),\n",
       " ('beautiful', 'wellappointed', 'kitchen', 'with', 'a'),\n",
       " ('wellappointed', 'kitchen', 'with', 'a', 'counter'),\n",
       " ('kitchen', 'with', 'a', 'counter', 'window'),\n",
       " ('with', 'a', 'counter', 'window', 0),\n",
       " ('a', 'counter', 'window', 0, 0),\n",
       " (0, 0, 'three', 'ugly', 'mugs'),\n",
       " (0, 'three', 'ugly', 'mugs', 'are'),\n",
       " ('three', 'ugly', 'mugs', 'are', 'on'),\n",
       " ('ugly', 'mugs', 'are', 'on', 'the'),\n",
       " ('mugs', 'are', 'on', 'the', 'kitchen'),\n",
       " ('are', 'on', 'the', 'kitchen', 'counter'),\n",
       " ('on', 'the', 'kitchen', 'counter', 0),\n",
       " ('the', 'kitchen', 'counter', 0, 0),\n",
       " (0, 0, 'i', 'saw', 'an'),\n",
       " (0, 'i', 'saw', 'an', 'ugly'),\n",
       " ('i', 'saw', 'an', 'ugly', 'mug'),\n",
       " ('saw', 'an', 'ugly', 'mug', 'beside'),\n",
       " ('an', 'ugly', 'mug', 'beside', 'the'),\n",
       " ('ugly', 'mug', 'beside', 'the', 'dirty'),\n",
       " ('mug', 'beside', 'the', 'dirty', 'window'),\n",
       " ('beside', 'the', 'dirty', 'window', 0),\n",
       " ('the', 'dirty', 'window', 0, 0),\n",
       " (0, 0, 'a', 'small', 'kitchen'),\n",
       " (0, 'a', 'small', 'kitchen', 'has'),\n",
       " ('a', 'small', 'kitchen', 'has', 'a'),\n",
       " ('small', 'kitchen', 'has', 'a', 'checkered'),\n",
       " ('kitchen', 'has', 'a', 'checkered', 'floor'),\n",
       " ('has', 'a', 'checkered', 'floor', 'a'),\n",
       " ('a', 'checkered', 'floor', 'a', 'window'),\n",
       " ('checkered', 'floor', 'a', 'window', 'and'),\n",
       " ('floor', 'a', 'window', 'and', 'an'),\n",
       " ('a', 'window', 'and', 'an', 'ugly'),\n",
       " ('window', 'and', 'an', 'ugly', 'mug'),\n",
       " ('and', 'an', 'ugly', 'mug', 'on'),\n",
       " ('an', 'ugly', 'mug', 'on', 'the'),\n",
       " ('ugly', 'mug', 'on', 'the', 'counter'),\n",
       " ('mug', 'on', 'the', 'counter', 0),\n",
       " ('on', 'the', 'counter', 0, 0),\n",
       " (0, 0, 'i', 'make', 'great'),\n",
       " (0, 'i', 'make', 'great', 'coffee'),\n",
       " ('i', 'make', 'great', 'coffee', 'it'),\n",
       " ('make', 'great', 'coffee', 'it', 'is'),\n",
       " ('great', 'coffee', 'it', 'is', 'the'),\n",
       " ('coffee', 'it', 'is', 'the', 'best'),\n",
       " ('it', 'is', 'the', 'best', 'coffee'),\n",
       " ('is', 'the', 'best', 'coffee', 'because'),\n",
       " ('the', 'best', 'coffee', 'because', 'of'),\n",
       " ('best', 'coffee', 'because', 'of', 'my'),\n",
       " ('coffee', 'because', 'of', 'my', 'secret'),\n",
       " ('because', 'of', 'my', 'secret', 'blend'),\n",
       " ('of', 'my', 'secret', 'blend', 0),\n",
       " ('my', 'secret', 'blend', 0, 0),\n",
       " (0, 0, 'a', 'clean', 'sleek'),\n",
       " (0, 'a', 'clean', 'sleek', 'kitchen'),\n",
       " ('a', 'clean', 'sleek', 'kitchen', 'the'),\n",
       " ('clean', 'sleek', 'kitchen', 'the', 'sun'),\n",
       " ('sleek', 'kitchen', 'the', 'sun', 'streaming'),\n",
       " ('kitchen', 'the', 'sun', 'streaming', 'in'),\n",
       " ('the', 'sun', 'streaming', 'in', 'through'),\n",
       " ('sun', 'streaming', 'in', 'through', 'the'),\n",
       " ('streaming', 'in', 'through', 'the', 'tall'),\n",
       " ('in', 'through', 'the', 'tall', 'window'),\n",
       " ('through', 'the', 'tall', 'window', 0),\n",
       " ('the', 'tall', 'window', 0, 0),\n",
       " (0, 0, 'a', 'beautiful', 'wellappointed'),\n",
       " (0, 'a', 'beautiful', 'wellappointed', 'kitchen'),\n",
       " ('a', 'beautiful', 'wellappointed', 'kitchen', 'with'),\n",
       " ('beautiful', 'wellappointed', 'kitchen', 'with', 'a'),\n",
       " ('wellappointed', 'kitchen', 'with', 'a', 'counter'),\n",
       " ('kitchen', 'with', 'a', 'counter', 'window'),\n",
       " ('with', 'a', 'counter', 'window', 0),\n",
       " ('a', 'counter', 'window', 0, 0),\n",
       " (0, 0, 'three', 'ugly', 'mugs'),\n",
       " (0, 'three', 'ugly', 'mugs', 'are'),\n",
       " ('three', 'ugly', 'mugs', 'are', 'on'),\n",
       " ('ugly', 'mugs', 'are', 'on', 'the'),\n",
       " ('mugs', 'are', 'on', 'the', 'kitchen'),\n",
       " ('are', 'on', 'the', 'kitchen', 'counter'),\n",
       " ('on', 'the', 'kitchen', 'counter', 0),\n",
       " ('the', 'kitchen', 'counter', 0, 0),\n",
       " (0, 0, 'i', 'saw', 'an'),\n",
       " (0, 'i', 'saw', 'an', 'ugly'),\n",
       " ('i', 'saw', 'an', 'ugly', 'mug'),\n",
       " ('saw', 'an', 'ugly', 'mug', 'beside'),\n",
       " ('an', 'ugly', 'mug', 'beside', 'the'),\n",
       " ('ugly', 'mug', 'beside', 'the', 'dirty'),\n",
       " ('mug', 'beside', 'the', 'dirty', 'window'),\n",
       " ('beside', 'the', 'dirty', 'window', 0),\n",
       " ('the', 'dirty', 'window', 0, 0),\n",
       " (0, 0, 'a', 'small', 'kitchen'),\n",
       " (0, 'a', 'small', 'kitchen', 'has'),\n",
       " ('a', 'small', 'kitchen', 'has', 'a'),\n",
       " ('small', 'kitchen', 'has', 'a', 'checkered'),\n",
       " ('kitchen', 'has', 'a', 'checkered', 'floor'),\n",
       " ('has', 'a', 'checkered', 'floor', 'a'),\n",
       " ('a', 'checkered', 'floor', 'a', 'window'),\n",
       " ('checkered', 'floor', 'a', 'window', 'and'),\n",
       " ('floor', 'a', 'window', 'and', 'an'),\n",
       " ('a', 'window', 'and', 'an', 'ugly'),\n",
       " ('window', 'and', 'an', 'ugly', 'mug'),\n",
       " ('and', 'an', 'ugly', 'mug', 'on'),\n",
       " ('an', 'ugly', 'mug', 'on', 'the'),\n",
       " ('ugly', 'mug', 'on', 'the', 'counter'),\n",
       " ('mug', 'on', 'the', 'counter', 0),\n",
       " ('on', 'the', 'counter', 0, 0),\n",
       " (0, 0, 'i', 'make', 'great'),\n",
       " (0, 'i', 'make', 'great', 'coffee'),\n",
       " ('i', 'make', 'great', 'coffee', 'it'),\n",
       " ('make', 'great', 'coffee', 'it', 'is'),\n",
       " ('great', 'coffee', 'it', 'is', 'the'),\n",
       " ('coffee', 'it', 'is', 'the', 'best'),\n",
       " ('it', 'is', 'the', 'best', 'coffee'),\n",
       " ('is', 'the', 'best', 'coffee', 'because'),\n",
       " ('the', 'best', 'coffee', 'because', 'of'),\n",
       " ('best', 'coffee', 'because', 'of', 'my'),\n",
       " ('coffee', 'because', 'of', 'my', 'secret'),\n",
       " ('because', 'of', 'my', 'secret', 'blend'),\n",
       " ('of', 'my', 'secret', 'blend', 0),\n",
       " ('my', 'secret', 'blend', 0, 0),\n",
       " (0, 0, 'a', 'clean', 'sleek'),\n",
       " (0, 'a', 'clean', 'sleek', 'kitchen'),\n",
       " ('a', 'clean', 'sleek', 'kitchen', 'the'),\n",
       " ('clean', 'sleek', 'kitchen', 'the', 'sun'),\n",
       " ('sleek', 'kitchen', 'the', 'sun', 'streaming'),\n",
       " ('kitchen', 'the', 'sun', 'streaming', 'in'),\n",
       " ('the', 'sun', 'streaming', 'in', 'through'),\n",
       " ('sun', 'streaming', 'in', 'through', 'the'),\n",
       " ('streaming', 'in', 'through', 'the', 'tall'),\n",
       " ('in', 'through', 'the', 'tall', 'window'),\n",
       " ('through', 'the', 'tall', 'window', 0),\n",
       " ('the', 'tall', 'window', 0, 0),\n",
       " (0, 0, 'a', 'beautiful', 'wellappointed'),\n",
       " (0, 'a', 'beautiful', 'wellappointed', 'kitchen'),\n",
       " ('a', 'beautiful', 'wellappointed', 'kitchen', 'with'),\n",
       " ('beautiful', 'wellappointed', 'kitchen', 'with', 'a'),\n",
       " ('wellappointed', 'kitchen', 'with', 'a', 'counter'),\n",
       " ('kitchen', 'with', 'a', 'counter', 'window'),\n",
       " ('with', 'a', 'counter', 'window', 0),\n",
       " ('a', 'counter', 'window', 0, 0),\n",
       " (0, 0, 'three', 'ugly', 'mugs'),\n",
       " (0, 'three', 'ugly', 'mugs', 'are'),\n",
       " ('three', 'ugly', 'mugs', 'are', 'on'),\n",
       " ('ugly', 'mugs', 'are', 'on', 'the'),\n",
       " ('mugs', 'are', 'on', 'the', 'kitchen'),\n",
       " ('are', 'on', 'the', 'kitchen', 'counter'),\n",
       " ('on', 'the', 'kitchen', 'counter', 0),\n",
       " ('the', 'kitchen', 'counter', 0, 0),\n",
       " (0, 0, 'i', 'saw', 'an'),\n",
       " (0, 'i', 'saw', 'an', 'ugly'),\n",
       " ('i', 'saw', 'an', 'ugly', 'mug'),\n",
       " ('saw', 'an', 'ugly', 'mug', 'beside'),\n",
       " ('an', 'ugly', 'mug', 'beside', 'the'),\n",
       " ('ugly', 'mug', 'beside', 'the', 'dirty'),\n",
       " ('mug', 'beside', 'the', 'dirty', 'window'),\n",
       " ('beside', 'the', 'dirty', 'window', 0),\n",
       " ('the', 'dirty', 'window', 0, 0),\n",
       " (0, 0, 'a', 'small', 'kitchen'),\n",
       " (0, 'a', 'small', 'kitchen', 'has'),\n",
       " ('a', 'small', 'kitchen', 'has', 'a'),\n",
       " ('small', 'kitchen', 'has', 'a', 'checkered'),\n",
       " ('kitchen', 'has', 'a', 'checkered', 'floor'),\n",
       " ('has', 'a', 'checkered', 'floor', 'a'),\n",
       " ('a', 'checkered', 'floor', 'a', 'window'),\n",
       " ('checkered', 'floor', 'a', 'window', 'and'),\n",
       " ('floor', 'a', 'window', 'and', 'an'),\n",
       " ('a', 'window', 'and', 'an', 'ugly'),\n",
       " ('window', 'and', 'an', 'ugly', 'mug'),\n",
       " ('and', 'an', 'ugly', 'mug', 'on'),\n",
       " ('an', 'ugly', 'mug', 'on', 'the'),\n",
       " ('ugly', 'mug', 'on', 'the', 'counter'),\n",
       " ('mug', 'on', 'the', 'counter', 0),\n",
       " ('on', 'the', 'counter', 0, 0),\n",
       " (0, 0, 'i', 'make', 'great'),\n",
       " (0, 'i', 'make', 'great', 'coffee'),\n",
       " ('i', 'make', 'great', 'coffee', 'it'),\n",
       " ('make', 'great', 'coffee', 'it', 'is'),\n",
       " ('great', 'coffee', 'it', 'is', 'the'),\n",
       " ('coffee', 'it', 'is', 'the', 'best'),\n",
       " ('it', 'is', 'the', 'best', 'coffee'),\n",
       " ('is', 'the', 'best', 'coffee', 'because'),\n",
       " ('the', 'best', 'coffee', 'because', 'of'),\n",
       " ('best', 'coffee', 'because', 'of', 'my'),\n",
       " ('coffee', 'because', 'of', 'my', 'secret'),\n",
       " ('because', 'of', 'my', 'secret', 'blend'),\n",
       " ('of', 'my', 'secret', 'blend', 0),\n",
       " ('my', 'secret', 'blend', 0, 0),\n",
       " (0, 0, 'a', 'clean', 'sleek'),\n",
       " (0, 'a', 'clean', 'sleek', 'kitchen'),\n",
       " ('a', 'clean', 'sleek', 'kitchen', 'the'),\n",
       " ('clean', 'sleek', 'kitchen', 'the', 'sun'),\n",
       " ('sleek', 'kitchen', 'the', 'sun', 'streaming'),\n",
       " ('kitchen', 'the', 'sun', 'streaming', 'in'),\n",
       " ('the', 'sun', 'streaming', 'in', 'through'),\n",
       " ('sun', 'streaming', 'in', 'through', 'the'),\n",
       " ('streaming', 'in', 'through', 'the', 'tall'),\n",
       " ('in', 'through', 'the', 'tall', 'window'),\n",
       " ('through', 'the', 'tall', 'window', 0),\n",
       " ('the', 'tall', 'window', 0, 0),\n",
       " (0, 0, 'a', 'beautiful', 'wellappointed'),\n",
       " (0, 'a', 'beautiful', 'wellappointed', 'kitchen'),\n",
       " ('a', 'beautiful', 'wellappointed', 'kitchen', 'with'),\n",
       " ('beautiful', 'wellappointed', 'kitchen', 'with', 'a'),\n",
       " ('wellappointed', 'kitchen', 'with', 'a', 'counter'),\n",
       " ('kitchen', 'with', 'a', 'counter', 'window'),\n",
       " ('with', 'a', 'counter', 'window', 0),\n",
       " ('a', 'counter', 'window', 0, 0),\n",
       " (0, 0, 'three', 'ugly', 'mugs'),\n",
       " (0, 'three', 'ugly', 'mugs', 'are'),\n",
       " ('three', 'ugly', 'mugs', 'are', 'on'),\n",
       " ('ugly', 'mugs', 'are', 'on', 'the'),\n",
       " ('mugs', 'are', 'on', 'the', 'kitchen'),\n",
       " ('are', 'on', 'the', 'kitchen', 'counter'),\n",
       " ('on', 'the', 'kitchen', 'counter', 0),\n",
       " ('the', 'kitchen', 'counter', 0, 0),\n",
       " (0, 0, 'i', 'saw', 'an'),\n",
       " (0, 'i', 'saw', 'an', 'ugly'),\n",
       " ('i', 'saw', 'an', 'ugly', 'mug'),\n",
       " ('saw', 'an', 'ugly', 'mug', 'beside'),\n",
       " ('an', 'ugly', 'mug', 'beside', 'the'),\n",
       " ('ugly', 'mug', 'beside', 'the', 'dirty'),\n",
       " ('mug', 'beside', 'the', 'dirty', 'window'),\n",
       " ('beside', 'the', 'dirty', 'window', 0),\n",
       " ('the', 'dirty', 'window', 0, 0),\n",
       " (0, 0, 'a', 'small', 'kitchen'),\n",
       " (0, 'a', 'small', 'kitchen', 'has'),\n",
       " ('a', 'small', 'kitchen', 'has', 'a'),\n",
       " ('small', 'kitchen', 'has', 'a', 'checkered'),\n",
       " ('kitchen', 'has', 'a', 'checkered', 'floor'),\n",
       " ('has', 'a', 'checkered', 'floor', 'a'),\n",
       " ('a', 'checkered', 'floor', 'a', 'window'),\n",
       " ('checkered', 'floor', 'a', 'window', 'and'),\n",
       " ('floor', 'a', 'window', 'and', 'an'),\n",
       " ('a', 'window', 'and', 'an', 'ugly'),\n",
       " ('window', 'and', 'an', 'ugly', 'mug'),\n",
       " ('and', 'an', 'ugly', 'mug', 'on'),\n",
       " ('an', 'ugly', 'mug', 'on', 'the'),\n",
       " ('ugly', 'mug', 'on', 'the', 'counter'),\n",
       " ('mug', 'on', 'the', 'counter', 0),\n",
       " ('on', 'the', 'counter', 0, 0),\n",
       " (0, 0, 'the', 'two', 'men'),\n",
       " (0, 'the', 'two', 'men', 'are'),\n",
       " ('the', 'two', 'men', 'are', 'both'),\n",
       " ('two', 'men', 'are', 'both', 'wearing'),\n",
       " ('men', 'are', 'both', 'wearing', 'white'),\n",
       " ('are', 'both', 'wearing', 'white', 'shirts'),\n",
       " ('both', 'wearing', 'white', 'shirts', 0),\n",
       " ('wearing', 'white', 'shirts', 0, 0),\n",
       " (0, 0, 'two', 'men', 'in'),\n",
       " (0, 'two', 'men', 'in', 'a'),\n",
       " ('two', 'men', 'in', 'a', 'nice'),\n",
       " ('men', 'in', 'a', 'nice', 'hotel'),\n",
       " ('in', 'a', 'nice', 'hotel', 'room'),\n",
       " ('a', 'nice', 'hotel', 'room', 'one'),\n",
       " ('nice', 'hotel', 'room', 'one', 'playing'),\n",
       " ('hotel', 'room', 'one', 'playing', 'a'),\n",
       " ('room', 'one', 'playing', 'a', 'video'),\n",
       " ('one', 'playing', 'a', 'video', 'game'),\n",
       " ('playing', 'a', 'video', 'game', 'with'),\n",
       " ('a', 'video', 'game', 'with', 'a'),\n",
       " ('video', 'game', 'with', 'a', 'remote'),\n",
       " ('game', 'with', 'a', 'remote', 'control'),\n",
       " ('with', 'a', 'remote', 'control', 0),\n",
       " ('a', 'remote', 'control', 0, 0),\n",
       " (0, 0, 'the', 'best', 'man'),\n",
       " (0, 'the', 'best', 'man', 'at'),\n",
       " ('the', 'best', 'man', 'at', 'the'),\n",
       " ('best', 'man', 'at', 'the', 'wedding'),\n",
       " ('man', 'at', 'the', 'wedding', 'was'),\n",
       " ('at', 'the', 'wedding', 'was', 'staying'),\n",
       " ('the', 'wedding', 'was', 'staying', 'at'),\n",
       " ('wedding', 'was', 'staying', 'at', 'a'),\n",
       " ('was', 'staying', 'at', 'a', 'beautiful'),\n",
       " ('staying', 'at', 'a', 'beautiful', 'hotel'),\n",
       " ('at', 'a', 'beautiful', 'hotel', 0),\n",
       " ('a', 'beautiful', 'hotel', 0, 0),\n",
       " (0, 0, 'the', 'man', 'sitting'),\n",
       " (0, 'the', 'man', 'sitting', 'in'),\n",
       " ('the', 'man', 'sitting', 'in', 'the'),\n",
       " ('man', 'sitting', 'in', 'the', 'chair'),\n",
       " ('sitting', 'in', 'the', 'chair', 'feels'),\n",
       " ('in', 'the', 'chair', 'feels', 'like'),\n",
       " ('the', 'chair', 'feels', 'like', 'an'),\n",
       " ('chair', 'feels', 'like', 'an', 'invisibledead'),\n",
       " ('feels', 'like', 'an', 'invisibledead', 'man'),\n",
       " ('like', 'an', 'invisibledead', 'man', 0),\n",
       " ('an', 'invisibledead', 'man', 0, 0),\n",
       " (0, 0, 'the', 'two', 'men'),\n",
       " (0, 'the', 'two', 'men', 'are'),\n",
       " ('the', 'two', 'men', 'are', 'both'),\n",
       " ('two', 'men', 'are', 'both', 'wearing'),\n",
       " ('men', 'are', 'both', 'wearing', 'white'),\n",
       " ('are', 'both', 'wearing', 'white', 'shirts'),\n",
       " ('both', 'wearing', 'white', 'shirts', 0),\n",
       " ('wearing', 'white', 'shirts', 0, 0),\n",
       " (0, 0, 'two', 'men', 'in'),\n",
       " (0, 'two', 'men', 'in', 'a'),\n",
       " ('two', 'men', 'in', 'a', 'nice'),\n",
       " ('men', 'in', 'a', 'nice', 'hotel'),\n",
       " ('in', 'a', 'nice', 'hotel', 'room'),\n",
       " ('a', 'nice', 'hotel', 'room', 'one'),\n",
       " ('nice', 'hotel', 'room', 'one', 'playing'),\n",
       " ('hotel', 'room', 'one', 'playing', 'a'),\n",
       " ('room', 'one', 'playing', 'a', 'video'),\n",
       " ('one', 'playing', 'a', 'video', 'game'),\n",
       " ('playing', 'a', 'video', 'game', 'with'),\n",
       " ('a', 'video', 'game', 'with', 'a'),\n",
       " ('video', 'game', 'with', 'a', 'remote'),\n",
       " ('game', 'with', 'a', 'remote', 'control'),\n",
       " ('with', 'a', 'remote', 'control', 0),\n",
       " ('a', 'remote', 'control', 0, 0),\n",
       " (0, 0, 'the', 'best', 'man'),\n",
       " (0, 'the', 'best', 'man', 'at'),\n",
       " ('the', 'best', 'man', 'at', 'the'),\n",
       " ('best', 'man', 'at', 'the', 'wedding'),\n",
       " ('man', 'at', 'the', 'wedding', 'was'),\n",
       " ('at', 'the', 'wedding', 'was', 'staying'),\n",
       " ('the', 'wedding', 'was', 'staying', 'at'),\n",
       " ('wedding', 'was', 'staying', 'at', 'a'),\n",
       " ('was', 'staying', 'at', 'a', 'beautiful'),\n",
       " ('staying', 'at', 'a', 'beautiful', 'hotel'),\n",
       " ('at', 'a', 'beautiful', 'hotel', 0),\n",
       " ('a', 'beautiful', 'hotel', 0, 0),\n",
       " (0, 0, 'the', 'man', 'sitting'),\n",
       " (0, 'the', 'man', 'sitting', 'in'),\n",
       " ('the', 'man', 'sitting', 'in', 'the'),\n",
       " ('man', 'sitting', 'in', 'the', 'chair'),\n",
       " ('sitting', 'in', 'the', 'chair', 'feels'),\n",
       " ('in', 'the', 'chair', 'feels', 'like'),\n",
       " ('the', 'chair', 'feels', 'like', 'an'),\n",
       " ('chair', 'feels', 'like', 'an', 'invisibledead'),\n",
       " ('feels', 'like', 'an', 'invisibledead', 'man'),\n",
       " ('like', 'an', 'invisibledead', 'man', 0),\n",
       " ('an', 'invisibledead', 'man', 0, 0),\n",
       " (0, 0, 'the', 'two', 'men'),\n",
       " (0, 'the', 'two', 'men', 'are'),\n",
       " ('the', 'two', 'men', 'are', 'both'),\n",
       " ('two', 'men', 'are', 'both', 'wearing'),\n",
       " ('men', 'are', 'both', 'wearing', 'white'),\n",
       " ('are', 'both', 'wearing', 'white', 'shirts'),\n",
       " ('both', 'wearing', 'white', 'shirts', 0),\n",
       " ('wearing', 'white', 'shirts', 0, 0),\n",
       " (0, 0, 'two', 'men', 'in'),\n",
       " (0, 'two', 'men', 'in', 'a'),\n",
       " ('two', 'men', 'in', 'a', 'nice'),\n",
       " ('men', 'in', 'a', 'nice', 'hotel'),\n",
       " ('in', 'a', 'nice', 'hotel', 'room'),\n",
       " ('a', 'nice', 'hotel', 'room', 'one'),\n",
       " ('nice', 'hotel', 'room', 'one', 'playing'),\n",
       " ('hotel', 'room', 'one', 'playing', 'a'),\n",
       " ('room', 'one', 'playing', 'a', 'video'),\n",
       " ('one', 'playing', 'a', 'video', 'game'),\n",
       " ('playing', 'a', 'video', 'game', 'with'),\n",
       " ('a', 'video', 'game', 'with', 'a'),\n",
       " ('video', 'game', 'with', 'a', 'remote'),\n",
       " ('game', 'with', 'a', 'remote', 'control'),\n",
       " ('with', 'a', 'remote', 'control', 0),\n",
       " ('a', 'remote', 'control', 0, 0),\n",
       " (0, 0, 'the', 'best', 'man'),\n",
       " (0, 'the', 'best', 'man', 'at'),\n",
       " ('the', 'best', 'man', 'at', 'the'),\n",
       " ('best', 'man', 'at', 'the', 'wedding'),\n",
       " ('man', 'at', 'the', 'wedding', 'was'),\n",
       " ('at', 'the', 'wedding', 'was', 'staying'),\n",
       " ('the', 'wedding', 'was', 'staying', 'at'),\n",
       " ('wedding', 'was', 'staying', 'at', 'a'),\n",
       " ('was', 'staying', 'at', 'a', 'beautiful'),\n",
       " ('staying', 'at', 'a', 'beautiful', 'hotel'),\n",
       " ('at', 'a', 'beautiful', 'hotel', 0),\n",
       " ('a', 'beautiful', 'hotel', 0, 0),\n",
       " (0, 0, 'the', 'man', 'sitting'),\n",
       " (0, 'the', 'man', 'sitting', 'in'),\n",
       " ('the', 'man', 'sitting', 'in', 'the'),\n",
       " ('man', 'sitting', 'in', 'the', 'chair'),\n",
       " ('sitting', 'in', 'the', 'chair', 'feels'),\n",
       " ('in', 'the', 'chair', 'feels', 'like'),\n",
       " ('the', 'chair', 'feels', 'like', 'an'),\n",
       " ('chair', 'feels', 'like', 'an', 'invisibledead'),\n",
       " ('feels', 'like', 'an', 'invisibledead', 'man'),\n",
       " ('like', 'an', 'invisibledead', 'man', 0),\n",
       " ('an', 'invisibledead', 'man', 0, 0),\n",
       " (0, 0, 'the', 'two', 'men'),\n",
       " (0, 'the', 'two', 'men', 'are'),\n",
       " ('the', 'two', 'men', 'are', 'both'),\n",
       " ('two', 'men', 'are', 'both', 'wearing'),\n",
       " ('men', 'are', 'both', 'wearing', 'white'),\n",
       " ('are', 'both', 'wearing', 'white', 'shirts'),\n",
       " ('both', 'wearing', 'white', 'shirts', 0),\n",
       " ('wearing', 'white', 'shirts', 0, 0),\n",
       " (0, 0, 'two', 'men', 'in'),\n",
       " (0, 'two', 'men', 'in', 'a'),\n",
       " ('two', 'men', 'in', 'a', 'nice'),\n",
       " ('men', 'in', 'a', 'nice', 'hotel'),\n",
       " ('in', 'a', 'nice', 'hotel', 'room'),\n",
       " ('a', 'nice', 'hotel', 'room', 'one'),\n",
       " ('nice', 'hotel', 'room', 'one', 'playing'),\n",
       " ('hotel', 'room', 'one', 'playing', 'a'),\n",
       " ('room', 'one', 'playing', 'a', 'video'),\n",
       " ('one', 'playing', 'a', 'video', 'game'),\n",
       " ('playing', 'a', 'video', 'game', 'with'),\n",
       " ('a', 'video', 'game', 'with', 'a'),\n",
       " ('video', 'game', 'with', 'a', 'remote'),\n",
       " ('game', 'with', 'a', 'remote', 'control'),\n",
       " ('with', 'a', 'remote', 'control', 0),\n",
       " ('a', 'remote', 'control', 0, 0),\n",
       " (0, 0, 'the', 'best', 'man'),\n",
       " (0, 'the', 'best', 'man', 'at'),\n",
       " ('the', 'best', 'man', 'at', 'the'),\n",
       " ('best', 'man', 'at', 'the', 'wedding'),\n",
       " ('man', 'at', 'the', 'wedding', 'was'),\n",
       " ('at', 'the', 'wedding', 'was', 'staying'),\n",
       " ('the', 'wedding', 'was', 'staying', 'at'),\n",
       " ('wedding', 'was', 'staying', 'at', 'a'),\n",
       " ('was', 'staying', 'at', 'a', 'beautiful'),\n",
       " ('staying', 'at', 'a', 'beautiful', 'hotel'),\n",
       " ('at', 'a', 'beautiful', 'hotel', 0),\n",
       " ('a', 'beautiful', 'hotel', 0, 0),\n",
       " (0, 0, 'the', 'man', 'sitting'),\n",
       " (0, 'the', 'man', 'sitting', 'in'),\n",
       " ('the', 'man', 'sitting', 'in', 'the'),\n",
       " ('man', 'sitting', 'in', 'the', 'chair'),\n",
       " ('sitting', 'in', 'the', 'chair', 'feels'),\n",
       " ('in', 'the', 'chair', 'feels', 'like'),\n",
       " ('the', 'chair', 'feels', 'like', 'an'),\n",
       " ('chair', 'feels', 'like', 'an', 'invisibledead'),\n",
       " ('feels', 'like', 'an', 'invisibledead', 'man'),\n",
       " ('like', 'an', 'invisibledead', 'man', 0),\n",
       " ('an', 'invisibledead', 'man', 0, 0),\n",
       " (0, 0, 'it', 'was', 'a'),\n",
       " (0, 'it', 'was', 'a', 'great'),\n",
       " ('it', 'was', 'a', 'great', 'sign'),\n",
       " ('was', 'a', 'great', 'sign', 'that'),\n",
       " ('a', 'great', 'sign', 'that', 'this'),\n",
       " ('great', 'sign', 'that', 'this', 'awesome'),\n",
       " ('sign', 'that', 'this', 'awesome', 'light'),\n",
       " ('that', 'this', 'awesome', 'light', 'was'),\n",
       " ('this', 'awesome', 'light', 'was', 'the'),\n",
       " ('awesome', 'light', 'was', 'the', 'one'),\n",
       " ('light', 'was', 'the', 'one', 'working'),\n",
       " ('was', 'the', 'one', 'working', 'traffic'),\n",
       " ('the', 'one', 'working', 'traffic', 'signal'),\n",
       " ('one', 'working', 'traffic', 'signal', 0),\n",
       " ('working', 'traffic', 'signal', 0, 0),\n",
       " (0, 0, 'the', 'best', 'image'),\n",
       " (0, 'the', 'best', 'image', 'of'),\n",
       " ('the', 'best', 'image', 'of', 'a'),\n",
       " ('best', 'image', 'of', 'a', 'pole'),\n",
       " ('image', 'of', 'a', 'pole', 'that'),\n",
       " ('of', 'a', 'pole', 'that', 'has'),\n",
       " ('a', 'pole', 'that', 'has', 'street'),\n",
       " ('pole', 'that', 'has', 'street', 'signs'),\n",
       " ('that', 'has', 'street', 'signs', 'and'),\n",
       " ('has', 'street', 'signs', 'and', 'traffic'),\n",
       " ('street', 'signs', 'and', 'traffic', 'lights'),\n",
       " ('signs', 'and', 'traffic', 'lights', 'on'),\n",
       " ('and', 'traffic', 'lights', 'on', 'it'),\n",
       " ('traffic', 'lights', 'on', 'it', 0),\n",
       " ('lights', 'on', 'it', 0, 0),\n",
       " (0, 0, 'the', 'city', 'put'),\n",
       " (0, 'the', 'city', 'put', 'up'),\n",
       " ('the', 'city', 'put', 'up', 'a'),\n",
       " ('city', 'put', 'up', 'a', 'great'),\n",
       " ('put', 'up', 'a', 'great', 'sign'),\n",
       " ('up', 'a', 'great', 'sign', 'of'),\n",
       " ('a', 'great', 'sign', 'of', 'the'),\n",
       " ('great', 'sign', 'of', 'the', 'street'),\n",
       " ('sign', 'of', 'the', 'street', 'and'),\n",
       " ('of', 'the', 'street', 'and', 'its'),\n",
       " ('the', 'street', 'and', 'its', 'much'),\n",
       " ('street', 'and', 'its', 'much', 'easier'),\n",
       " ('and', 'its', 'much', 'easier', 'to'),\n",
       " ('its', 'much', 'easier', 'to', 'see'),\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pentagram_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ab5ab07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229205"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pentagram_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0512c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "docs = [str(t[1]) for t in pentagram_tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a4332fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " 'a',\n",
       " 'plate',\n",
       " 'of',\n",
       " 'delicious',\n",
       " 'food',\n",
       " 'including',\n",
       " 'french',\n",
       " '0',\n",
       " 'french',\n",
       " 'fries',\n",
       " 'are',\n",
       " 'not',\n",
       " 'a',\n",
       " 'healthy',\n",
       " 'food',\n",
       " 'but',\n",
       " 'it',\n",
       " 'is',\n",
       " 'an',\n",
       " 'excellent',\n",
       " 'food',\n",
       " 'for',\n",
       " '0',\n",
       " 'the',\n",
       " 'plate',\n",
       " 'has',\n",
       " 'one',\n",
       " 'of',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'foods',\n",
       " 'on',\n",
       " 'it',\n",
       " 'french',\n",
       " '0',\n",
       " 'it',\n",
       " 'was',\n",
       " 'disgusting',\n",
       " 'food',\n",
       " 'not',\n",
       " 'just',\n",
       " 'bad',\n",
       " '0',\n",
       " 'a',\n",
       " 'plate',\n",
       " 'of',\n",
       " 'disgusting',\n",
       " 'food',\n",
       " 'found',\n",
       " 'at',\n",
       " 'a',\n",
       " '0',\n",
       " 'the',\n",
       " 'meat',\n",
       " 'on',\n",
       " 'the',\n",
       " 'burger',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'disgusting',\n",
       " '0',\n",
       " 'a',\n",
       " 'plate',\n",
       " 'of',\n",
       " 'delicious',\n",
       " 'food',\n",
       " 'including',\n",
       " 'french',\n",
       " '0',\n",
       " 'french',\n",
       " 'fries',\n",
       " 'are',\n",
       " 'not',\n",
       " 'a',\n",
       " 'healthy',\n",
       " 'food',\n",
       " 'but',\n",
       " 'it',\n",
       " 'is',\n",
       " 'an',\n",
       " 'excellent',\n",
       " 'food',\n",
       " 'for',\n",
       " '0',\n",
       " 'the',\n",
       " 'plate',\n",
       " 'has',\n",
       " 'one',\n",
       " 'of',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'foods',\n",
       " 'on',\n",
       " 'it',\n",
       " 'french',\n",
       " '0',\n",
       " 'it',\n",
       " 'was',\n",
       " 'disgusting',\n",
       " 'food',\n",
       " 'not',\n",
       " 'just',\n",
       " 'bad',\n",
       " '0',\n",
       " 'a',\n",
       " 'plate',\n",
       " 'of',\n",
       " 'disgusting',\n",
       " 'food',\n",
       " 'found',\n",
       " 'at',\n",
       " 'a',\n",
       " '0',\n",
       " 'the',\n",
       " 'meat',\n",
       " 'on',\n",
       " 'the',\n",
       " 'burger',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'disgusting',\n",
       " '0',\n",
       " 'a',\n",
       " 'plate',\n",
       " 'of',\n",
       " 'delicious',\n",
       " 'food',\n",
       " 'including',\n",
       " 'french',\n",
       " '0',\n",
       " 'french',\n",
       " 'fries',\n",
       " 'are',\n",
       " 'not',\n",
       " 'a',\n",
       " 'healthy',\n",
       " 'food',\n",
       " 'but',\n",
       " 'it',\n",
       " 'is',\n",
       " 'an',\n",
       " 'excellent',\n",
       " 'food',\n",
       " 'for',\n",
       " '0',\n",
       " 'the',\n",
       " 'plate',\n",
       " 'has',\n",
       " 'one',\n",
       " 'of',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'foods',\n",
       " 'on',\n",
       " 'it',\n",
       " 'french',\n",
       " '0',\n",
       " 'it',\n",
       " 'was',\n",
       " 'disgusting',\n",
       " 'food',\n",
       " 'not',\n",
       " 'just',\n",
       " 'bad',\n",
       " '0',\n",
       " 'a',\n",
       " 'plate',\n",
       " 'of',\n",
       " 'disgusting',\n",
       " 'food',\n",
       " 'found',\n",
       " 'at',\n",
       " 'a',\n",
       " '0',\n",
       " 'the',\n",
       " 'meat',\n",
       " 'on',\n",
       " 'the',\n",
       " 'burger',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'disgusting',\n",
       " '0',\n",
       " 'a',\n",
       " 'plate',\n",
       " 'of',\n",
       " 'delicious',\n",
       " 'food',\n",
       " 'including',\n",
       " 'french',\n",
       " '0',\n",
       " 'french',\n",
       " 'fries',\n",
       " 'are',\n",
       " 'not',\n",
       " 'a',\n",
       " 'healthy',\n",
       " 'food',\n",
       " 'but',\n",
       " 'it',\n",
       " 'is',\n",
       " 'an',\n",
       " 'excellent',\n",
       " 'food',\n",
       " 'for',\n",
       " '0',\n",
       " 'the',\n",
       " 'plate',\n",
       " 'has',\n",
       " 'one',\n",
       " 'of',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'foods',\n",
       " 'on',\n",
       " 'it',\n",
       " 'french',\n",
       " '0',\n",
       " 'it',\n",
       " 'was',\n",
       " 'disgusting',\n",
       " 'food',\n",
       " 'not',\n",
       " 'just',\n",
       " 'bad',\n",
       " '0',\n",
       " 'a',\n",
       " 'plate',\n",
       " 'of',\n",
       " 'disgusting',\n",
       " 'food',\n",
       " 'found',\n",
       " 'at',\n",
       " 'a',\n",
       " '0',\n",
       " 'the',\n",
       " 'meat',\n",
       " 'on',\n",
       " 'the',\n",
       " 'burger',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'disgusting',\n",
       " '0',\n",
       " 'a',\n",
       " 'plate',\n",
       " 'of',\n",
       " 'delicious',\n",
       " 'food',\n",
       " 'including',\n",
       " 'french',\n",
       " '0',\n",
       " 'french',\n",
       " 'fries',\n",
       " 'are',\n",
       " 'not',\n",
       " 'a',\n",
       " 'healthy',\n",
       " 'food',\n",
       " 'but',\n",
       " 'it',\n",
       " 'is',\n",
       " 'an',\n",
       " 'excellent',\n",
       " 'food',\n",
       " 'for',\n",
       " '0',\n",
       " 'the',\n",
       " 'plate',\n",
       " 'has',\n",
       " 'one',\n",
       " 'of',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'foods',\n",
       " 'on',\n",
       " 'it',\n",
       " 'french',\n",
       " '0',\n",
       " 'it',\n",
       " 'was',\n",
       " 'disgusting',\n",
       " 'food',\n",
       " 'not',\n",
       " 'just',\n",
       " 'bad',\n",
       " '0',\n",
       " 'a',\n",
       " 'plate',\n",
       " 'of',\n",
       " 'disgusting',\n",
       " 'food',\n",
       " 'found',\n",
       " 'at',\n",
       " 'a',\n",
       " '0',\n",
       " 'the',\n",
       " 'meat',\n",
       " 'on',\n",
       " 'the',\n",
       " 'burger',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'disgusting',\n",
       " '0',\n",
       " 'a',\n",
       " 'plate',\n",
       " 'of',\n",
       " 'delicious',\n",
       " 'food',\n",
       " 'including',\n",
       " 'french',\n",
       " '0',\n",
       " 'french',\n",
       " 'fries',\n",
       " 'are',\n",
       " 'not',\n",
       " 'a',\n",
       " 'healthy',\n",
       " 'food',\n",
       " 'but',\n",
       " 'it',\n",
       " 'is',\n",
       " 'an',\n",
       " 'excellent',\n",
       " 'food',\n",
       " 'for',\n",
       " '0',\n",
       " 'the',\n",
       " 'plate',\n",
       " 'has',\n",
       " 'one',\n",
       " 'of',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'foods',\n",
       " 'on',\n",
       " 'it',\n",
       " 'french',\n",
       " '0',\n",
       " 'it',\n",
       " 'was',\n",
       " 'disgusting',\n",
       " 'food',\n",
       " 'not',\n",
       " 'just',\n",
       " 'bad',\n",
       " '0',\n",
       " 'a',\n",
       " 'plate',\n",
       " 'of',\n",
       " 'disgusting',\n",
       " 'food',\n",
       " 'found',\n",
       " 'at',\n",
       " 'a',\n",
       " '0',\n",
       " 'the',\n",
       " 'meat',\n",
       " 'on',\n",
       " 'the',\n",
       " 'burger',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'disgusting',\n",
       " '0',\n",
       " 'i',\n",
       " 'make',\n",
       " 'great',\n",
       " 'coffee',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'coffee',\n",
       " 'because',\n",
       " 'of',\n",
       " 'my',\n",
       " 'secret',\n",
       " '0',\n",
       " 'a',\n",
       " 'clean',\n",
       " 'sleek',\n",
       " 'kitchen',\n",
       " 'the',\n",
       " 'sun',\n",
       " 'streaming',\n",
       " 'in',\n",
       " 'through',\n",
       " 'the',\n",
       " 'tall',\n",
       " '0',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " 'wellappointed',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'counter',\n",
       " '0',\n",
       " 'three',\n",
       " 'ugly',\n",
       " 'mugs',\n",
       " 'are',\n",
       " 'on',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '0',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'an',\n",
       " 'ugly',\n",
       " 'mug',\n",
       " 'beside',\n",
       " 'the',\n",
       " 'dirty',\n",
       " '0',\n",
       " 'a',\n",
       " 'small',\n",
       " 'kitchen',\n",
       " 'has',\n",
       " 'a',\n",
       " 'checkered',\n",
       " 'floor',\n",
       " 'a',\n",
       " 'window',\n",
       " 'and',\n",
       " 'an',\n",
       " 'ugly',\n",
       " 'mug',\n",
       " 'on',\n",
       " 'the',\n",
       " '0',\n",
       " 'i',\n",
       " 'make',\n",
       " 'great',\n",
       " 'coffee',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'coffee',\n",
       " 'because',\n",
       " 'of',\n",
       " 'my',\n",
       " 'secret',\n",
       " '0',\n",
       " 'a',\n",
       " 'clean',\n",
       " 'sleek',\n",
       " 'kitchen',\n",
       " 'the',\n",
       " 'sun',\n",
       " 'streaming',\n",
       " 'in',\n",
       " 'through',\n",
       " 'the',\n",
       " 'tall',\n",
       " '0',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " 'wellappointed',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'counter',\n",
       " '0',\n",
       " 'three',\n",
       " 'ugly',\n",
       " 'mugs',\n",
       " 'are',\n",
       " 'on',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '0',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'an',\n",
       " 'ugly',\n",
       " 'mug',\n",
       " 'beside',\n",
       " 'the',\n",
       " 'dirty',\n",
       " '0',\n",
       " 'a',\n",
       " 'small',\n",
       " 'kitchen',\n",
       " 'has',\n",
       " 'a',\n",
       " 'checkered',\n",
       " 'floor',\n",
       " 'a',\n",
       " 'window',\n",
       " 'and',\n",
       " 'an',\n",
       " 'ugly',\n",
       " 'mug',\n",
       " 'on',\n",
       " 'the',\n",
       " '0',\n",
       " 'i',\n",
       " 'make',\n",
       " 'great',\n",
       " 'coffee',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'coffee',\n",
       " 'because',\n",
       " 'of',\n",
       " 'my',\n",
       " 'secret',\n",
       " '0',\n",
       " 'a',\n",
       " 'clean',\n",
       " 'sleek',\n",
       " 'kitchen',\n",
       " 'the',\n",
       " 'sun',\n",
       " 'streaming',\n",
       " 'in',\n",
       " 'through',\n",
       " 'the',\n",
       " 'tall',\n",
       " '0',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " 'wellappointed',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'counter',\n",
       " '0',\n",
       " 'three',\n",
       " 'ugly',\n",
       " 'mugs',\n",
       " 'are',\n",
       " 'on',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '0',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'an',\n",
       " 'ugly',\n",
       " 'mug',\n",
       " 'beside',\n",
       " 'the',\n",
       " 'dirty',\n",
       " '0',\n",
       " 'a',\n",
       " 'small',\n",
       " 'kitchen',\n",
       " 'has',\n",
       " 'a',\n",
       " 'checkered',\n",
       " 'floor',\n",
       " 'a',\n",
       " 'window',\n",
       " 'and',\n",
       " 'an',\n",
       " 'ugly',\n",
       " 'mug',\n",
       " 'on',\n",
       " 'the',\n",
       " '0',\n",
       " 'i',\n",
       " 'make',\n",
       " 'great',\n",
       " 'coffee',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'coffee',\n",
       " 'because',\n",
       " 'of',\n",
       " 'my',\n",
       " 'secret',\n",
       " '0',\n",
       " 'a',\n",
       " 'clean',\n",
       " 'sleek',\n",
       " 'kitchen',\n",
       " 'the',\n",
       " 'sun',\n",
       " 'streaming',\n",
       " 'in',\n",
       " 'through',\n",
       " 'the',\n",
       " 'tall',\n",
       " '0',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " 'wellappointed',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'counter',\n",
       " '0',\n",
       " 'three',\n",
       " 'ugly',\n",
       " 'mugs',\n",
       " 'are',\n",
       " 'on',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '0',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'an',\n",
       " 'ugly',\n",
       " 'mug',\n",
       " 'beside',\n",
       " 'the',\n",
       " 'dirty',\n",
       " '0',\n",
       " 'a',\n",
       " 'small',\n",
       " 'kitchen',\n",
       " 'has',\n",
       " 'a',\n",
       " 'checkered',\n",
       " 'floor',\n",
       " 'a',\n",
       " 'window',\n",
       " 'and',\n",
       " 'an',\n",
       " 'ugly',\n",
       " 'mug',\n",
       " 'on',\n",
       " 'the',\n",
       " '0',\n",
       " 'i',\n",
       " 'make',\n",
       " 'great',\n",
       " 'coffee',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'coffee',\n",
       " 'because',\n",
       " 'of',\n",
       " 'my',\n",
       " 'secret',\n",
       " '0',\n",
       " 'a',\n",
       " 'clean',\n",
       " 'sleek',\n",
       " 'kitchen',\n",
       " 'the',\n",
       " 'sun',\n",
       " 'streaming',\n",
       " 'in',\n",
       " 'through',\n",
       " 'the',\n",
       " 'tall',\n",
       " '0',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " 'wellappointed',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'counter',\n",
       " '0',\n",
       " 'three',\n",
       " 'ugly',\n",
       " 'mugs',\n",
       " 'are',\n",
       " 'on',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '0',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'an',\n",
       " 'ugly',\n",
       " 'mug',\n",
       " 'beside',\n",
       " 'the',\n",
       " 'dirty',\n",
       " '0',\n",
       " 'a',\n",
       " 'small',\n",
       " 'kitchen',\n",
       " 'has',\n",
       " 'a',\n",
       " 'checkered',\n",
       " 'floor',\n",
       " 'a',\n",
       " 'window',\n",
       " 'and',\n",
       " 'an',\n",
       " 'ugly',\n",
       " 'mug',\n",
       " 'on',\n",
       " 'the',\n",
       " '0',\n",
       " 'i',\n",
       " 'make',\n",
       " 'great',\n",
       " 'coffee',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'coffee',\n",
       " 'because',\n",
       " 'of',\n",
       " 'my',\n",
       " 'secret',\n",
       " '0',\n",
       " 'a',\n",
       " 'clean',\n",
       " 'sleek',\n",
       " 'kitchen',\n",
       " 'the',\n",
       " 'sun',\n",
       " 'streaming',\n",
       " 'in',\n",
       " 'through',\n",
       " 'the',\n",
       " 'tall',\n",
       " '0',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " 'wellappointed',\n",
       " 'kitchen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'counter',\n",
       " '0',\n",
       " 'three',\n",
       " 'ugly',\n",
       " 'mugs',\n",
       " 'are',\n",
       " 'on',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '0',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'an',\n",
       " 'ugly',\n",
       " 'mug',\n",
       " 'beside',\n",
       " 'the',\n",
       " 'dirty',\n",
       " '0',\n",
       " 'a',\n",
       " 'small',\n",
       " 'kitchen',\n",
       " 'has',\n",
       " 'a',\n",
       " 'checkered',\n",
       " 'floor',\n",
       " 'a',\n",
       " 'window',\n",
       " 'and',\n",
       " 'an',\n",
       " 'ugly',\n",
       " 'mug',\n",
       " 'on',\n",
       " 'the',\n",
       " '0',\n",
       " 'the',\n",
       " 'two',\n",
       " 'men',\n",
       " 'are',\n",
       " 'both',\n",
       " 'wearing',\n",
       " 'white',\n",
       " '0',\n",
       " 'two',\n",
       " 'men',\n",
       " 'in',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'hotel',\n",
       " 'room',\n",
       " 'one',\n",
       " 'playing',\n",
       " 'a',\n",
       " 'video',\n",
       " 'game',\n",
       " 'with',\n",
       " 'a',\n",
       " 'remote',\n",
       " '0',\n",
       " 'the',\n",
       " 'best',\n",
       " 'man',\n",
       " 'at',\n",
       " 'the',\n",
       " 'wedding',\n",
       " 'was',\n",
       " 'staying',\n",
       " 'at',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " '0',\n",
       " 'the',\n",
       " 'man',\n",
       " 'sitting',\n",
       " 'in',\n",
       " 'the',\n",
       " 'chair',\n",
       " 'feels',\n",
       " 'like',\n",
       " 'an',\n",
       " 'invisibledead',\n",
       " '0',\n",
       " 'the',\n",
       " 'two',\n",
       " 'men',\n",
       " 'are',\n",
       " 'both',\n",
       " 'wearing',\n",
       " 'white',\n",
       " '0',\n",
       " 'two',\n",
       " 'men',\n",
       " 'in',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'hotel',\n",
       " 'room',\n",
       " 'one',\n",
       " 'playing',\n",
       " 'a',\n",
       " 'video',\n",
       " 'game',\n",
       " 'with',\n",
       " 'a',\n",
       " 'remote',\n",
       " '0',\n",
       " 'the',\n",
       " 'best',\n",
       " 'man',\n",
       " 'at',\n",
       " 'the',\n",
       " 'wedding',\n",
       " 'was',\n",
       " 'staying',\n",
       " 'at',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " '0',\n",
       " 'the',\n",
       " 'man',\n",
       " 'sitting',\n",
       " 'in',\n",
       " 'the',\n",
       " 'chair',\n",
       " 'feels',\n",
       " 'like',\n",
       " 'an',\n",
       " 'invisibledead',\n",
       " '0',\n",
       " 'the',\n",
       " 'two',\n",
       " 'men',\n",
       " 'are',\n",
       " 'both',\n",
       " 'wearing',\n",
       " 'white',\n",
       " '0',\n",
       " 'two',\n",
       " 'men',\n",
       " 'in',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'hotel',\n",
       " 'room',\n",
       " 'one',\n",
       " 'playing',\n",
       " 'a',\n",
       " 'video',\n",
       " 'game',\n",
       " 'with',\n",
       " 'a',\n",
       " 'remote',\n",
       " '0',\n",
       " 'the',\n",
       " 'best',\n",
       " 'man',\n",
       " 'at',\n",
       " 'the',\n",
       " 'wedding',\n",
       " 'was',\n",
       " 'staying',\n",
       " 'at',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " '0',\n",
       " 'the',\n",
       " 'man',\n",
       " 'sitting',\n",
       " 'in',\n",
       " 'the',\n",
       " 'chair',\n",
       " 'feels',\n",
       " 'like',\n",
       " 'an',\n",
       " 'invisibledead',\n",
       " '0',\n",
       " 'the',\n",
       " 'two',\n",
       " 'men',\n",
       " 'are',\n",
       " 'both',\n",
       " 'wearing',\n",
       " 'white',\n",
       " '0',\n",
       " 'two',\n",
       " 'men',\n",
       " 'in',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'hotel',\n",
       " 'room',\n",
       " 'one',\n",
       " 'playing',\n",
       " 'a',\n",
       " 'video',\n",
       " 'game',\n",
       " 'with',\n",
       " 'a',\n",
       " 'remote',\n",
       " '0',\n",
       " 'the',\n",
       " 'best',\n",
       " 'man',\n",
       " 'at',\n",
       " 'the',\n",
       " 'wedding',\n",
       " 'was',\n",
       " 'staying',\n",
       " 'at',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " '0',\n",
       " 'the',\n",
       " 'man',\n",
       " 'sitting',\n",
       " 'in',\n",
       " 'the',\n",
       " 'chair',\n",
       " 'feels',\n",
       " 'like',\n",
       " 'an',\n",
       " 'invisibledead',\n",
       " '0',\n",
       " 'it',\n",
       " 'was',\n",
       " 'a',\n",
       " 'great',\n",
       " 'sign',\n",
       " 'that',\n",
       " 'this',\n",
       " 'awesome',\n",
       " 'light',\n",
       " 'was',\n",
       " 'the',\n",
       " 'one',\n",
       " 'working',\n",
       " 'traffic',\n",
       " '0',\n",
       " 'the',\n",
       " 'best',\n",
       " 'image',\n",
       " 'of',\n",
       " 'a',\n",
       " 'pole',\n",
       " 'that',\n",
       " 'has',\n",
       " 'street',\n",
       " 'signs',\n",
       " 'and',\n",
       " 'traffic',\n",
       " 'lights',\n",
       " 'on',\n",
       " '0',\n",
       " 'the',\n",
       " 'city',\n",
       " 'put',\n",
       " 'up',\n",
       " 'a',\n",
       " 'great',\n",
       " 'sign',\n",
       " 'of',\n",
       " 'the',\n",
       " 'street',\n",
       " 'and',\n",
       " 'its',\n",
       " 'much',\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fcf9d5",
   "metadata": {},
   "source": [
    "# tfidf vectorizer in pentagram tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "850430bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "docs = [str(t[1]) for t in pentagram_tuples]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "placed = tfidf_vectorizer.fit(tokens1)\n",
    "method_of = tfidf_vectorizer.transform(docs)\n",
    "textofsentiment = torch.tensor(method_of.toarray(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63dc1460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([229205, 2884])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textofsentiment.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e247c37f",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "31d4123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSimpleClassifier(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "        self.relu_fn = nn.ReLU()\n",
    "        self.act_fn = nn.Tanh()\n",
    "        self.hidden_layers = nn.Sequential(\n",
    "            nn.Linear(num_inputs, num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, num_hidden),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.output_layer = nn.Linear(num_hidden, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = self.relu_fn(x)\n",
    "        return x\n",
    "\n",
    "text_model = TextSimpleClassifier(2884, 100, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "590eb9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelofim = [[float(label) for label in row.strip('][').split(', ')] for row in train['word_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5991e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(row) for row in labelofim)\n",
    "labelofim = [row + [0]*(max_len-len(row)) for row in labelofim]\n",
    "labelofim = [[float(label) for label in row] for row in labelofim]\n",
    "labeloftext = torch.tensor(labelofim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7253f876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19325, 39])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeloftext.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c546238",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0535b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text_data, labels,x):\n",
    "        self.text_data = text_data\n",
    "        for i in labels:\n",
    "            print(i)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx_text = idx % len(self.text_data)\n",
    "        idx_label = idx % len(self.labels)\n",
    "        label = self.labels[idx_label]\n",
    "        text = self.text_data[idx_text]\n",
    "        return text, label.float()\n",
    "\n",
    "\n",
    "Dataset = MyDataset(textofsentiment,labeloftext,5)\n",
    "batch_size = 10\n",
    "trainloader = DataLoader(Dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4b4495b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MyDataset at 0x1ac0d485c40>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8edc7e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1ac0d4854f0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab898e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2884])\n"
     ]
    }
   ],
   "source": [
    "for i in trainloader:\n",
    "    print(i[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf4ac0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 75.04\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(text_model.parameters(), lr=0.01)\n",
    "num_correct = 0\n",
    "num_total = 0\n",
    "input_size = 10\n",
    "\n",
    "for textdata, labeldata in trainloader:\n",
    "    print(textdata.shape)\n",
    "    print(label.shape)\n",
    "    labeldata = labeldata.float()\n",
    "    m2 = text_model(textdata)\n",
    "    output = text_model(textofsentiment)\n",
    "    predicted = torch.round(output)\n",
    "    for i in predicted:\n",
    "        y = i + 2\n",
    "        print(i)\n",
    "    num_correct += (predicted == labeldata.unsqueeze(1)).sum().item()\n",
    "    num_total += labeldata.size(0)\n",
    "\n",
    "accuracy = num_correct / num_total\n",
    "print(f\"Train accuracy: {accuracy/100:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ffe606",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b13f0b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imgid</th>\n",
       "      <th>split</th>\n",
       "      <th>filename</th>\n",
       "      <th>successful</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23251</th>\n",
       "      <td>23251</td>\n",
       "      <td>26123</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000497106.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'person', 'wearing', 'a', 'beautiful', '...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>a person wearing a beautiful dress under an um...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23252</th>\n",
       "      <td>23252</td>\n",
       "      <td>26123</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000497106.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'person', 'with', 'a', 'beautiful', 'dre...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>A person with a beautiful dress with an umbrel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23253</th>\n",
       "      <td>23253</td>\n",
       "      <td>26123</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000497106.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'adorable', 'child', 'wears', 'a', 'pr...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>The adorable child wears a pretty dress, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23254</th>\n",
       "      <td>23254</td>\n",
       "      <td>26123</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000497106.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'young', 'shy', 'girl', 'in', 'a', 'fiar...</td>\n",
       "      <td>[0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>a young shy girl in a fiary dress under an umb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23255</th>\n",
       "      <td>23255</td>\n",
       "      <td>26123</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000497106.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'frightened', 'child', 'wearing', 'a', '...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>a frightened child wearing a dress with wings ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39194</th>\n",
       "      <td>39194</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39195</th>\n",
       "      <td>39195</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39196</th>\n",
       "      <td>39196</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>a towel that is on a rack in a dirty bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39197</th>\n",
       "      <td>39197</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39198</th>\n",
       "      <td>39198</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15948 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  imgid split                       filename  successful  \\\n",
       "23251       23251  26123  test  COCO_val2014_000000497106.jpg           1   \n",
       "23252       23252  26123  test  COCO_val2014_000000497106.jpg           1   \n",
       "23253       23253  26123  test  COCO_val2014_000000497106.jpg           1   \n",
       "23254       23254  26123  test  COCO_val2014_000000497106.jpg           1   \n",
       "23255       23255  26123  test  COCO_val2014_000000497106.jpg           1   \n",
       "...           ...    ...   ...                            ...         ...   \n",
       "39194       39194  24628  test  COCO_val2014_000000190705.jpg           1   \n",
       "39195       39195  24628  test  COCO_val2014_000000190705.jpg           1   \n",
       "39196       39196  24628  test  COCO_val2014_000000190705.jpg           1   \n",
       "39197       39197  24628  test  COCO_val2014_000000190705.jpg           1   \n",
       "39198       39198  24628  test  COCO_val2014_000000190705.jpg           1   \n",
       "\n",
       "                                                  tokens  \\\n",
       "23251  ['a', 'person', 'wearing', 'a', 'beautiful', '...   \n",
       "23252  ['a', 'person', 'with', 'a', 'beautiful', 'dre...   \n",
       "23253  ['the', 'adorable', 'child', 'wears', 'a', 'pr...   \n",
       "23254  ['a', 'young', 'shy', 'girl', 'in', 'a', 'fiar...   \n",
       "23255  ['a', 'frightened', 'child', 'wearing', 'a', '...   \n",
       "...                                                  ...   \n",
       "39194  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39195  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39196  ['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...   \n",
       "39197  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39198  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "\n",
       "                                          word_sentiment  sentiment  \\\n",
       "23251  [0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0,...          1   \n",
       "23252  [0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0,...          1   \n",
       "23253  [0.0, 1, 1, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0...          1   \n",
       "23254  [0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...          0   \n",
       "23255  [0.0, 1, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...          0   \n",
       "...                                                  ...        ...   \n",
       "39194   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39195            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "39196  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          0   \n",
       "39197   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39198            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "\n",
       "                                                     raw  \n",
       "23251  a person wearing a beautiful dress under an um...  \n",
       "23252  A person with a beautiful dress with an umbrel...  \n",
       "23253  The adorable child wears a pretty dress, that ...  \n",
       "23254  a young shy girl in a fiary dress under an umb...  \n",
       "23255  a frightened child wearing a dress with wings ...  \n",
       "...                                                  ...  \n",
       "39194  A dirty bathroom that has a dirty window made ...  \n",
       "39195          A dirty bathroom that has a window in it.  \n",
       "39196      a towel that is on a rack in a dirty bathroom  \n",
       "39197  A dirty bathroom that has a dirty window made ...  \n",
       "39198          A dirty bathroom that has a window in it.  \n",
       "\n",
       "[15948 rows x 9 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "20d5ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "placed = tfidf_vectorizer.fit(test)\n",
    "method_of = tfidf_vectorizer.transform(test['tokens'])\n",
    "textofsentiment = torch.tensor(method_of.toarray(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "638953e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15948, 9])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textofsentiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "668092ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test['word_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb437678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/22921], Loss: -9.4386\n",
      "Epoch [1/10], Step [200/22921], Loss: -25.1299\n",
      "Epoch [1/10], Step [300/22921], Loss: -74.2425\n",
      "Epoch [1/10], Step [400/22921], Loss: -42.0554\n",
      "Epoch [1/10], Step [500/22921], Loss: -103.9888\n",
      "Epoch [1/10], Step [600/22921], Loss: -149.6882\n",
      "Epoch [1/10], Step [700/22921], Loss: -110.7082\n",
      "Epoch [1/10], Step [800/22921], Loss: -58.1878\n",
      "Epoch [1/10], Step [900/22921], Loss: -180.8349\n",
      "Epoch [1/10], Step [1000/22921], Loss: -177.6357\n",
      "Epoch [1/10], Step [1100/22921], Loss: -251.1320\n",
      "Epoch [1/10], Step [1200/22921], Loss: -147.8508\n",
      "Epoch [1/10], Step [1300/22921], Loss: -184.8954\n",
      "Epoch [1/10], Step [1400/22921], Loss: -107.4183\n",
      "Epoch [1/10], Step [1500/22921], Loss: -220.9207\n",
      "Epoch [1/10], Step [1600/22921], Loss: -372.3165\n",
      "Epoch [1/10], Step [1700/22921], Loss: -232.0339\n",
      "Epoch [1/10], Step [1800/22921], Loss: -393.3957\n",
      "Epoch [1/10], Step [1900/22921], Loss: -141.7596\n",
      "Epoch [1/10], Step [2000/22921], Loss: -356.7178\n",
      "Epoch [1/10], Step [2100/22921], Loss: -309.6884\n",
      "Epoch [1/10], Step [2200/22921], Loss: -271.6591\n",
      "Epoch [1/10], Step [2300/22921], Loss: -616.7222\n",
      "Epoch [1/10], Step [2400/22921], Loss: -603.8273\n",
      "Epoch [1/10], Step [2500/22921], Loss: -395.9226\n",
      "Epoch [1/10], Step [2600/22921], Loss: -224.8021\n",
      "Epoch [1/10], Step [2700/22921], Loss: -219.6385\n",
      "Epoch [1/10], Step [2800/22921], Loss: -385.4961\n",
      "Epoch [1/10], Step [2900/22921], Loss: -383.4881\n",
      "Epoch [1/10], Step [3000/22921], Loss: -476.8451\n",
      "Epoch [1/10], Step [3100/22921], Loss: -852.8467\n",
      "Epoch [1/10], Step [3200/22921], Loss: -461.7044\n",
      "Epoch [1/10], Step [3300/22921], Loss: -121.6849\n",
      "Epoch [1/10], Step [3400/22921], Loss: -406.7587\n",
      "Epoch [1/10], Step [3500/22921], Loss: -433.6840\n",
      "Epoch [1/10], Step [3600/22921], Loss: -704.8367\n",
      "Epoch [1/10], Step [3700/22921], Loss: -402.9969\n",
      "Epoch [1/10], Step [3800/22921], Loss: -258.0216\n",
      "Epoch [1/10], Step [3900/22921], Loss: -298.7823\n",
      "Epoch [1/10], Step [4000/22921], Loss: -485.4263\n",
      "Epoch [1/10], Step [4100/22921], Loss: -421.5878\n",
      "Epoch [1/10], Step [4200/22921], Loss: -862.3295\n",
      "Epoch [1/10], Step [4300/22921], Loss: -267.7286\n",
      "Epoch [1/10], Step [4400/22921], Loss: -371.0153\n",
      "Epoch [1/10], Step [4500/22921], Loss: -617.5243\n",
      "Epoch [1/10], Step [4600/22921], Loss: -670.1420\n",
      "Epoch [1/10], Step [4700/22921], Loss: -393.0899\n",
      "Epoch [1/10], Step [4800/22921], Loss: -907.0050\n",
      "Epoch [1/10], Step [4900/22921], Loss: -730.4550\n",
      "Epoch [1/10], Step [5000/22921], Loss: -939.4102\n",
      "Epoch [1/10], Step [5100/22921], Loss: -801.4759\n",
      "Epoch [1/10], Step [5200/22921], Loss: -384.6976\n",
      "Epoch [1/10], Step [5300/22921], Loss: -942.4274\n",
      "Epoch [1/10], Step [5400/22921], Loss: -911.6476\n",
      "Epoch [1/10], Step [5500/22921], Loss: -950.4391\n",
      "Epoch [1/10], Step [5600/22921], Loss: -1110.2349\n",
      "Epoch [1/10], Step [5700/22921], Loss: -392.5072\n",
      "Epoch [1/10], Step [5800/22921], Loss: -895.6848\n",
      "Epoch [1/10], Step [5900/22921], Loss: -480.4751\n",
      "Epoch [1/10], Step [6000/22921], Loss: -768.6407\n",
      "Epoch [1/10], Step [6100/22921], Loss: -987.1800\n",
      "Epoch [1/10], Step [6200/22921], Loss: -975.1443\n",
      "Epoch [1/10], Step [6300/22921], Loss: -776.0060\n",
      "Epoch [1/10], Step [6400/22921], Loss: -841.2308\n",
      "Epoch [1/10], Step [6500/22921], Loss: -660.0233\n",
      "Epoch [1/10], Step [6600/22921], Loss: -947.9819\n",
      "Epoch [1/10], Step [6700/22921], Loss: -989.3092\n",
      "Epoch [1/10], Step [6800/22921], Loss: -944.9615\n",
      "Epoch [1/10], Step [6900/22921], Loss: -725.3922\n",
      "Epoch [1/10], Step [7000/22921], Loss: -853.2352\n",
      "Epoch [1/10], Step [7100/22921], Loss: -714.6483\n",
      "Epoch [1/10], Step [7200/22921], Loss: -994.7485\n",
      "Epoch [1/10], Step [7300/22921], Loss: -915.9994\n",
      "Epoch [1/10], Step [7400/22921], Loss: -772.0520\n",
      "Epoch [1/10], Step [7500/22921], Loss: -1375.4973\n",
      "Epoch [1/10], Step [7600/22921], Loss: -475.1027\n",
      "Epoch [1/10], Step [7700/22921], Loss: -1666.2340\n",
      "Epoch [1/10], Step [7800/22921], Loss: -1620.0242\n",
      "Epoch [1/10], Step [7900/22921], Loss: -917.9263\n",
      "Epoch [1/10], Step [8000/22921], Loss: -1392.5203\n",
      "Epoch [1/10], Step [8100/22921], Loss: -1576.0044\n",
      "Epoch [1/10], Step [8200/22921], Loss: -1119.6409\n",
      "Epoch [1/10], Step [8300/22921], Loss: -1337.1201\n",
      "Epoch [1/10], Step [8400/22921], Loss: -797.3505\n",
      "Epoch [1/10], Step [8500/22921], Loss: -1191.3984\n",
      "Epoch [1/10], Step [8600/22921], Loss: -920.4742\n",
      "Epoch [1/10], Step [8700/22921], Loss: -572.8753\n",
      "Epoch [1/10], Step [8800/22921], Loss: -831.9103\n",
      "Epoch [1/10], Step [8900/22921], Loss: -840.2676\n",
      "Epoch [1/10], Step [9000/22921], Loss: -1365.6702\n",
      "Epoch [1/10], Step [9100/22921], Loss: -1193.4271\n",
      "Epoch [1/10], Step [9200/22921], Loss: -1582.6974\n",
      "Epoch [1/10], Step [9300/22921], Loss: -1294.2166\n",
      "Epoch [1/10], Step [9400/22921], Loss: -883.8629\n",
      "Epoch [1/10], Step [9500/22921], Loss: -853.7656\n",
      "Epoch [1/10], Step [9600/22921], Loss: -979.5781\n",
      "Epoch [1/10], Step [9700/22921], Loss: -2293.7107\n",
      "Epoch [1/10], Step [9800/22921], Loss: -957.8585\n",
      "Epoch [1/10], Step [9900/22921], Loss: -805.7277\n",
      "Epoch [1/10], Step [10000/22921], Loss: -1219.3459\n",
      "Epoch [1/10], Step [10100/22921], Loss: -1271.8049\n",
      "Epoch [1/10], Step [10200/22921], Loss: -1076.9730\n",
      "Epoch [1/10], Step [10300/22921], Loss: -1923.1068\n",
      "Epoch [1/10], Step [10400/22921], Loss: -1518.5886\n",
      "Epoch [1/10], Step [10500/22921], Loss: -1872.5934\n",
      "Epoch [1/10], Step [10600/22921], Loss: -1760.0000\n",
      "Epoch [1/10], Step [10700/22921], Loss: -1298.8463\n",
      "Epoch [1/10], Step [10800/22921], Loss: -916.6254\n",
      "Epoch [1/10], Step [10900/22921], Loss: -1277.3789\n",
      "Epoch [1/10], Step [11000/22921], Loss: -1733.8633\n",
      "Epoch [1/10], Step [11100/22921], Loss: -2331.0630\n",
      "Epoch [1/10], Step [11200/22921], Loss: -1175.2599\n",
      "Epoch [1/10], Step [11300/22921], Loss: -1503.8599\n",
      "Epoch [1/10], Step [11400/22921], Loss: -1378.9155\n",
      "Epoch [1/10], Step [11500/22921], Loss: -2271.3149\n",
      "Epoch [1/10], Step [11600/22921], Loss: -1448.6582\n",
      "Epoch [1/10], Step [11700/22921], Loss: -2026.0459\n",
      "Epoch [1/10], Step [11800/22921], Loss: -1092.0197\n",
      "Epoch [1/10], Step [11900/22921], Loss: -1052.5865\n",
      "Epoch [1/10], Step [12000/22921], Loss: -1349.9762\n",
      "Epoch [1/10], Step [12100/22921], Loss: -1117.2507\n",
      "Epoch [1/10], Step [12200/22921], Loss: -1810.3489\n",
      "Epoch [1/10], Step [12300/22921], Loss: -2465.0776\n",
      "Epoch [1/10], Step [12400/22921], Loss: -1391.1929\n",
      "Epoch [1/10], Step [12500/22921], Loss: -1401.9358\n",
      "Epoch [1/10], Step [12600/22921], Loss: -1714.6682\n",
      "Epoch [1/10], Step [12700/22921], Loss: -2388.0535\n",
      "Epoch [1/10], Step [12800/22921], Loss: -2302.9561\n",
      "Epoch [1/10], Step [12900/22921], Loss: -2319.8789\n",
      "Epoch [1/10], Step [13000/22921], Loss: -2388.9265\n",
      "Epoch [1/10], Step [13100/22921], Loss: -1412.0834\n",
      "Epoch [1/10], Step [13200/22921], Loss: -843.0955\n",
      "Epoch [1/10], Step [13300/22921], Loss: -159.2200\n",
      "Epoch [1/10], Step [13400/22921], Loss: -2726.4817\n",
      "Epoch [1/10], Step [13500/22921], Loss: -3014.6997\n",
      "Epoch [1/10], Step [13600/22921], Loss: -2114.7046\n",
      "Epoch [1/10], Step [13700/22921], Loss: -1092.2400\n",
      "Epoch [1/10], Step [13800/22921], Loss: -2088.7253\n",
      "Epoch [1/10], Step [13900/22921], Loss: -1051.5442\n",
      "Epoch [1/10], Step [14000/22921], Loss: -2172.6121\n",
      "Epoch [1/10], Step [14100/22921], Loss: -3196.5281\n",
      "Epoch [1/10], Step [14200/22921], Loss: -2710.6821\n",
      "Epoch [1/10], Step [14300/22921], Loss: -1875.5723\n",
      "Epoch [1/10], Step [14400/22921], Loss: -2002.2061\n",
      "Epoch [1/10], Step [14500/22921], Loss: -2187.5571\n",
      "Epoch [1/10], Step [14600/22921], Loss: -1738.5779\n",
      "Epoch [1/10], Step [14700/22921], Loss: -2799.3062\n",
      "Epoch [1/10], Step [14800/22921], Loss: -1937.1390\n",
      "Epoch [1/10], Step [14900/22921], Loss: -3190.1880\n",
      "Epoch [1/10], Step [15000/22921], Loss: -1605.1588\n",
      "Epoch [1/10], Step [15100/22921], Loss: -2093.9370\n",
      "Epoch [1/10], Step [15200/22921], Loss: -1384.4674\n",
      "Epoch [1/10], Step [15300/22921], Loss: -2240.8608\n",
      "Epoch [1/10], Step [15400/22921], Loss: -1645.6179\n",
      "Epoch [1/10], Step [15500/22921], Loss: -1655.8965\n",
      "Epoch [1/10], Step [15600/22921], Loss: -2467.9712\n",
      "Epoch [1/10], Step [15700/22921], Loss: -1862.0183\n",
      "Epoch [1/10], Step [15800/22921], Loss: -1124.0570\n",
      "Epoch [1/10], Step [15900/22921], Loss: -3078.2119\n",
      "Epoch [1/10], Step [16000/22921], Loss: -2591.1904\n",
      "Epoch [1/10], Step [16100/22921], Loss: -2097.8933\n",
      "Epoch [1/10], Step [16200/22921], Loss: -1406.3972\n",
      "Epoch [1/10], Step [16300/22921], Loss: -2829.5896\n",
      "Epoch [1/10], Step [16400/22921], Loss: -1488.0126\n",
      "Epoch [1/10], Step [16500/22921], Loss: -2602.7534\n",
      "Epoch [1/10], Step [16600/22921], Loss: -2879.4766\n",
      "Epoch [1/10], Step [16700/22921], Loss: -2238.2795\n",
      "Epoch [1/10], Step [16800/22921], Loss: -2450.0012\n",
      "Epoch [1/10], Step [16900/22921], Loss: -2396.6218\n",
      "Epoch [1/10], Step [17000/22921], Loss: -2075.5034\n",
      "Epoch [1/10], Step [17100/22921], Loss: -2625.7874\n",
      "Epoch [1/10], Step [17200/22921], Loss: -2234.5930\n",
      "Epoch [1/10], Step [17300/22921], Loss: -1293.6033\n",
      "Epoch [1/10], Step [17400/22921], Loss: -3217.2261\n",
      "Epoch [1/10], Step [17500/22921], Loss: -3027.9111\n",
      "Epoch [1/10], Step [17600/22921], Loss: -2767.4739\n",
      "Epoch [1/10], Step [17700/22921], Loss: -2365.1121\n",
      "Epoch [1/10], Step [17800/22921], Loss: -2027.7302\n",
      "Epoch [1/10], Step [17900/22921], Loss: -1335.4402\n",
      "Epoch [1/10], Step [18000/22921], Loss: -2190.0701\n",
      "Epoch [1/10], Step [18100/22921], Loss: -1278.5275\n",
      "Epoch [1/10], Step [18200/22921], Loss: -1570.9568\n",
      "Epoch [1/10], Step [18300/22921], Loss: -2942.3159\n",
      "Epoch [1/10], Step [18400/22921], Loss: -3246.2864\n",
      "Epoch [1/10], Step [18500/22921], Loss: -2248.3066\n",
      "Epoch [1/10], Step [18600/22921], Loss: -1312.5345\n",
      "Epoch [1/10], Step [18700/22921], Loss: -3371.1665\n",
      "Epoch [1/10], Step [18800/22921], Loss: -2284.4905\n",
      "Epoch [1/10], Step [18900/22921], Loss: -3555.1907\n",
      "Epoch [1/10], Step [19000/22921], Loss: -1786.7637\n",
      "Epoch [1/10], Step [19100/22921], Loss: -1421.8409\n",
      "Epoch [1/10], Step [19200/22921], Loss: -2256.7534\n",
      "Epoch [1/10], Step [19300/22921], Loss: -1511.5531\n",
      "Epoch [1/10], Step [19400/22921], Loss: -2431.0476\n",
      "Epoch [1/10], Step [19500/22921], Loss: -1756.2285\n",
      "Epoch [1/10], Step [19600/22921], Loss: -4143.7334\n",
      "Epoch [1/10], Step [19700/22921], Loss: -3624.6724\n",
      "Epoch [1/10], Step [19800/22921], Loss: -3409.4302\n",
      "Epoch [1/10], Step [19900/22921], Loss: -3035.9690\n",
      "Epoch [1/10], Step [20000/22921], Loss: -3440.9524\n",
      "Epoch [1/10], Step [20100/22921], Loss: -863.9034\n",
      "Epoch [1/10], Step [20200/22921], Loss: -1814.8342\n",
      "Epoch [1/10], Step [20300/22921], Loss: -3092.6565\n",
      "Epoch [1/10], Step [20400/22921], Loss: -1832.1104\n",
      "Epoch [1/10], Step [20500/22921], Loss: -2721.3403\n",
      "Epoch [1/10], Step [20600/22921], Loss: -3940.7695\n",
      "Epoch [1/10], Step [20700/22921], Loss: -2586.3354\n",
      "Epoch [1/10], Step [20800/22921], Loss: -1948.5588\n",
      "Epoch [1/10], Step [20900/22921], Loss: -2446.7537\n",
      "Epoch [1/10], Step [21000/22921], Loss: -3195.0496\n",
      "Epoch [1/10], Step [21100/22921], Loss: -1151.8645\n",
      "Epoch [1/10], Step [21200/22921], Loss: -1322.3605\n",
      "Epoch [1/10], Step [21300/22921], Loss: -3570.2136\n",
      "Epoch [1/10], Step [21400/22921], Loss: -1084.3296\n",
      "Epoch [1/10], Step [21500/22921], Loss: -5700.1538\n",
      "Epoch [1/10], Step [21600/22921], Loss: -3874.1987\n",
      "Epoch [1/10], Step [21700/22921], Loss: -2622.2437\n",
      "Epoch [1/10], Step [21800/22921], Loss: -1359.3232\n",
      "Epoch [1/10], Step [21900/22921], Loss: -2133.2444\n",
      "Epoch [1/10], Step [22000/22921], Loss: -3685.7520\n",
      "Epoch [1/10], Step [22100/22921], Loss: -3270.2974\n",
      "Epoch [1/10], Step [22200/22921], Loss: -2073.7273\n",
      "Epoch [1/10], Step [22300/22921], Loss: -1908.8414\n",
      "Epoch [1/10], Step [22400/22921], Loss: -2352.1111\n",
      "Epoch [1/10], Step [22500/22921], Loss: -2274.9202\n",
      "Epoch [1/10], Step [22600/22921], Loss: -1230.4017\n",
      "Epoch [1/10], Step [22700/22921], Loss: -3795.7368\n",
      "Epoch [1/10], Step [22800/22921], Loss: -3634.4595\n",
      "Epoch [1/10], Step [22900/22921], Loss: -4451.0454\n",
      "Epoch [1/10], Training Accuracy: 0.4014\n",
      "Epoch [2/10], Step [100/22921], Loss: -4295.5352\n",
      "Epoch [2/10], Step [200/22921], Loss: -539.1844\n",
      "Epoch [2/10], Step [300/22921], Loss: -3969.6587\n",
      "Epoch [2/10], Step [400/22921], Loss: -3986.4023\n",
      "Epoch [2/10], Step [500/22921], Loss: -3548.5359\n",
      "Epoch [2/10], Step [600/22921], Loss: -2284.6646\n",
      "Epoch [2/10], Step [700/22921], Loss: -3487.2825\n",
      "Epoch [2/10], Step [800/22921], Loss: -1935.0531\n",
      "Epoch [2/10], Step [900/22921], Loss: -2127.8462\n",
      "Epoch [2/10], Step [1000/22921], Loss: -4086.8813\n",
      "Epoch [2/10], Step [1100/22921], Loss: -4009.4590\n",
      "Epoch [2/10], Step [1200/22921], Loss: -5055.8594\n",
      "Epoch [2/10], Step [1300/22921], Loss: -2538.1565\n",
      "Epoch [2/10], Step [1400/22921], Loss: -1604.4197\n",
      "Epoch [2/10], Step [1500/22921], Loss: -2179.3684\n",
      "Epoch [2/10], Step [1600/22921], Loss: -4565.7710\n",
      "Epoch [2/10], Step [1700/22921], Loss: -3151.3420\n",
      "Epoch [2/10], Step [1800/22921], Loss: -671.1178\n",
      "Epoch [2/10], Step [1900/22921], Loss: -2888.0730\n",
      "Epoch [2/10], Step [2000/22921], Loss: -4444.7373\n",
      "Epoch [2/10], Step [2100/22921], Loss: -3589.6133\n",
      "Epoch [2/10], Step [2200/22921], Loss: -1752.9196\n",
      "Epoch [2/10], Step [2300/22921], Loss: -3616.4946\n",
      "Epoch [2/10], Step [2400/22921], Loss: -2256.8159\n",
      "Epoch [2/10], Step [2500/22921], Loss: -3052.8779\n",
      "Epoch [2/10], Step [2600/22921], Loss: -2471.4973\n",
      "Epoch [2/10], Step [2700/22921], Loss: -3174.9080\n",
      "Epoch [2/10], Step [2800/22921], Loss: -4881.0127\n",
      "Epoch [2/10], Step [2900/22921], Loss: -2099.5537\n",
      "Epoch [2/10], Step [3000/22921], Loss: -1505.5103\n",
      "Epoch [2/10], Step [3100/22921], Loss: -1007.6439\n",
      "Epoch [2/10], Step [3200/22921], Loss: -6169.3174\n",
      "Epoch [2/10], Step [3300/22921], Loss: -5988.6421\n",
      "Epoch [2/10], Step [3400/22921], Loss: -2241.6812\n",
      "Epoch [2/10], Step [3500/22921], Loss: -4602.6494\n",
      "Epoch [2/10], Step [3600/22921], Loss: -3694.7668\n",
      "Epoch [2/10], Step [3700/22921], Loss: -2987.3599\n",
      "Epoch [2/10], Step [3800/22921], Loss: -1033.8523\n",
      "Epoch [2/10], Step [3900/22921], Loss: -5809.0474\n",
      "Epoch [2/10], Step [4000/22921], Loss: -4268.2817\n",
      "Epoch [2/10], Step [4100/22921], Loss: -5537.4702\n",
      "Epoch [2/10], Step [4200/22921], Loss: -2830.9443\n",
      "Epoch [2/10], Step [4300/22921], Loss: -3051.6660\n",
      "Epoch [2/10], Step [4400/22921], Loss: -2534.8999\n",
      "Epoch [2/10], Step [4500/22921], Loss: -3604.0774\n",
      "Epoch [2/10], Step [4600/22921], Loss: -4680.8486\n",
      "Epoch [2/10], Step [4700/22921], Loss: -2669.3196\n",
      "Epoch [2/10], Step [4800/22921], Loss: -5571.9590\n",
      "Epoch [2/10], Step [4900/22921], Loss: -4193.9058\n",
      "Epoch [2/10], Step [5000/22921], Loss: -3561.4622\n",
      "Epoch [2/10], Step [5100/22921], Loss: -1083.0000\n",
      "Epoch [2/10], Step [5200/22921], Loss: -3151.8098\n",
      "Epoch [2/10], Step [5300/22921], Loss: -2181.1155\n",
      "Epoch [2/10], Step [5400/22921], Loss: -4705.1475\n",
      "Epoch [2/10], Step [5500/22921], Loss: -3293.1040\n",
      "Epoch [2/10], Step [5600/22921], Loss: -4516.5508\n",
      "Epoch [2/10], Step [5700/22921], Loss: -3868.7832\n",
      "Epoch [2/10], Step [5800/22921], Loss: -4768.3730\n",
      "Epoch [2/10], Step [5900/22921], Loss: -5341.3740\n",
      "Epoch [2/10], Step [6000/22921], Loss: -2791.5566\n",
      "Epoch [2/10], Step [6100/22921], Loss: -3025.2402\n",
      "Epoch [2/10], Step [6200/22921], Loss: -3035.8230\n",
      "Epoch [2/10], Step [6300/22921], Loss: -4737.8218\n",
      "Epoch [2/10], Step [6400/22921], Loss: -3734.6445\n",
      "Epoch [2/10], Step [6500/22921], Loss: -2157.0225\n",
      "Epoch [2/10], Step [6600/22921], Loss: -2619.1570\n",
      "Epoch [2/10], Step [6700/22921], Loss: -2513.8484\n",
      "Epoch [2/10], Step [6800/22921], Loss: -4241.7368\n",
      "Epoch [2/10], Step [6900/22921], Loss: -1840.2903\n",
      "Epoch [2/10], Step [7000/22921], Loss: -5769.4565\n",
      "Epoch [2/10], Step [7100/22921], Loss: -6251.9585\n",
      "Epoch [2/10], Step [7200/22921], Loss: -4762.4756\n",
      "Epoch [2/10], Step [7300/22921], Loss: -2214.2351\n",
      "Epoch [2/10], Step [7400/22921], Loss: -5611.6768\n",
      "Epoch [2/10], Step [7500/22921], Loss: -6450.9014\n",
      "Epoch [2/10], Step [7600/22921], Loss: -4940.8623\n",
      "Epoch [2/10], Step [7700/22921], Loss: -2478.0522\n",
      "Epoch [2/10], Step [7800/22921], Loss: -5564.3408\n",
      "Epoch [2/10], Step [7900/22921], Loss: -4038.6021\n",
      "Epoch [2/10], Step [8000/22921], Loss: -3217.0149\n",
      "Epoch [2/10], Step [8100/22921], Loss: -3704.3477\n",
      "Epoch [2/10], Step [8200/22921], Loss: -3116.1265\n",
      "Epoch [2/10], Step [8300/22921], Loss: -3606.6948\n",
      "Epoch [2/10], Step [8400/22921], Loss: -5546.8662\n",
      "Epoch [2/10], Step [8500/22921], Loss: -3144.9133\n",
      "Epoch [2/10], Step [8600/22921], Loss: -3033.6165\n",
      "Epoch [2/10], Step [8700/22921], Loss: -2799.2463\n",
      "Epoch [2/10], Step [8800/22921], Loss: -4150.4858\n",
      "Epoch [2/10], Step [8900/22921], Loss: -3060.9233\n",
      "Epoch [2/10], Step [9000/22921], Loss: -2824.9434\n",
      "Epoch [2/10], Step [9100/22921], Loss: -5544.0806\n",
      "Epoch [2/10], Step [9200/22921], Loss: -4078.0188\n",
      "Epoch [2/10], Step [9300/22921], Loss: -1859.5176\n",
      "Epoch [2/10], Step [9400/22921], Loss: -4351.8994\n",
      "Epoch [2/10], Step [9500/22921], Loss: -3491.9683\n",
      "Epoch [2/10], Step [9600/22921], Loss: -4753.1265\n",
      "Epoch [2/10], Step [9700/22921], Loss: -3764.1555\n",
      "Epoch [2/10], Step [9800/22921], Loss: -3271.9902\n",
      "Epoch [2/10], Step [9900/22921], Loss: -3028.6375\n",
      "Epoch [2/10], Step [10000/22921], Loss: -4809.0015\n",
      "Epoch [2/10], Step [10100/22921], Loss: -3553.2766\n",
      "Epoch [2/10], Step [10200/22921], Loss: -2545.4041\n",
      "Epoch [2/10], Step [10300/22921], Loss: -4851.6885\n",
      "Epoch [2/10], Step [10400/22921], Loss: -2817.6003\n",
      "Epoch [2/10], Step [10500/22921], Loss: -6037.3120\n",
      "Epoch [2/10], Step [10600/22921], Loss: -3348.9663\n",
      "Epoch [2/10], Step [10700/22921], Loss: -7620.8740\n",
      "Epoch [2/10], Step [10800/22921], Loss: -1425.0894\n",
      "Epoch [2/10], Step [10900/22921], Loss: -4937.4463\n",
      "Epoch [2/10], Step [11000/22921], Loss: -3908.6355\n",
      "Epoch [2/10], Step [11100/22921], Loss: -4181.7446\n",
      "Epoch [2/10], Step [11200/22921], Loss: -7731.8877\n",
      "Epoch [2/10], Step [11300/22921], Loss: -5914.0190\n",
      "Epoch [2/10], Step [11400/22921], Loss: -5272.4893\n",
      "Epoch [2/10], Step [11500/22921], Loss: -3700.9902\n",
      "Epoch [2/10], Step [11600/22921], Loss: -4639.4023\n",
      "Epoch [2/10], Step [11700/22921], Loss: -2791.7710\n",
      "Epoch [2/10], Step [11800/22921], Loss: -7332.7476\n",
      "Epoch [2/10], Step [11900/22921], Loss: -3877.4121\n",
      "Epoch [2/10], Step [12000/22921], Loss: -2815.6208\n",
      "Epoch [2/10], Step [12100/22921], Loss: -5512.4980\n",
      "Epoch [2/10], Step [12200/22921], Loss: -3775.4460\n",
      "Epoch [2/10], Step [12300/22921], Loss: -1081.8086\n",
      "Epoch [2/10], Step [12400/22921], Loss: -3932.4507\n",
      "Epoch [2/10], Step [12500/22921], Loss: -5711.6123\n",
      "Epoch [2/10], Step [12600/22921], Loss: -4091.1648\n",
      "Epoch [2/10], Step [12700/22921], Loss: -3281.9734\n",
      "Epoch [2/10], Step [12800/22921], Loss: -5896.6709\n",
      "Epoch [2/10], Step [12900/22921], Loss: -3575.0703\n",
      "Epoch [2/10], Step [13000/22921], Loss: -4135.9619\n",
      "Epoch [2/10], Step [13100/22921], Loss: -3041.4187\n",
      "Epoch [2/10], Step [13200/22921], Loss: -2218.0977\n",
      "Epoch [2/10], Step [13300/22921], Loss: -3335.5332\n",
      "Epoch [2/10], Step [13400/22921], Loss: -5294.9849\n",
      "Epoch [2/10], Step [13500/22921], Loss: -5589.0537\n",
      "Epoch [2/10], Step [13600/22921], Loss: -2942.1030\n",
      "Epoch [2/10], Step [13700/22921], Loss: -3792.6543\n",
      "Epoch [2/10], Step [13800/22921], Loss: -2112.7148\n",
      "Epoch [2/10], Step [13900/22921], Loss: -4377.7515\n",
      "Epoch [2/10], Step [14000/22921], Loss: -3256.8188\n",
      "Epoch [2/10], Step [14100/22921], Loss: -7664.7393\n",
      "Epoch [2/10], Step [14200/22921], Loss: -7116.0757\n",
      "Epoch [2/10], Step [14300/22921], Loss: -998.9232\n",
      "Epoch [2/10], Step [14400/22921], Loss: -4435.5864\n",
      "Epoch [2/10], Step [14500/22921], Loss: -6169.0186\n",
      "Epoch [2/10], Step [14600/22921], Loss: -5034.2671\n",
      "Epoch [2/10], Step [14700/22921], Loss: -4903.5947\n",
      "Epoch [2/10], Step [14800/22921], Loss: -5350.0513\n",
      "Epoch [2/10], Step [14900/22921], Loss: -5074.6685\n",
      "Epoch [2/10], Step [15000/22921], Loss: -3779.5981\n",
      "Epoch [2/10], Step [15100/22921], Loss: -5101.2109\n",
      "Epoch [2/10], Step [15200/22921], Loss: -4237.5732\n",
      "Epoch [2/10], Step [15300/22921], Loss: -7764.2524\n",
      "Epoch [2/10], Step [15400/22921], Loss: -4846.6914\n",
      "Epoch [2/10], Step [15500/22921], Loss: -3386.3743\n",
      "Epoch [2/10], Step [15600/22921], Loss: -6199.0532\n",
      "Epoch [2/10], Step [15700/22921], Loss: -2958.6150\n",
      "Epoch [2/10], Step [15800/22921], Loss: -3262.5391\n",
      "Epoch [2/10], Step [15900/22921], Loss: -3865.4224\n",
      "Epoch [2/10], Step [16000/22921], Loss: -4471.6812\n",
      "Epoch [2/10], Step [16100/22921], Loss: -5528.4756\n",
      "Epoch [2/10], Step [16200/22921], Loss: -4493.8247\n",
      "Epoch [2/10], Step [16300/22921], Loss: -1651.7434\n",
      "Epoch [2/10], Step [16400/22921], Loss: -1806.3828\n",
      "Epoch [2/10], Step [16500/22921], Loss: -150.9120\n",
      "Epoch [2/10], Step [16600/22921], Loss: -1664.0717\n",
      "Epoch [2/10], Step [16700/22921], Loss: -8644.5420\n",
      "Epoch [2/10], Step [16800/22921], Loss: -6081.5884\n",
      "Epoch [2/10], Step [16900/22921], Loss: -2896.2368\n",
      "Epoch [2/10], Step [17000/22921], Loss: -4278.6826\n",
      "Epoch [2/10], Step [17100/22921], Loss: -3676.8530\n",
      "Epoch [2/10], Step [17200/22921], Loss: -5989.5039\n",
      "Epoch [2/10], Step [17300/22921], Loss: -6157.7080\n",
      "Epoch [2/10], Step [17400/22921], Loss: -3241.3843\n",
      "Epoch [2/10], Step [17500/22921], Loss: -4796.5464\n",
      "Epoch [2/10], Step [17600/22921], Loss: -4032.7859\n",
      "Epoch [2/10], Step [17700/22921], Loss: -6686.7422\n",
      "Epoch [2/10], Step [17800/22921], Loss: -4988.1060\n",
      "Epoch [2/10], Step [17900/22921], Loss: -3437.9934\n",
      "Epoch [2/10], Step [18000/22921], Loss: -3602.9355\n",
      "Epoch [2/10], Step [18100/22921], Loss: -7223.8970\n",
      "Epoch [2/10], Step [18200/22921], Loss: -6138.7212\n",
      "Epoch [2/10], Step [18300/22921], Loss: -4890.3960\n",
      "Epoch [2/10], Step [18400/22921], Loss: -1739.4948\n",
      "Epoch [2/10], Step [18500/22921], Loss: -9192.7842\n",
      "Epoch [2/10], Step [18600/22921], Loss: -4765.7959\n",
      "Epoch [2/10], Step [18700/22921], Loss: -1910.6292\n",
      "Epoch [2/10], Step [18800/22921], Loss: -9255.0869\n",
      "Epoch [2/10], Step [18900/22921], Loss: -6238.0674\n",
      "Epoch [2/10], Step [19000/22921], Loss: -2084.3208\n",
      "Epoch [2/10], Step [19100/22921], Loss: -7713.6030\n",
      "Epoch [2/10], Step [19200/22921], Loss: -6926.4985\n",
      "Epoch [2/10], Step [19300/22921], Loss: -8556.5059\n",
      "Epoch [2/10], Step [19400/22921], Loss: -7281.9946\n",
      "Epoch [2/10], Step [19500/22921], Loss: -5352.8271\n",
      "Epoch [2/10], Step [19600/22921], Loss: -6178.4990\n",
      "Epoch [2/10], Step [19700/22921], Loss: -6519.0625\n",
      "Epoch [2/10], Step [19800/22921], Loss: -6207.2305\n",
      "Epoch [2/10], Step [19900/22921], Loss: -7532.0884\n",
      "Epoch [2/10], Step [20000/22921], Loss: -5087.4253\n",
      "Epoch [2/10], Step [20100/22921], Loss: -9046.3477\n",
      "Epoch [2/10], Step [20200/22921], Loss: -8572.6064\n",
      "Epoch [2/10], Step [20300/22921], Loss: -2147.9290\n",
      "Epoch [2/10], Step [20400/22921], Loss: -3808.6509\n",
      "Epoch [2/10], Step [20500/22921], Loss: -8132.5322\n",
      "Epoch [2/10], Step [20600/22921], Loss: -9815.2334\n",
      "Epoch [2/10], Step [20700/22921], Loss: -7336.3740\n",
      "Epoch [2/10], Step [20800/22921], Loss: -4511.6743\n",
      "Epoch [2/10], Step [20900/22921], Loss: -4689.2314\n",
      "Epoch [2/10], Step [21000/22921], Loss: -5371.2563\n",
      "Epoch [2/10], Step [21100/22921], Loss: -3364.6414\n",
      "Epoch [2/10], Step [21200/22921], Loss: -4552.4595\n",
      "Epoch [2/10], Step [21300/22921], Loss: -4224.7808\n",
      "Epoch [2/10], Step [21400/22921], Loss: -7113.4971\n",
      "Epoch [2/10], Step [21500/22921], Loss: -5431.9385\n",
      "Epoch [2/10], Step [21600/22921], Loss: -3572.6777\n",
      "Epoch [2/10], Step [21700/22921], Loss: -2557.4094\n",
      "Epoch [2/10], Step [21800/22921], Loss: -9056.2285\n",
      "Epoch [2/10], Step [21900/22921], Loss: -6165.0518\n",
      "Epoch [2/10], Step [22000/22921], Loss: -3604.4910\n",
      "Epoch [2/10], Step [22100/22921], Loss: -7052.2007\n",
      "Epoch [2/10], Step [22200/22921], Loss: -6378.2705\n",
      "Epoch [2/10], Step [22300/22921], Loss: -8637.4424\n",
      "Epoch [2/10], Step [22400/22921], Loss: -2770.2690\n",
      "Epoch [2/10], Step [22500/22921], Loss: -7113.9858\n",
      "Epoch [2/10], Step [22600/22921], Loss: -3304.1460\n",
      "Epoch [2/10], Step [22700/22921], Loss: -3311.3882\n",
      "Epoch [2/10], Step [22800/22921], Loss: -5064.9614\n",
      "Epoch [2/10], Step [22900/22921], Loss: -1750.2864\n",
      "Epoch [2/10], Training Accuracy: 0.4014\n",
      "Epoch [3/10], Step [100/22921], Loss: -5614.9941\n",
      "Epoch [3/10], Step [200/22921], Loss: -6330.1978\n",
      "Epoch [3/10], Step [300/22921], Loss: -5637.8896\n",
      "Epoch [3/10], Step [400/22921], Loss: -4413.8633\n",
      "Epoch [3/10], Step [500/22921], Loss: -4954.7822\n",
      "Epoch [3/10], Step [600/22921], Loss: -3369.0610\n",
      "Epoch [3/10], Step [700/22921], Loss: -4975.0688\n",
      "Epoch [3/10], Step [800/22921], Loss: -7477.9912\n",
      "Epoch [3/10], Step [900/22921], Loss: -4638.9683\n",
      "Epoch [3/10], Step [1000/22921], Loss: -5722.0273\n",
      "Epoch [3/10], Step [1100/22921], Loss: -5196.7837\n",
      "Epoch [3/10], Step [1200/22921], Loss: -9158.5488\n",
      "Epoch [3/10], Step [1300/22921], Loss: -5937.8936\n",
      "Epoch [3/10], Step [1400/22921], Loss: -7212.4116\n",
      "Epoch [3/10], Step [1500/22921], Loss: -4697.5186\n",
      "Epoch [3/10], Step [1600/22921], Loss: -5250.2632\n",
      "Epoch [3/10], Step [1700/22921], Loss: -5079.8398\n",
      "Epoch [3/10], Step [1800/22921], Loss: -9453.4600\n",
      "Epoch [3/10], Step [1900/22921], Loss: -3279.2983\n",
      "Epoch [3/10], Step [2000/22921], Loss: -6937.2861\n",
      "Epoch [3/10], Step [2100/22921], Loss: -6403.3691\n",
      "Epoch [3/10], Step [2200/22921], Loss: -11182.5576\n",
      "Epoch [3/10], Step [2300/22921], Loss: -4776.0161\n",
      "Epoch [3/10], Step [2400/22921], Loss: -5154.4346\n",
      "Epoch [3/10], Step [2500/22921], Loss: -6086.8584\n",
      "Epoch [3/10], Step [2600/22921], Loss: -4066.1926\n",
      "Epoch [3/10], Step [2700/22921], Loss: -6852.8779\n",
      "Epoch [3/10], Step [2800/22921], Loss: -3712.0278\n",
      "Epoch [3/10], Step [2900/22921], Loss: -5765.5444\n",
      "Epoch [3/10], Step [3000/22921], Loss: -8945.8877\n",
      "Epoch [3/10], Step [3100/22921], Loss: -5042.0146\n",
      "Epoch [3/10], Step [3200/22921], Loss: -10103.6152\n",
      "Epoch [3/10], Step [3300/22921], Loss: -9186.3066\n",
      "Epoch [3/10], Step [3400/22921], Loss: -3381.1750\n",
      "Epoch [3/10], Step [3500/22921], Loss: -3200.0513\n",
      "Epoch [3/10], Step [3600/22921], Loss: -5469.3760\n",
      "Epoch [3/10], Step [3700/22921], Loss: -6424.0449\n",
      "Epoch [3/10], Step [3800/22921], Loss: -6057.6279\n",
      "Epoch [3/10], Step [3900/22921], Loss: -5690.3647\n",
      "Epoch [3/10], Step [4000/22921], Loss: -10452.9902\n",
      "Epoch [3/10], Step [4100/22921], Loss: -5903.2837\n",
      "Epoch [3/10], Step [4200/22921], Loss: -5533.5166\n",
      "Epoch [3/10], Step [4300/22921], Loss: -6117.8110\n",
      "Epoch [3/10], Step [4400/22921], Loss: -9387.1865\n",
      "Epoch [3/10], Step [4500/22921], Loss: -6910.4736\n",
      "Epoch [3/10], Step [4600/22921], Loss: -8847.4785\n",
      "Epoch [3/10], Step [4700/22921], Loss: -8479.5293\n",
      "Epoch [3/10], Step [4800/22921], Loss: -11585.6904\n",
      "Epoch [3/10], Step [4900/22921], Loss: -4062.9570\n",
      "Epoch [3/10], Step [5000/22921], Loss: -1163.0951\n",
      "Epoch [3/10], Step [5100/22921], Loss: -7768.1265\n",
      "Epoch [3/10], Step [5200/22921], Loss: -6615.8125\n",
      "Epoch [3/10], Step [5300/22921], Loss: -3509.1960\n",
      "Epoch [3/10], Step [5400/22921], Loss: -6445.4756\n",
      "Epoch [3/10], Step [5500/22921], Loss: -5674.6841\n",
      "Epoch [3/10], Step [5600/22921], Loss: -8821.8203\n",
      "Epoch [3/10], Step [5700/22921], Loss: -8446.1143\n",
      "Epoch [3/10], Step [5800/22921], Loss: -5116.8701\n",
      "Epoch [3/10], Step [5900/22921], Loss: -6310.0483\n",
      "Epoch [3/10], Step [6000/22921], Loss: -5532.1367\n",
      "Epoch [3/10], Step [6100/22921], Loss: -1385.6113\n",
      "Epoch [3/10], Step [6200/22921], Loss: -4164.9683\n",
      "Epoch [3/10], Step [6300/22921], Loss: -6557.1572\n",
      "Epoch [3/10], Step [6400/22921], Loss: -5176.4878\n",
      "Epoch [3/10], Step [6500/22921], Loss: -7181.9868\n",
      "Epoch [3/10], Step [6600/22921], Loss: -3397.9226\n",
      "Epoch [3/10], Step [6700/22921], Loss: -6207.7148\n",
      "Epoch [3/10], Step [6800/22921], Loss: -7623.1079\n",
      "Epoch [3/10], Step [6900/22921], Loss: -6632.0259\n",
      "Epoch [3/10], Step [7000/22921], Loss: -4832.5674\n",
      "Epoch [3/10], Step [7100/22921], Loss: -6455.7334\n",
      "Epoch [3/10], Step [7200/22921], Loss: -12530.1953\n",
      "Epoch [3/10], Step [7300/22921], Loss: -5872.1040\n",
      "Epoch [3/10], Step [7400/22921], Loss: -5679.8540\n",
      "Epoch [3/10], Step [7500/22921], Loss: -5080.5586\n",
      "Epoch [3/10], Step [7600/22921], Loss: -3664.9077\n",
      "Epoch [3/10], Step [7700/22921], Loss: -4283.2017\n",
      "Epoch [3/10], Step [7800/22921], Loss: -9603.7021\n",
      "Epoch [3/10], Step [7900/22921], Loss: -9621.0527\n",
      "Epoch [3/10], Step [8000/22921], Loss: -7793.4673\n",
      "Epoch [3/10], Step [8100/22921], Loss: -4109.1924\n",
      "Epoch [3/10], Step [8200/22921], Loss: -6792.6768\n",
      "Epoch [3/10], Step [8300/22921], Loss: -5773.8911\n",
      "Epoch [3/10], Step [8400/22921], Loss: -3305.4399\n",
      "Epoch [3/10], Step [8500/22921], Loss: -3932.3999\n",
      "Epoch [3/10], Step [8600/22921], Loss: -6219.6899\n",
      "Epoch [3/10], Step [8700/22921], Loss: -6438.4634\n",
      "Epoch [3/10], Step [8800/22921], Loss: -10611.5684\n",
      "Epoch [3/10], Step [8900/22921], Loss: -7711.9087\n",
      "Epoch [3/10], Step [9000/22921], Loss: -11066.5879\n",
      "Epoch [3/10], Step [9100/22921], Loss: -7321.1548\n",
      "Epoch [3/10], Step [9200/22921], Loss: -7543.9570\n",
      "Epoch [3/10], Step [9300/22921], Loss: -6298.2510\n",
      "Epoch [3/10], Step [9400/22921], Loss: -4627.3110\n",
      "Epoch [3/10], Step [9500/22921], Loss: -9271.5215\n",
      "Epoch [3/10], Step [9600/22921], Loss: -7177.0986\n",
      "Epoch [3/10], Step [9700/22921], Loss: -9093.7627\n",
      "Epoch [3/10], Step [9800/22921], Loss: -7838.6201\n",
      "Epoch [3/10], Step [9900/22921], Loss: -5305.5435\n",
      "Epoch [3/10], Step [10000/22921], Loss: -5952.5254\n",
      "Epoch [3/10], Step [10100/22921], Loss: -5750.0117\n",
      "Epoch [3/10], Step [10200/22921], Loss: -10452.4609\n",
      "Epoch [3/10], Step [10300/22921], Loss: -6411.8857\n",
      "Epoch [3/10], Step [10400/22921], Loss: -5780.6851\n",
      "Epoch [3/10], Step [10500/22921], Loss: -12011.8242\n",
      "Epoch [3/10], Step [10600/22921], Loss: -10099.1816\n",
      "Epoch [3/10], Step [10700/22921], Loss: -10978.5449\n",
      "Epoch [3/10], Step [10800/22921], Loss: -6684.6602\n",
      "Epoch [3/10], Step [10900/22921], Loss: -11448.5801\n",
      "Epoch [3/10], Step [11000/22921], Loss: -6491.6328\n",
      "Epoch [3/10], Step [11100/22921], Loss: -11488.3555\n",
      "Epoch [3/10], Step [11200/22921], Loss: -6731.0493\n",
      "Epoch [3/10], Step [11300/22921], Loss: -6959.3413\n",
      "Epoch [3/10], Step [11400/22921], Loss: -5227.9492\n",
      "Epoch [3/10], Step [11500/22921], Loss: -8728.5176\n",
      "Epoch [3/10], Step [11600/22921], Loss: -4371.9976\n",
      "Epoch [3/10], Step [11700/22921], Loss: -4598.1455\n",
      "Epoch [3/10], Step [11800/22921], Loss: -8334.5127\n",
      "Epoch [3/10], Step [11900/22921], Loss: -5053.3564\n",
      "Epoch [3/10], Step [12000/22921], Loss: -9903.9648\n",
      "Epoch [3/10], Step [12100/22921], Loss: -6614.3096\n",
      "Epoch [3/10], Step [12200/22921], Loss: -5521.2041\n",
      "Epoch [3/10], Step [12300/22921], Loss: -8627.8486\n",
      "Epoch [3/10], Step [12400/22921], Loss: -13960.8691\n",
      "Epoch [3/10], Step [12500/22921], Loss: -2885.7515\n",
      "Epoch [3/10], Step [12600/22921], Loss: -10005.9434\n",
      "Epoch [3/10], Step [12700/22921], Loss: -9800.6846\n",
      "Epoch [3/10], Step [12800/22921], Loss: -10710.3389\n",
      "Epoch [3/10], Step [12900/22921], Loss: -7600.0537\n",
      "Epoch [3/10], Step [13000/22921], Loss: -7612.7710\n",
      "Epoch [3/10], Step [13100/22921], Loss: -12559.6182\n",
      "Epoch [3/10], Step [13200/22921], Loss: -2021.7894\n",
      "Epoch [3/10], Step [13300/22921], Loss: -3150.0637\n",
      "Epoch [3/10], Step [13400/22921], Loss: -4732.8384\n",
      "Epoch [3/10], Step [13500/22921], Loss: -8803.6826\n",
      "Epoch [3/10], Step [13600/22921], Loss: -4296.8506\n",
      "Epoch [3/10], Step [13700/22921], Loss: -6568.9399\n",
      "Epoch [3/10], Step [13800/22921], Loss: -10890.2354\n",
      "Epoch [3/10], Step [13900/22921], Loss: -8181.5312\n",
      "Epoch [3/10], Step [14000/22921], Loss: -12064.9326\n",
      "Epoch [3/10], Step [14100/22921], Loss: -7523.9092\n",
      "Epoch [3/10], Step [14200/22921], Loss: -6394.9375\n",
      "Epoch [3/10], Step [14300/22921], Loss: -5490.2510\n",
      "Epoch [3/10], Step [14400/22921], Loss: -8018.5752\n",
      "Epoch [3/10], Step [14500/22921], Loss: -5048.3643\n",
      "Epoch [3/10], Step [14600/22921], Loss: -8503.8926\n",
      "Epoch [3/10], Step [14700/22921], Loss: -1381.3191\n",
      "Epoch [3/10], Step [14800/22921], Loss: -8532.6025\n",
      "Epoch [3/10], Step [14900/22921], Loss: -3927.1445\n",
      "Epoch [3/10], Step [15000/22921], Loss: -12494.8779\n",
      "Epoch [3/10], Step [15100/22921], Loss: -6025.9541\n",
      "Epoch [3/10], Step [15200/22921], Loss: -6963.8281\n",
      "Epoch [3/10], Step [15300/22921], Loss: -6741.4741\n",
      "Epoch [3/10], Step [15400/22921], Loss: -6054.3037\n",
      "Epoch [3/10], Step [15500/22921], Loss: -6064.3110\n",
      "Epoch [3/10], Step [15600/22921], Loss: -12849.1230\n",
      "Epoch [3/10], Step [15700/22921], Loss: -8189.6641\n",
      "Epoch [3/10], Step [15800/22921], Loss: -4921.4272\n",
      "Epoch [3/10], Step [15900/22921], Loss: -10562.7559\n",
      "Epoch [3/10], Step [16000/22921], Loss: -9639.7754\n",
      "Epoch [3/10], Step [16100/22921], Loss: -4945.9502\n",
      "Epoch [3/10], Step [16200/22921], Loss: -4245.9458\n",
      "Epoch [3/10], Step [16300/22921], Loss: -7796.9883\n",
      "Epoch [3/10], Step [16400/22921], Loss: -12776.8867\n",
      "Epoch [3/10], Step [16500/22921], Loss: -5450.7495\n",
      "Epoch [3/10], Step [16600/22921], Loss: -5697.2471\n",
      "Epoch [3/10], Step [16700/22921], Loss: -4042.0085\n",
      "Epoch [3/10], Step [16800/22921], Loss: -5477.0728\n",
      "Epoch [3/10], Step [16900/22921], Loss: -9540.4814\n",
      "Epoch [3/10], Step [17000/22921], Loss: -9794.1484\n",
      "Epoch [3/10], Step [17100/22921], Loss: -10287.3379\n",
      "Epoch [3/10], Step [17200/22921], Loss: -8147.4141\n",
      "Epoch [3/10], Step [17300/22921], Loss: -6000.8311\n",
      "Epoch [3/10], Step [17400/22921], Loss: -3365.7422\n",
      "Epoch [3/10], Step [17500/22921], Loss: -6260.2109\n",
      "Epoch [3/10], Step [17600/22921], Loss: -5546.7681\n",
      "Epoch [3/10], Step [17700/22921], Loss: -6521.0381\n",
      "Epoch [3/10], Step [17800/22921], Loss: -7014.9858\n",
      "Epoch [3/10], Step [17900/22921], Loss: -8237.6035\n",
      "Epoch [3/10], Step [18000/22921], Loss: -3882.3843\n",
      "Epoch [3/10], Step [18100/22921], Loss: -7047.2056\n",
      "Epoch [3/10], Step [18200/22921], Loss: -8518.0986\n",
      "Epoch [3/10], Step [18300/22921], Loss: -8043.4126\n",
      "Epoch [3/10], Step [18400/22921], Loss: -10007.9160\n",
      "Epoch [3/10], Step [18500/22921], Loss: -5622.5781\n",
      "Epoch [3/10], Step [18600/22921], Loss: -6855.2891\n",
      "Epoch [3/10], Step [18700/22921], Loss: -7111.6650\n",
      "Epoch [3/10], Step [18800/22921], Loss: -7614.0796\n",
      "Epoch [3/10], Step [18900/22921], Loss: -9840.1406\n",
      "Epoch [3/10], Step [19000/22921], Loss: -4681.4077\n",
      "Epoch [3/10], Step [19100/22921], Loss: -9871.5938\n",
      "Epoch [3/10], Step [19200/22921], Loss: -3954.5645\n",
      "Epoch [3/10], Step [19300/22921], Loss: -3217.9578\n",
      "Epoch [3/10], Step [19400/22921], Loss: -11650.5137\n",
      "Epoch [3/10], Step [19500/22921], Loss: -6950.9150\n",
      "Epoch [3/10], Step [19600/22921], Loss: -8701.4541\n",
      "Epoch [3/10], Step [19700/22921], Loss: -6722.0889\n",
      "Epoch [3/10], Step [19800/22921], Loss: -7231.2344\n",
      "Epoch [3/10], Step [19900/22921], Loss: -9490.3428\n",
      "Epoch [3/10], Step [20000/22921], Loss: -8504.4521\n",
      "Epoch [3/10], Step [20100/22921], Loss: -12022.9902\n",
      "Epoch [3/10], Step [20200/22921], Loss: -6773.1396\n",
      "Epoch [3/10], Step [20300/22921], Loss: -2512.2639\n",
      "Epoch [3/10], Step [20400/22921], Loss: -11320.8613\n",
      "Epoch [3/10], Step [20500/22921], Loss: -6047.0112\n",
      "Epoch [3/10], Step [20600/22921], Loss: -10345.7051\n",
      "Epoch [3/10], Step [20700/22921], Loss: -12636.7012\n",
      "Epoch [3/10], Step [20800/22921], Loss: -4808.9478\n",
      "Epoch [3/10], Step [20900/22921], Loss: -5829.9976\n",
      "Epoch [3/10], Step [21000/22921], Loss: -6853.9297\n",
      "Epoch [3/10], Step [21100/22921], Loss: -10169.3174\n",
      "Epoch [3/10], Step [21200/22921], Loss: -3818.9302\n",
      "Epoch [3/10], Step [21300/22921], Loss: -9943.8066\n",
      "Epoch [3/10], Step [21400/22921], Loss: -10980.2314\n",
      "Epoch [3/10], Step [21500/22921], Loss: -10996.4766\n",
      "Epoch [3/10], Step [21600/22921], Loss: -8707.7891\n",
      "Epoch [3/10], Step [21700/22921], Loss: -8976.5361\n",
      "Epoch [3/10], Step [21800/22921], Loss: -11300.4668\n",
      "Epoch [3/10], Step [21900/22921], Loss: -18517.3477\n",
      "Epoch [3/10], Step [22000/22921], Loss: -9014.4346\n",
      "Epoch [3/10], Step [22100/22921], Loss: -8254.0127\n",
      "Epoch [3/10], Step [22200/22921], Loss: -7490.8765\n",
      "Epoch [3/10], Step [22300/22921], Loss: -8019.6406\n",
      "Epoch [3/10], Step [22400/22921], Loss: -7772.1953\n",
      "Epoch [3/10], Step [22500/22921], Loss: -8821.4297\n",
      "Epoch [3/10], Step [22600/22921], Loss: -11953.0342\n",
      "Epoch [3/10], Step [22700/22921], Loss: -7546.4155\n",
      "Epoch [3/10], Step [22800/22921], Loss: -3648.3313\n",
      "Epoch [3/10], Step [22900/22921], Loss: -7045.9990\n",
      "Epoch [3/10], Training Accuracy: 0.4014\n",
      "Epoch [4/10], Step [100/22921], Loss: -7580.6797\n",
      "Epoch [4/10], Step [200/22921], Loss: -6543.9873\n",
      "Epoch [4/10], Step [300/22921], Loss: -3932.0867\n",
      "Epoch [4/10], Step [400/22921], Loss: -10238.1055\n",
      "Epoch [4/10], Step [500/22921], Loss: -10516.1973\n",
      "Epoch [4/10], Step [600/22921], Loss: -6318.7261\n",
      "Epoch [4/10], Step [700/22921], Loss: -6854.7407\n",
      "Epoch [4/10], Step [800/22921], Loss: -9239.9717\n",
      "Epoch [4/10], Step [900/22921], Loss: -5022.9521\n",
      "Epoch [4/10], Step [1000/22921], Loss: -6883.7056\n",
      "Epoch [4/10], Step [1100/22921], Loss: -8484.3145\n",
      "Epoch [4/10], Step [1200/22921], Loss: -10620.3984\n",
      "Epoch [4/10], Step [1300/22921], Loss: -9040.3037\n",
      "Epoch [4/10], Step [1400/22921], Loss: -8786.4092\n",
      "Epoch [4/10], Step [1500/22921], Loss: -6665.1616\n",
      "Epoch [4/10], Step [1600/22921], Loss: -4272.0181\n",
      "Epoch [4/10], Step [1700/22921], Loss: -4545.7495\n",
      "Epoch [4/10], Step [1800/22921], Loss: -7765.9131\n",
      "Epoch [4/10], Step [1900/22921], Loss: -5363.0454\n",
      "Epoch [4/10], Step [2000/22921], Loss: -7250.0991\n",
      "Epoch [4/10], Step [2100/22921], Loss: -11024.7480\n",
      "Epoch [4/10], Step [2200/22921], Loss: -7539.6143\n",
      "Epoch [4/10], Step [2300/22921], Loss: -11056.6230\n",
      "Epoch [4/10], Step [2400/22921], Loss: -12152.1494\n",
      "Epoch [4/10], Step [2500/22921], Loss: -7301.7197\n",
      "Epoch [4/10], Step [2600/22921], Loss: -7582.7471\n",
      "Epoch [4/10], Step [2700/22921], Loss: -5965.7939\n",
      "Epoch [4/10], Step [2800/22921], Loss: -5430.8145\n",
      "Epoch [4/10], Step [2900/22921], Loss: -9516.1865\n",
      "Epoch [4/10], Step [3000/22921], Loss: -10618.0938\n",
      "Epoch [4/10], Step [3100/22921], Loss: -10359.8848\n",
      "Epoch [4/10], Step [3200/22921], Loss: -10646.4004\n",
      "Epoch [4/10], Step [3300/22921], Loss: -5467.3071\n",
      "Epoch [4/10], Step [3400/22921], Loss: -8759.6973\n",
      "Epoch [4/10], Step [3500/22921], Loss: -7949.6377\n",
      "Epoch [4/10], Step [3600/22921], Loss: -9882.4629\n",
      "Epoch [4/10], Step [3700/22921], Loss: -12645.1113\n",
      "Epoch [4/10], Step [3800/22921], Loss: -4404.6299\n",
      "Epoch [4/10], Step [3900/22921], Loss: -10200.3848\n",
      "Epoch [4/10], Step [4000/22921], Loss: -3312.4751\n",
      "Epoch [4/10], Step [4100/22921], Loss: -9121.3594\n",
      "Epoch [4/10], Step [4200/22921], Loss: -15222.3184\n",
      "Epoch [4/10], Step [4300/22921], Loss: -7759.6133\n",
      "Epoch [4/10], Step [4400/22921], Loss: -9989.9678\n",
      "Epoch [4/10], Step [4500/22921], Loss: -8058.9468\n",
      "Epoch [4/10], Step [4600/22921], Loss: -8626.7090\n",
      "Epoch [4/10], Step [4700/22921], Loss: -12261.6973\n",
      "Epoch [4/10], Step [4800/22921], Loss: -11999.6807\n",
      "Epoch [4/10], Step [4900/22921], Loss: -7265.5522\n",
      "Epoch [4/10], Step [5000/22921], Loss: -8115.1719\n",
      "Epoch [4/10], Step [5100/22921], Loss: -6444.7959\n",
      "Epoch [4/10], Step [5200/22921], Loss: -15150.4590\n",
      "Epoch [4/10], Step [5300/22921], Loss: -9552.0586\n",
      "Epoch [4/10], Step [5400/22921], Loss: -11253.2891\n",
      "Epoch [4/10], Step [5500/22921], Loss: -9860.0781\n",
      "Epoch [4/10], Step [5600/22921], Loss: -7335.1006\n",
      "Epoch [4/10], Step [5700/22921], Loss: -8192.2695\n",
      "Epoch [4/10], Step [5800/22921], Loss: -6505.5098\n",
      "Epoch [4/10], Step [5900/22921], Loss: -6231.3574\n",
      "Epoch [4/10], Step [6000/22921], Loss: -8508.5137\n",
      "Epoch [4/10], Step [6100/22921], Loss: -5679.8154\n",
      "Epoch [4/10], Step [6200/22921], Loss: -13365.0098\n",
      "Epoch [4/10], Step [6300/22921], Loss: -5409.8228\n",
      "Epoch [4/10], Step [6400/22921], Loss: -12544.4277\n",
      "Epoch [4/10], Step [6500/22921], Loss: -5994.9087\n",
      "Epoch [4/10], Step [6600/22921], Loss: -10004.6523\n",
      "Epoch [4/10], Step [6700/22921], Loss: -6582.9697\n",
      "Epoch [4/10], Step [6800/22921], Loss: -8024.6611\n",
      "Epoch [4/10], Step [6900/22921], Loss: -8034.6719\n",
      "Epoch [4/10], Step [7000/22921], Loss: -17813.4121\n",
      "Epoch [4/10], Step [7100/22921], Loss: -2301.6431\n",
      "Epoch [4/10], Step [7200/22921], Loss: -9794.6699\n",
      "Epoch [4/10], Step [7300/22921], Loss: -9806.9258\n",
      "Epoch [4/10], Step [7400/22921], Loss: -19061.0039\n",
      "Epoch [4/10], Step [7500/22921], Loss: -7518.7905\n",
      "Epoch [4/10], Step [7600/22921], Loss: -8108.2314\n",
      "Epoch [4/10], Step [7700/22921], Loss: -11597.3018\n",
      "Epoch [4/10], Step [7800/22921], Loss: -13934.9004\n",
      "Epoch [4/10], Step [7900/22921], Loss: -8429.9668\n",
      "Epoch [4/10], Step [8000/22921], Loss: -6985.7959\n",
      "Epoch [4/10], Step [8100/22921], Loss: -12240.4727\n",
      "Epoch [4/10], Step [8200/22921], Loss: -11964.8213\n",
      "Epoch [4/10], Step [8300/22921], Loss: -10810.9033\n",
      "Epoch [4/10], Step [8400/22921], Loss: -6728.9307\n",
      "Epoch [4/10], Step [8500/22921], Loss: -7909.2344\n",
      "Epoch [4/10], Step [8600/22921], Loss: -11439.1719\n",
      "Epoch [4/10], Step [8700/22921], Loss: -11160.4395\n",
      "Epoch [4/10], Step [8800/22921], Loss: -18230.7598\n",
      "Epoch [4/10], Step [8900/22921], Loss: -12954.8721\n",
      "Epoch [4/10], Step [9000/22921], Loss: -6780.9209\n",
      "Epoch [4/10], Step [9100/22921], Loss: -10626.6309\n",
      "Epoch [4/10], Step [9200/22921], Loss: -9457.7764\n",
      "Epoch [4/10], Step [9300/22921], Loss: -9470.1279\n",
      "Epoch [4/10], Step [9400/22921], Loss: -14519.6221\n",
      "Epoch [4/10], Step [9500/22921], Loss: -10087.8408\n",
      "Epoch [4/10], Step [9600/22921], Loss: -13071.4004\n",
      "Epoch [4/10], Step [9700/22921], Loss: -12790.7236\n",
      "Epoch [4/10], Step [9800/22921], Loss: -8934.8086\n",
      "Epoch [4/10], Step [9900/22921], Loss: -7753.3359\n",
      "Epoch [4/10], Step [10000/22921], Loss: -9255.6650\n",
      "Epoch [4/10], Step [10100/22921], Loss: -8072.0928\n",
      "Epoch [4/10], Step [10200/22921], Loss: -10776.0420\n",
      "Epoch [4/10], Step [10300/22921], Loss: -5394.8057\n",
      "Epoch [4/10], Step [10400/22921], Loss: -2400.4917\n",
      "Epoch [4/10], Step [10500/22921], Loss: -6909.6143\n",
      "Epoch [4/10], Step [10600/22921], Loss: -12332.5020\n",
      "Epoch [4/10], Step [10700/22921], Loss: -10842.8076\n",
      "Epoch [4/10], Step [10800/22921], Loss: -8745.3809\n",
      "Epoch [4/10], Step [10900/22921], Loss: -5736.7002\n",
      "Epoch [4/10], Step [11000/22921], Loss: -6650.8530\n",
      "Epoch [4/10], Step [11100/22921], Loss: -1513.4507\n",
      "Epoch [4/10], Step [11200/22921], Loss: -13334.7451\n",
      "Epoch [4/10], Step [11300/22921], Loss: -4551.6318\n",
      "Epoch [4/10], Step [11400/22921], Loss: -9721.9707\n",
      "Epoch [4/10], Step [11500/22921], Loss: -10341.6396\n",
      "Epoch [4/10], Step [11600/22921], Loss: -8831.3965\n",
      "Epoch [4/10], Step [11700/22921], Loss: -8842.3008\n",
      "Epoch [4/10], Step [11800/22921], Loss: -10379.7520\n",
      "Epoch [4/10], Step [11900/22921], Loss: -17727.6309\n",
      "Epoch [4/10], Step [12000/22921], Loss: -7650.8291\n",
      "Epoch [4/10], Step [12100/22921], Loss: -7966.9307\n",
      "Epoch [4/10], Step [12200/22921], Loss: -3681.5461\n",
      "Epoch [4/10], Step [12300/22921], Loss: -14130.4092\n",
      "Epoch [4/10], Step [12400/22921], Loss: -8304.1582\n",
      "Epoch [4/10], Step [12500/22921], Loss: -11086.5371\n",
      "Epoch [4/10], Step [12600/22921], Loss: -7708.2930\n",
      "Epoch [4/10], Step [12700/22921], Loss: -6173.7930\n",
      "Epoch [4/10], Step [12800/22921], Loss: -9272.1465\n",
      "Epoch [4/10], Step [12900/22921], Loss: -11138.8105\n",
      "Epoch [4/10], Step [13000/22921], Loss: -5885.7222\n",
      "Epoch [4/10], Step [13100/22921], Loss: -7754.1807\n",
      "Epoch [4/10], Step [13200/22921], Loss: -7142.7314\n",
      "Epoch [4/10], Step [13300/22921], Loss: -13680.9863\n",
      "Epoch [4/10], Step [13400/22921], Loss: -8093.8804\n",
      "Epoch [4/10], Step [13500/22921], Loss: -15272.1436\n",
      "Epoch [4/10], Step [13600/22921], Loss: -11234.0967\n",
      "Epoch [4/10], Step [13700/22921], Loss: -9998.2314\n",
      "Epoch [4/10], Step [13800/22921], Loss: -12513.1914\n",
      "Epoch [4/10], Step [13900/22921], Loss: -10648.8320\n",
      "Epoch [4/10], Step [14000/22921], Loss: -10348.1387\n",
      "Epoch [4/10], Step [14100/22921], Loss: -10046.3428\n",
      "Epoch [4/10], Step [14200/22921], Loss: -16031.4736\n",
      "Epoch [4/10], Step [14300/22921], Loss: -8812.0859\n",
      "Epoch [4/10], Step [14400/22921], Loss: -10398.4434\n",
      "Epoch [4/10], Step [14500/22921], Loss: -8833.0186\n",
      "Epoch [4/10], Step [14600/22921], Loss: -11054.1982\n",
      "Epoch [4/10], Step [14700/22921], Loss: -4426.9600\n",
      "Epoch [4/10], Step [14800/22921], Loss: -10131.0029\n",
      "Epoch [4/10], Step [14900/22921], Loss: -19017.7070\n",
      "Epoch [4/10], Step [15000/22921], Loss: -2856.1172\n",
      "Epoch [4/10], Step [15100/22921], Loss: -11439.0205\n",
      "Epoch [4/10], Step [15200/22921], Loss: -9862.0508\n",
      "Epoch [4/10], Step [15300/22921], Loss: -10192.4668\n",
      "Epoch [4/10], Step [15400/22921], Loss: -8929.3379\n",
      "Epoch [4/10], Step [15500/22921], Loss: -9897.3730\n",
      "Epoch [4/10], Step [15600/22921], Loss: -7031.9346\n",
      "Epoch [4/10], Step [15700/22921], Loss: -9280.5146\n",
      "Epoch [4/10], Step [15800/22921], Loss: -2562.9146\n",
      "Epoch [4/10], Step [15900/22921], Loss: -11225.9629\n",
      "Epoch [4/10], Step [16000/22921], Loss: -642.2184\n",
      "Epoch [4/10], Step [16100/22921], Loss: -6429.5430\n",
      "Epoch [4/10], Step [16200/22921], Loss: -10298.5488\n",
      "Epoch [4/10], Step [16300/22921], Loss: -17076.3105\n",
      "Epoch [4/10], Step [16400/22921], Loss: -9354.7588\n",
      "Epoch [4/10], Step [16500/22921], Loss: -16793.3848\n",
      "Epoch [4/10], Step [16600/22921], Loss: -3233.5786\n",
      "Epoch [4/10], Step [16700/22921], Loss: -13272.5918\n",
      "Epoch [4/10], Step [16800/22921], Loss: -9074.5986\n",
      "Epoch [4/10], Step [16900/22921], Loss: -11032.0176\n",
      "Epoch [4/10], Step [17000/22921], Loss: -11044.2168\n",
      "Epoch [4/10], Step [17100/22921], Loss: -19187.2402\n",
      "Epoch [4/10], Step [17200/22921], Loss: -9767.5605\n",
      "Epoch [4/10], Step [17300/22921], Loss: -14993.2158\n",
      "Epoch [4/10], Step [17400/22921], Loss: -4568.2100\n",
      "Epoch [4/10], Step [17500/22921], Loss: -13720.9238\n",
      "Epoch [4/10], Step [17600/22921], Loss: -7195.6382\n",
      "Epoch [4/10], Step [17700/22921], Loss: -5238.7803\n",
      "Epoch [4/10], Step [17800/22921], Loss: -12784.1592\n",
      "Epoch [4/10], Step [17900/22921], Loss: -12142.6387\n",
      "Epoch [4/10], Step [18000/22921], Loss: -16100.3047\n",
      "Epoch [4/10], Step [18100/22921], Loss: -11842.6289\n",
      "Epoch [4/10], Step [18200/22921], Loss: -8232.7480\n",
      "Epoch [4/10], Step [18300/22921], Loss: -9561.0703\n",
      "Epoch [4/10], Step [18400/22921], Loss: -8251.7080\n",
      "Epoch [4/10], Step [18500/22921], Loss: -17181.8711\n",
      "Epoch [4/10], Step [18600/22921], Loss: -6947.1626\n",
      "Epoch [4/10], Step [18700/22921], Loss: -9272.8779\n",
      "Epoch [4/10], Step [18800/22921], Loss: -11935.3672\n",
      "Epoch [4/10], Step [18900/22921], Loss: -11617.4385\n",
      "Epoch [4/10], Step [19000/22921], Loss: -9636.6221\n",
      "Epoch [4/10], Step [19100/22921], Loss: -6986.5220\n",
      "Epoch [4/10], Step [19200/22921], Loss: -6328.6084\n",
      "Epoch [4/10], Step [19300/22921], Loss: -5335.3203\n",
      "Epoch [4/10], Step [19400/22921], Loss: -8679.4902\n",
      "Epoch [4/10], Step [19500/22921], Loss: -11697.1270\n",
      "Epoch [4/10], Step [19600/22921], Loss: -6691.3193\n",
      "Epoch [4/10], Step [19700/22921], Loss: -12058.3389\n",
      "Epoch [4/10], Step [19800/22921], Loss: -10059.7725\n",
      "Epoch [4/10], Step [19900/22921], Loss: -9399.3008\n",
      "Epoch [4/10], Step [20000/22921], Loss: -11762.2598\n",
      "Epoch [4/10], Step [20100/22921], Loss: -3700.8789\n",
      "Epoch [4/10], Step [20200/22921], Loss: -14145.7393\n",
      "Epoch [4/10], Step [20300/22921], Loss: -16184.5674\n",
      "Epoch [4/10], Step [20400/22921], Loss: -8101.4282\n",
      "Epoch [4/10], Step [20500/22921], Loss: -14194.0723\n",
      "Epoch [4/10], Step [20600/22921], Loss: -7443.3799\n",
      "Epoch [4/10], Step [20700/22921], Loss: -6096.8037\n",
      "Epoch [4/10], Step [20800/22921], Loss: -4408.0225\n",
      "Epoch [4/10], Step [20900/22921], Loss: -10523.1855\n",
      "Epoch [4/10], Step [21000/22921], Loss: -4418.2173\n",
      "Epoch [4/10], Step [21100/22921], Loss: -7825.4502\n",
      "Epoch [4/10], Step [21200/22921], Loss: -9537.3340\n",
      "Epoch [4/10], Step [21300/22921], Loss: -10912.1777\n",
      "Epoch [4/10], Step [21400/22921], Loss: -11265.8076\n",
      "Epoch [4/10], Step [21500/22921], Loss: -5126.3120\n",
      "Epoch [4/10], Step [21600/22921], Loss: -4789.5879\n",
      "Epoch [4/10], Step [21700/22921], Loss: -15069.4824\n",
      "Epoch [4/10], Step [21800/22921], Loss: -11999.9668\n",
      "Epoch [4/10], Step [21900/22921], Loss: -7551.3096\n",
      "Epoch [4/10], Step [22000/22921], Loss: -16149.9297\n",
      "Epoch [4/10], Step [22100/22921], Loss: -12727.8594\n",
      "Epoch [4/10], Step [22200/22921], Loss: -10675.9238\n",
      "Epoch [4/10], Step [22300/22921], Loss: -7584.5923\n",
      "Epoch [4/10], Step [22400/22921], Loss: -9318.0117\n",
      "Epoch [4/10], Step [22500/22921], Loss: -19692.7031\n",
      "Epoch [4/10], Step [22600/22921], Loss: -12797.6729\n",
      "Epoch [4/10], Step [22700/22921], Loss: -8656.2002\n",
      "Epoch [4/10], Step [22800/22921], Loss: -14904.6855\n",
      "Epoch [4/10], Step [22900/22921], Loss: -7980.8438\n",
      "Epoch [4/10], Training Accuracy: 0.4014\n",
      "Epoch [5/10], Step [100/22921], Loss: -10770.6582\n",
      "Epoch [5/10], Step [200/22921], Loss: -12520.8223\n",
      "Epoch [5/10], Step [300/22921], Loss: -14274.8955\n",
      "Epoch [5/10], Step [400/22921], Loss: -7668.1475\n",
      "Epoch [5/10], Step [500/22921], Loss: -23378.4160\n",
      "Epoch [5/10], Step [600/22921], Loss: -6986.2280\n",
      "Epoch [5/10], Step [700/22921], Loss: -9791.3877\n",
      "Epoch [5/10], Step [800/22921], Loss: -13301.6592\n",
      "Epoch [5/10], Step [900/22921], Loss: -8059.6611\n",
      "Epoch [5/10], Step [1000/22921], Loss: -12979.2246\n",
      "Epoch [5/10], Step [1100/22921], Loss: -11587.6611\n",
      "Epoch [5/10], Step [1200/22921], Loss: -5624.7266\n",
      "Epoch [5/10], Step [1300/22921], Loss: -7390.7017\n",
      "Epoch [5/10], Step [1400/22921], Loss: -9864.4746\n",
      "Epoch [5/10], Step [1500/22921], Loss: -10932.8994\n",
      "Epoch [5/10], Step [1600/22921], Loss: -8120.1533\n",
      "Epoch [5/10], Step [1700/22921], Loss: -15904.6377\n",
      "Epoch [5/10], Step [1800/22921], Loss: -12384.1855\n",
      "Epoch [5/10], Step [1900/22921], Loss: -17355.2285\n",
      "Epoch [5/10], Step [2000/22921], Loss: -21628.9336\n",
      "Epoch [5/10], Step [2100/22921], Loss: -11713.0811\n",
      "Epoch [5/10], Step [2200/22921], Loss: -17054.4336\n",
      "Epoch [5/10], Step [2300/22921], Loss: -11737.4033\n",
      "Epoch [5/10], Step [2400/22921], Loss: -3916.3843\n",
      "Epoch [5/10], Step [2500/22921], Loss: -8553.7051\n",
      "Epoch [5/10], Step [2600/22921], Loss: -13558.1592\n",
      "Epoch [5/10], Step [2700/22921], Loss: -15000.7949\n",
      "Epoch [5/10], Step [2800/22921], Loss: -13228.4668\n",
      "Epoch [5/10], Step [2900/22921], Loss: -11452.9951\n",
      "Epoch [5/10], Step [3000/22921], Loss: -12181.6465\n",
      "Epoch [5/10], Step [3100/22921], Loss: -6814.6279\n",
      "Epoch [5/10], Step [3200/22921], Loss: -10053.1660\n",
      "Epoch [5/10], Step [3300/22921], Loss: -17970.2129\n",
      "Epoch [5/10], Step [3400/22921], Loss: -12592.5801\n",
      "Epoch [5/10], Step [3500/22921], Loss: -13686.7207\n",
      "Epoch [5/10], Step [3600/22921], Loss: -14782.4043\n",
      "Epoch [5/10], Step [3700/22921], Loss: -18406.9434\n",
      "Epoch [5/10], Step [3800/22921], Loss: -10838.6621\n",
      "Epoch [5/10], Step [3900/22921], Loss: -4340.1284\n",
      "Epoch [5/10], Step [4000/22921], Loss: -15567.9531\n",
      "Epoch [5/10], Step [4100/22921], Loss: -10872.8545\n",
      "Epoch [5/10], Step [4200/22921], Loss: -3991.0181\n",
      "Epoch [5/10], Step [4300/22921], Loss: -12712.0859\n",
      "Epoch [5/10], Step [4400/22921], Loss: -17451.8652\n",
      "Epoch [5/10], Step [4500/22921], Loss: -6915.0640\n",
      "Epoch [5/10], Step [4600/22921], Loss: -7650.5664\n",
      "Epoch [5/10], Step [4700/22921], Loss: -4740.8550\n",
      "Epoch [5/10], Step [4800/22921], Loss: -21172.7695\n",
      "Epoch [5/10], Step [4900/22921], Loss: -13520.6406\n",
      "Epoch [5/10], Step [5000/22921], Loss: -14631.7217\n",
      "Epoch [5/10], Step [5100/22921], Loss: -12815.7090\n",
      "Epoch [5/10], Step [5200/22921], Loss: -12462.3496\n",
      "Epoch [5/10], Step [5300/22921], Loss: -12842.7158\n",
      "Epoch [5/10], Step [5400/22921], Loss: -6978.4712\n",
      "Epoch [5/10], Step [5500/22921], Loss: -14338.4717\n",
      "Epoch [5/10], Step [5600/22921], Loss: -11041.3594\n",
      "Epoch [5/10], Step [5700/22921], Loss: -13631.2754\n",
      "Epoch [5/10], Step [5800/22921], Loss: -6638.0376\n",
      "Epoch [5/10], Step [5900/22921], Loss: -10335.7090\n",
      "Epoch [5/10], Step [6000/22921], Loss: -11823.9160\n",
      "Epoch [5/10], Step [6100/22921], Loss: -14794.7285\n",
      "Epoch [5/10], Step [6200/22921], Loss: -9626.3154\n",
      "Epoch [5/10], Step [6300/22921], Loss: -14824.9473\n",
      "Epoch [5/10], Step [6400/22921], Loss: -7419.7080\n",
      "Epoch [5/10], Step [6500/22921], Loss: -11511.3154\n",
      "Epoch [5/10], Step [6600/22921], Loss: -9663.8848\n",
      "Epoch [5/10], Step [6700/22921], Loss: -3348.6750\n",
      "Epoch [5/10], Step [6800/22921], Loss: -23093.8770\n",
      "Epoch [5/10], Step [6900/22921], Loss: -13423.0000\n",
      "Epoch [5/10], Step [7000/22921], Loss: -19407.7773\n",
      "Epoch [5/10], Step [7100/22921], Loss: -15318.7441\n",
      "Epoch [5/10], Step [7200/22921], Loss: -10845.5391\n",
      "Epoch [5/10], Step [7300/22921], Loss: -6738.8398\n",
      "Epoch [5/10], Step [7400/22921], Loss: -16115.0000\n",
      "Epoch [5/10], Step [7500/22921], Loss: -8628.0879\n",
      "Epoch [5/10], Step [7600/22921], Loss: -11640.9795\n",
      "Epoch [5/10], Step [7700/22921], Loss: -12027.9902\n",
      "Epoch [5/10], Step [7800/22921], Loss: -6019.9834\n",
      "Epoch [5/10], Step [7900/22921], Loss: -5272.6743\n",
      "Epoch [5/10], Step [8000/22921], Loss: -14325.9121\n",
      "Epoch [5/10], Step [8100/22921], Loss: -13963.2578\n",
      "Epoch [5/10], Step [8200/22921], Loss: -10955.0615\n",
      "Epoch [5/10], Step [8300/22921], Loss: -20041.4727\n",
      "Epoch [5/10], Step [8400/22921], Loss: -13626.7031\n",
      "Epoch [5/10], Step [8500/22921], Loss: -7956.7900\n",
      "Epoch [5/10], Step [8600/22921], Loss: -19342.4023\n",
      "Epoch [5/10], Step [8700/22921], Loss: -11769.0889\n",
      "Epoch [5/10], Step [8800/22921], Loss: -14820.6973\n",
      "Epoch [5/10], Step [8900/22921], Loss: -9509.9355\n",
      "Epoch [5/10], Step [9000/22921], Loss: -13327.2783\n",
      "Epoch [5/10], Step [9100/22921], Loss: -6479.6016\n",
      "Epoch [5/10], Step [9200/22921], Loss: -17932.2188\n",
      "Epoch [5/10], Step [9300/22921], Loss: -11839.0967\n",
      "Epoch [5/10], Step [9400/22921], Loss: -16821.2285\n",
      "Epoch [5/10], Step [9500/22921], Loss: -13010.0137\n",
      "Epoch [5/10], Step [9600/22921], Loss: -11107.3184\n",
      "Epoch [5/10], Step [9700/22921], Loss: -6134.1851\n",
      "Epoch [5/10], Step [9800/22921], Loss: -11512.4902\n",
      "Epoch [5/10], Step [9900/22921], Loss: -12675.7031\n",
      "Epoch [5/10], Step [10000/22921], Loss: -13456.9580\n",
      "Epoch [5/10], Step [10100/22921], Loss: -12315.6875\n",
      "Epoch [5/10], Step [10200/22921], Loss: -10401.9092\n",
      "Epoch [5/10], Step [10300/22921], Loss: -20823.9316\n",
      "Epoch [5/10], Step [10400/22921], Loss: -7334.2354\n",
      "Epoch [5/10], Step [10500/22921], Loss: -12750.9443\n",
      "Epoch [5/10], Step [10600/22921], Loss: -11989.0752\n",
      "Epoch [5/10], Step [10700/22921], Loss: -23614.4785\n",
      "Epoch [5/10], Step [10800/22921], Loss: -17436.1426\n",
      "Epoch [5/10], Step [10900/22921], Loss: -10084.1504\n",
      "Epoch [5/10], Step [11000/22921], Loss: -9705.6895\n",
      "Epoch [5/10], Step [11100/22921], Loss: -8549.2227\n",
      "Epoch [5/10], Step [11200/22921], Loss: -12835.6504\n",
      "Epoch [5/10], Step [11300/22921], Loss: -12458.8027\n",
      "Epoch [5/10], Step [11400/22921], Loss: -7015.1279\n",
      "Epoch [5/10], Step [11500/22921], Loss: -15994.5234\n",
      "Epoch [5/10], Step [11600/22921], Loss: -10933.5117\n",
      "Epoch [5/10], Step [11700/22921], Loss: -9380.7607\n",
      "Epoch [5/10], Step [11800/22921], Loss: -19171.8008\n",
      "Epoch [5/10], Step [11900/22921], Loss: -17623.9375\n",
      "Epoch [5/10], Step [12000/22921], Loss: -23522.0195\n",
      "Epoch [5/10], Step [12100/22921], Loss: -17266.1484\n",
      "Epoch [5/10], Step [12200/22921], Loss: -9033.8340\n",
      "Epoch [5/10], Step [12300/22921], Loss: -10615.1328\n",
      "Epoch [5/10], Step [12400/22921], Loss: -10231.6904\n",
      "Epoch [5/10], Step [12500/22921], Loss: -9059.9219\n",
      "Epoch [5/10], Step [12600/22921], Loss: -5914.3721\n",
      "Epoch [5/10], Step [12700/22921], Loss: -6709.3311\n",
      "Epoch [5/10], Step [12800/22921], Loss: -13431.2002\n",
      "Epoch [5/10], Step [12900/22921], Loss: -9885.1250\n",
      "Epoch [5/10], Step [13000/22921], Loss: -13457.1016\n",
      "Epoch [5/10], Step [13100/22921], Loss: -17034.9688\n",
      "Epoch [5/10], Step [13200/22921], Loss: -15068.5723\n",
      "Epoch [5/10], Step [13300/22921], Loss: -15082.6562\n",
      "Epoch [5/10], Step [13400/22921], Loss: -14700.0811\n",
      "Epoch [5/10], Step [13500/22921], Loss: -9544.4121\n",
      "Epoch [5/10], Step [13600/22921], Loss: -12339.6406\n",
      "Epoch [5/10], Step [13700/22921], Loss: -12350.9043\n",
      "Epoch [5/10], Step [13800/22921], Loss: -14755.7627\n",
      "Epoch [5/10], Step [13900/22921], Loss: -3193.6411\n",
      "Epoch [5/10], Step [14000/22921], Loss: -19579.3711\n",
      "Epoch [5/10], Step [14100/22921], Loss: -12398.8877\n",
      "Epoch [5/10], Step [14200/22921], Loss: -14011.4688\n",
      "Epoch [5/10], Step [14300/22921], Loss: -9616.4297\n",
      "Epoch [5/10], Step [14400/22921], Loss: -15240.8105\n",
      "Epoch [5/10], Step [14500/22921], Loss: -16058.2627\n",
      "Epoch [5/10], Step [14600/22921], Loss: -18082.1289\n",
      "Epoch [5/10], Step [14700/22921], Loss: -7641.4922\n",
      "Epoch [5/10], Step [14800/22921], Loss: -15296.5254\n",
      "Epoch [5/10], Step [14900/22921], Loss: -16519.4336\n",
      "Epoch [5/10], Step [15000/22921], Loss: -20164.2188\n",
      "Epoch [5/10], Step [15100/22921], Loss: -15339.6543\n",
      "Epoch [5/10], Step [15200/22921], Loss: -23434.1250\n",
      "Epoch [5/10], Step [15300/22921], Loss: -11323.6934\n",
      "Epoch [5/10], Step [15400/22921], Loss: -10928.8496\n",
      "Epoch [5/10], Step [15500/22921], Loss: -13370.2285\n",
      "Epoch [5/10], Step [15600/22921], Loss: -22305.8555\n",
      "Epoch [5/10], Step [15700/22921], Loss: -11771.8311\n",
      "Epoch [5/10], Step [15800/22921], Loss: -5688.3389\n",
      "Epoch [5/10], Step [15900/22921], Loss: -16673.5586\n",
      "Epoch [5/10], Step [16000/22921], Loss: -4477.5596\n",
      "Epoch [5/10], Step [16100/22921], Loss: -10185.5762\n",
      "Epoch [5/10], Step [16200/22921], Loss: -9379.3047\n",
      "Epoch [5/10], Step [16300/22921], Loss: -4489.7588\n",
      "Epoch [5/10], Step [16400/22921], Loss: -9804.7109\n",
      "Epoch [5/10], Step [16500/22921], Loss: -10631.2949\n",
      "Epoch [5/10], Step [16600/22921], Loss: -8594.7871\n",
      "Epoch [5/10], Step [16700/22921], Loss: -11470.1465\n",
      "Epoch [5/10], Step [16800/22921], Loss: -13121.2451\n",
      "Epoch [5/10], Step [16900/22921], Loss: -13544.2471\n",
      "Epoch [5/10], Step [17000/22921], Loss: -10269.7998\n",
      "Epoch [5/10], Step [17100/22921], Loss: -15212.8691\n",
      "Epoch [5/10], Step [17200/22921], Loss: -10699.5557\n",
      "Epoch [5/10], Step [17300/22921], Loss: -11532.8350\n",
      "Epoch [5/10], Step [17400/22921], Loss: -25558.3281\n",
      "Epoch [5/10], Step [17500/22921], Loss: -10728.0537\n",
      "Epoch [5/10], Step [17600/22921], Loss: -5781.9683\n",
      "Epoch [5/10], Step [17700/22921], Loss: -21082.7363\n",
      "Epoch [5/10], Step [17800/22921], Loss: -15308.4531\n",
      "Epoch [5/10], Step [17900/22921], Loss: -24019.4844\n",
      "Epoch [5/10], Step [18000/22921], Loss: -20724.7676\n",
      "Epoch [5/10], Step [18100/22921], Loss: -9127.5840\n",
      "Epoch [5/10], Step [18200/22921], Loss: -4983.2588\n",
      "Epoch [5/10], Step [18300/22921], Loss: -9559.6270\n",
      "Epoch [5/10], Step [18400/22921], Loss: -7072.1250\n",
      "Epoch [5/10], Step [18500/22921], Loss: -19986.3398\n",
      "Epoch [5/10], Step [18600/22921], Loss: -20838.2617\n",
      "Epoch [5/10], Step [18700/22921], Loss: -7925.5186\n",
      "Epoch [5/10], Step [18800/22921], Loss: -22545.9629\n",
      "Epoch [5/10], Step [18900/22921], Loss: -13789.8643\n",
      "Epoch [5/10], Step [19000/22921], Loss: -13802.7080\n",
      "Epoch [5/10], Step [19100/22921], Loss: -17164.7812\n",
      "Epoch [5/10], Step [19200/22921], Loss: -25980.2305\n",
      "Epoch [5/10], Step [19300/22921], Loss: -12582.5156\n",
      "Epoch [5/10], Step [19400/22921], Loss: -12174.2959\n",
      "Epoch [5/10], Step [19500/22921], Loss: -13025.9424\n",
      "Epoch [5/10], Step [19600/22921], Loss: -10093.9102\n",
      "Epoch [5/10], Step [19700/22921], Loss: -16417.4062\n",
      "Epoch [5/10], Step [19800/22921], Loss: -14745.9629\n",
      "Epoch [5/10], Step [19900/22921], Loss: -21506.3242\n",
      "Epoch [5/10], Step [20000/22921], Loss: -10551.7881\n",
      "Epoch [5/10], Step [20100/22921], Loss: -14363.5566\n",
      "Epoch [5/10], Step [20200/22921], Loss: -13952.6465\n",
      "Epoch [5/10], Step [20300/22921], Loss: -13118.1035\n",
      "Epoch [5/10], Step [20400/22921], Loss: -16095.0254\n",
      "Epoch [5/10], Step [20500/22921], Loss: -8054.5142\n",
      "Epoch [5/10], Step [20600/22921], Loss: -11880.2178\n",
      "Epoch [5/10], Step [20700/22921], Loss: -5520.8369\n",
      "Epoch [5/10], Step [20800/22921], Loss: -17852.6895\n",
      "Epoch [5/10], Step [20900/22921], Loss: -17442.6035\n",
      "Epoch [5/10], Step [21000/22921], Loss: -5109.5674\n",
      "Epoch [5/10], Step [21100/22921], Loss: -8097.1069\n",
      "Epoch [5/10], Step [21200/22921], Loss: -23459.0840\n",
      "Epoch [5/10], Step [21300/22921], Loss: -8111.4326\n",
      "Epoch [5/10], Step [21400/22921], Loss: -9400.3691\n",
      "Epoch [5/10], Step [21500/22921], Loss: -11547.8213\n",
      "Epoch [5/10], Step [21600/22921], Loss: -8561.1836\n",
      "Epoch [5/10], Step [21700/22921], Loss: -8997.1709\n",
      "Epoch [5/10], Step [21800/22921], Loss: -8147.3242\n",
      "Epoch [5/10], Step [21900/22921], Loss: -16309.3955\n",
      "Epoch [5/10], Step [22000/22921], Loss: -7732.1187\n",
      "Epoch [5/10], Step [22100/22921], Loss: -13327.5283\n",
      "Epoch [5/10], Step [22200/22921], Loss: -11187.5254\n",
      "Epoch [5/10], Step [22300/22921], Loss: -11628.0000\n",
      "Epoch [5/10], Step [22400/22921], Loss: -7758.7212\n",
      "Epoch [5/10], Step [22500/22921], Loss: -6902.8462\n",
      "Epoch [5/10], Step [22600/22921], Loss: -8204.4043\n",
      "Epoch [5/10], Step [22700/22921], Loss: -17287.1797\n",
      "Epoch [5/10], Step [22800/22921], Loss: -12976.3428\n",
      "Epoch [5/10], Step [22900/22921], Loss: -10823.3672\n",
      "Epoch [5/10], Training Accuracy: 0.4014\n",
      "Epoch [6/10], Step [100/22921], Loss: -19502.3535\n",
      "Epoch [6/10], Step [200/22921], Loss: -20820.4648\n",
      "Epoch [6/10], Step [300/22921], Loss: -8248.2100\n",
      "Epoch [6/10], Step [400/22921], Loss: -10427.9062\n",
      "Epoch [6/10], Step [500/22921], Loss: -21743.8359\n",
      "Epoch [6/10], Step [600/22921], Loss: -18716.2207\n",
      "Epoch [6/10], Step [700/22921], Loss: -25267.1602\n",
      "Epoch [6/10], Step [800/22921], Loss: -2180.1221\n",
      "Epoch [6/10], Step [900/22921], Loss: -10037.0312\n",
      "Epoch [6/10], Step [1000/22921], Loss: -13540.3174\n",
      "Epoch [6/10], Step [1100/22921], Loss: -22732.2285\n",
      "Epoch [6/10], Step [1200/22921], Loss: -19252.0195\n",
      "Epoch [6/10], Step [1300/22921], Loss: -15765.5957\n",
      "Epoch [6/10], Step [1400/22921], Loss: -18407.5879\n",
      "Epoch [6/10], Step [1500/22921], Loss: -13159.3701\n",
      "Epoch [6/10], Step [1600/22921], Loss: -10097.5518\n",
      "Epoch [6/10], Step [1700/22921], Loss: -19333.8535\n",
      "Epoch [6/10], Step [1800/22921], Loss: -10554.9160\n",
      "Epoch [6/10], Step [1900/22921], Loss: -19367.2539\n",
      "Epoch [6/10], Step [2000/22921], Loss: -12334.7480\n",
      "Epoch [6/10], Step [2100/22921], Loss: -15871.9395\n",
      "Epoch [6/10], Step [2200/22921], Loss: -13679.3154\n",
      "Epoch [6/10], Step [2300/22921], Loss: -12366.5156\n",
      "Epoch [6/10], Step [2400/22921], Loss: -16797.6094\n",
      "Epoch [6/10], Step [2500/22921], Loss: -11945.0996\n",
      "Epoch [6/10], Step [2600/22921], Loss: -11955.0449\n",
      "Epoch [6/10], Step [2700/22921], Loss: -14624.3672\n",
      "Epoch [6/10], Step [2800/22921], Loss: -15524.8730\n",
      "Epoch [6/10], Step [2900/22921], Loss: -22197.5879\n",
      "Epoch [6/10], Step [3000/22921], Loss: -15551.3105\n",
      "Epoch [6/10], Step [3100/22921], Loss: -14674.8389\n",
      "Epoch [6/10], Step [3200/22921], Loss: -13351.8564\n",
      "Epoch [6/10], Step [3300/22921], Loss: -13363.2480\n",
      "Epoch [6/10], Step [3400/22921], Loss: -27194.8965\n",
      "Epoch [6/10], Step [3500/22921], Loss: -14278.3467\n",
      "Epoch [6/10], Step [3600/22921], Loss: -9824.8379\n",
      "Epoch [6/10], Step [3700/22921], Loss: -16090.3223\n",
      "Epoch [6/10], Step [3800/22921], Loss: -21024.4336\n",
      "Epoch [6/10], Step [3900/22921], Loss: -19250.5898\n",
      "Epoch [6/10], Step [4000/22921], Loss: -17474.2285\n",
      "Epoch [6/10], Step [4100/22921], Loss: -8968.4482\n",
      "Epoch [6/10], Step [4200/22921], Loss: -15259.1436\n",
      "Epoch [6/10], Step [4300/22921], Loss: -10330.8740\n",
      "Epoch [6/10], Step [4400/22921], Loss: -17082.3398\n",
      "Epoch [6/10], Step [4500/22921], Loss: -17545.5430\n",
      "Epoch [6/10], Step [4600/22921], Loss: -19811.8125\n",
      "Epoch [6/10], Step [4700/22921], Loss: -9913.9219\n",
      "Epoch [6/10], Step [4800/22921], Loss: -6314.3320\n",
      "Epoch [6/10], Step [4900/22921], Loss: -15347.6689\n",
      "Epoch [6/10], Step [5000/22921], Loss: -21685.4590\n",
      "Epoch [6/10], Step [5100/22921], Loss: -15373.7061\n",
      "Epoch [6/10], Step [5200/22921], Loss: -21721.1406\n",
      "Epoch [6/10], Step [5300/22921], Loss: -11775.5498\n",
      "Epoch [6/10], Step [5400/22921], Loss: -4986.1001\n",
      "Epoch [6/10], Step [5500/22921], Loss: -25858.8691\n",
      "Epoch [6/10], Step [5600/22921], Loss: -12713.0234\n",
      "Epoch [6/10], Step [5700/22921], Loss: -19539.6738\n",
      "Epoch [6/10], Step [5800/22921], Loss: -22283.6699\n",
      "Epoch [6/10], Step [5900/22921], Loss: -7282.0806\n",
      "Epoch [6/10], Step [6000/22921], Loss: -24596.2578\n",
      "Epoch [6/10], Step [6100/22921], Loss: -14132.2129\n",
      "Epoch [6/10], Step [6200/22921], Loss: -20531.4766\n",
      "Epoch [6/10], Step [6300/22921], Loss: -14612.0449\n",
      "Epoch [6/10], Step [6400/22921], Loss: -8682.8926\n",
      "Epoch [6/10], Step [6500/22921], Loss: -15550.5840\n",
      "Epoch [6/10], Step [6600/22921], Loss: -16020.3154\n",
      "Epoch [6/10], Step [6700/22921], Loss: -8703.7129\n",
      "Epoch [6/10], Step [6800/22921], Loss: -8252.6748\n",
      "Epoch [6/10], Step [6900/22921], Loss: -24778.0039\n",
      "Epoch [6/10], Step [7000/22921], Loss: -4133.0195\n",
      "Epoch [6/10], Step [7100/22921], Loss: -13787.7686\n",
      "Epoch [6/10], Step [7200/22921], Loss: -9659.3906\n",
      "Epoch [6/10], Step [7300/22921], Loss: -6905.1094\n",
      "Epoch [6/10], Step [7400/22921], Loss: -22114.8457\n",
      "Epoch [6/10], Step [7500/22921], Loss: -19367.3965\n",
      "Epoch [6/10], Step [7600/22921], Loss: -13846.1465\n",
      "Epoch [6/10], Step [7700/22921], Loss: -10162.2832\n",
      "Epoch [6/10], Step [7800/22921], Loss: -15717.9688\n",
      "Epoch [6/10], Step [7900/22921], Loss: -11103.6250\n",
      "Epoch [6/10], Step [8000/22921], Loss: -18983.4688\n",
      "Epoch [6/10], Step [8100/22921], Loss: -21315.4883\n",
      "Epoch [6/10], Step [8200/22921], Loss: -16695.1836\n",
      "Epoch [6/10], Step [8300/22921], Loss: -10675.4531\n",
      "Epoch [6/10], Step [8400/22921], Loss: -21368.5801\n",
      "Epoch [6/10], Step [8500/22921], Loss: -14877.1846\n",
      "Epoch [6/10], Step [8600/22921], Loss: -13958.5439\n",
      "Epoch [6/10], Step [8700/22921], Loss: -12107.3643\n",
      "Epoch [6/10], Step [8800/22921], Loss: -11184.5439\n",
      "Epoch [6/10], Step [8900/22921], Loss: -2798.2922\n",
      "Epoch [6/10], Step [9000/22921], Loss: -14002.3809\n",
      "Epoch [6/10], Step [9100/22921], Loss: -19152.0059\n",
      "Epoch [6/10], Step [9200/22921], Loss: -11687.5879\n",
      "Epoch [6/10], Step [9300/22921], Loss: -10293.1826\n",
      "Epoch [6/10], Step [9400/22921], Loss: -11238.3496\n",
      "Epoch [6/10], Step [9500/22921], Loss: -2811.8843\n",
      "Epoch [6/10], Step [9600/22921], Loss: -15008.3984\n",
      "Epoch [6/10], Step [9700/22921], Loss: -9387.4404\n",
      "Epoch [6/10], Step [9800/22921], Loss: -14092.4922\n",
      "Epoch [6/10], Step [9900/22921], Loss: -1880.4838\n",
      "Epoch [6/10], Step [10000/22921], Loss: -14585.3184\n",
      "Epoch [6/10], Step [10100/22921], Loss: -24014.8438\n",
      "Epoch [6/10], Step [10200/22921], Loss: -16964.7520\n",
      "Epoch [6/10], Step [10300/22921], Loss: -5659.4907\n",
      "Epoch [6/10], Step [10400/22921], Loss: -24544.4434\n",
      "Epoch [6/10], Step [10500/22921], Loss: -14644.0840\n",
      "Epoch [6/10], Step [10600/22921], Loss: -20800.9844\n",
      "Epoch [6/10], Step [10700/22921], Loss: -11354.8809\n",
      "Epoch [6/10], Step [10800/22921], Loss: -19412.9160\n",
      "Epoch [6/10], Step [10900/22921], Loss: -13742.0889\n",
      "Epoch [6/10], Step [11000/22921], Loss: -18020.3789\n",
      "Epoch [6/10], Step [11100/22921], Loss: -10440.9639\n",
      "Epoch [6/10], Step [11200/22921], Loss: -17573.8848\n",
      "Epoch [6/10], Step [11300/22921], Loss: -20440.2188\n",
      "Epoch [6/10], Step [11400/22921], Loss: -17602.2695\n",
      "Epoch [6/10], Step [11500/22921], Loss: -19044.1836\n",
      "Epoch [6/10], Step [11600/22921], Loss: -24777.1953\n",
      "Epoch [6/10], Step [11700/22921], Loss: -8583.3203\n",
      "Epoch [6/10], Step [11800/22921], Loss: -14316.5830\n",
      "Epoch [6/10], Step [11900/22921], Loss: -27701.1035\n",
      "Epoch [6/10], Step [12000/22921], Loss: -12427.6816\n",
      "Epoch [6/10], Step [12100/22921], Loss: -9567.1504\n",
      "Epoch [6/10], Step [12200/22921], Loss: -18669.6113\n",
      "Epoch [6/10], Step [12300/22921], Loss: -9582.1074\n",
      "Epoch [6/10], Step [12400/22921], Loss: -20137.6426\n",
      "Epoch [6/10], Step [12500/22921], Loss: -15354.9219\n",
      "Epoch [6/10], Step [12600/22921], Loss: -14887.2168\n",
      "Epoch [6/10], Step [12700/22921], Loss: -15859.9189\n",
      "Epoch [6/10], Step [12800/22921], Loss: -19239.1387\n",
      "Epoch [6/10], Step [12900/22921], Loss: -20698.0859\n",
      "Epoch [6/10], Step [13000/22921], Loss: -13970.8125\n",
      "Epoch [6/10], Step [13100/22921], Loss: -13981.1738\n",
      "Epoch [6/10], Step [13200/22921], Loss: -13509.8848\n",
      "Epoch [6/10], Step [13300/22921], Loss: -13520.0439\n",
      "Epoch [6/10], Step [13400/22921], Loss: -20296.4375\n",
      "Epoch [6/10], Step [13500/22921], Loss: -17410.3945\n",
      "Epoch [6/10], Step [13600/22921], Loss: -20328.2598\n",
      "Epoch [6/10], Step [13700/22921], Loss: -13078.9688\n",
      "Epoch [6/10], Step [13800/22921], Loss: -9695.4629\n",
      "Epoch [6/10], Step [13900/22921], Loss: -27169.1836\n",
      "Epoch [6/10], Step [14000/22921], Loss: -13109.7998\n",
      "Epoch [6/10], Step [14100/22921], Loss: -27696.8184\n",
      "Epoch [6/10], Step [14200/22921], Loss: -21883.0996\n",
      "Epoch [6/10], Step [14300/22921], Loss: -20926.9531\n",
      "Epoch [6/10], Step [14400/22921], Loss: -10715.2676\n",
      "Epoch [6/10], Step [14500/22921], Loss: -15597.1777\n",
      "Epoch [6/10], Step [14600/22921], Loss: -15608.9424\n",
      "Epoch [6/10], Step [14700/22921], Loss: -18062.2422\n",
      "Epoch [6/10], Step [14800/22921], Loss: -10259.6660\n",
      "Epoch [6/10], Step [14900/22921], Loss: -15156.9482\n",
      "Epoch [6/10], Step [15000/22921], Loss: -22996.6973\n",
      "Epoch [6/10], Step [15100/22921], Loss: -22034.9238\n",
      "Epoch [6/10], Step [15200/22921], Loss: -9800.9453\n",
      "Epoch [6/10], Step [15300/22921], Loss: -17654.9434\n",
      "Epoch [6/10], Step [15400/22921], Loss: -9815.7920\n",
      "Epoch [6/10], Step [15500/22921], Loss: -15717.3047\n",
      "Epoch [6/10], Step [15600/22921], Loss: -9831.3594\n",
      "Epoch [6/10], Step [15700/22921], Loss: -10330.4307\n",
      "Epoch [6/10], Step [15800/22921], Loss: -12306.8594\n",
      "Epoch [6/10], Step [15900/22921], Loss: -20197.6211\n",
      "Epoch [6/10], Step [16000/22921], Loss: -8380.5303\n",
      "Epoch [6/10], Step [16100/22921], Loss: -15787.3887\n",
      "Epoch [6/10], Step [16200/22921], Loss: -18268.3320\n",
      "Epoch [6/10], Step [16300/22921], Loss: -20259.5586\n",
      "Epoch [6/10], Step [16400/22921], Loss: -25714.2871\n",
      "Epoch [6/10], Step [16500/22921], Loss: -19299.6055\n",
      "Epoch [6/10], Step [16600/22921], Loss: -6933.0781\n",
      "Epoch [6/10], Step [16700/22921], Loss: -15858.6455\n",
      "Epoch [6/10], Step [16800/22921], Loss: -20830.6816\n",
      "Epoch [6/10], Step [16900/22921], Loss: -22832.4941\n",
      "Epoch [6/10], Step [17000/22921], Loss: -10928.3799\n",
      "Epoch [6/10], Step [17100/22921], Loss: -20382.1094\n",
      "Epoch [6/10], Step [17200/22921], Loss: -16914.7852\n",
      "Epoch [6/10], Step [17300/22921], Loss: -12944.8057\n",
      "Epoch [6/10], Step [17400/22921], Loss: -8470.3965\n",
      "Epoch [6/10], Step [17500/22921], Loss: -9972.3223\n",
      "Epoch [6/10], Step [17600/22921], Loss: -17465.1289\n",
      "Epoch [6/10], Step [17700/22921], Loss: -14482.0156\n",
      "Epoch [6/10], Step [17800/22921], Loss: -18490.9023\n",
      "Epoch [6/10], Step [17900/22921], Loss: -16504.7852\n",
      "Epoch [6/10], Step [18000/22921], Loss: -15015.7363\n",
      "Epoch [6/10], Step [18100/22921], Loss: -23542.8223\n",
      "Epoch [6/10], Step [18200/22921], Loss: -25065.2520\n",
      "Epoch [6/10], Step [18300/22921], Loss: -18060.6445\n",
      "Epoch [6/10], Step [18400/22921], Loss: -10041.4912\n",
      "Epoch [6/10], Step [18500/22921], Loss: -18089.3867\n",
      "Epoch [6/10], Step [18600/22921], Loss: -9051.1777\n",
      "Epoch [6/10], Step [18700/22921], Loss: -14090.2783\n",
      "Epoch [6/10], Step [18800/22921], Loss: -7050.4282\n",
      "Epoch [6/10], Step [18900/22921], Loss: -4535.7026\n",
      "Epoch [6/10], Step [19000/22921], Loss: -9078.2139\n",
      "Epoch [6/10], Step [19100/22921], Loss: -23721.3789\n",
      "Epoch [6/10], Step [19200/22921], Loss: -8586.3896\n",
      "Epoch [6/10], Step [19300/22921], Loss: -15163.4434\n",
      "Epoch [6/10], Step [19400/22921], Loss: -5563.8853\n",
      "Epoch [6/10], Step [19500/22921], Loss: -27334.0410\n",
      "Epoch [6/10], Step [19600/22921], Loss: -12157.3691\n",
      "Epoch [6/10], Step [19700/22921], Loss: -18249.0996\n",
      "Epoch [6/10], Step [19800/22921], Loss: -17755.9395\n",
      "Epoch [6/10], Step [19900/22921], Loss: -5584.5977\n",
      "Epoch [6/10], Step [20000/22921], Loss: -22862.5410\n",
      "Epoch [6/10], Step [20100/22921], Loss: -18304.3086\n",
      "Epoch [6/10], Step [20200/22921], Loss: -21879.9570\n",
      "Epoch [6/10], Step [20300/22921], Loss: -14258.4092\n",
      "Epoch [6/10], Step [20400/22921], Loss: -9172.9580\n",
      "Epoch [6/10], Step [20500/22921], Loss: -14279.2910\n",
      "Epoch [6/10], Step [20600/22921], Loss: -25517.5977\n",
      "Epoch [6/10], Step [20700/22921], Loss: -33197.2070\n",
      "Epoch [6/10], Step [20800/22921], Loss: -15844.0908\n",
      "Epoch [6/10], Step [20900/22921], Loss: -11764.0283\n",
      "Epoch [6/10], Step [21000/22921], Loss: -17402.8789\n",
      "Epoch [6/10], Step [21100/22921], Loss: -15878.7480\n",
      "Epoch [6/10], Step [21200/22921], Loss: -24603.5977\n",
      "Epoch [6/10], Step [21300/22921], Loss: -27699.1777\n",
      "Epoch [6/10], Step [21400/22921], Loss: -17966.5977\n",
      "Epoch [6/10], Step [21500/22921], Loss: -25684.8789\n",
      "Epoch [6/10], Step [21600/22921], Loss: -16964.0117\n",
      "Epoch [6/10], Step [21700/22921], Loss: -11832.2441\n",
      "Epoch [6/10], Step [21800/22921], Loss: -19563.4316\n",
      "Epoch [6/10], Step [21900/22921], Loss: -12880.2637\n",
      "Epoch [6/10], Step [22000/22921], Loss: -12373.6494\n",
      "Epoch [6/10], Step [22100/22921], Loss: -6707.1313\n",
      "Epoch [6/10], Step [22200/22921], Loss: -18070.7383\n",
      "Epoch [6/10], Step [22300/22921], Loss: -21700.4258\n",
      "Epoch [6/10], Step [22400/22921], Loss: -9824.1309\n",
      "Epoch [6/10], Step [22500/22921], Loss: -7761.2124\n",
      "Epoch [6/10], Step [22600/22921], Loss: -24336.5820\n",
      "Epoch [6/10], Step [22700/22921], Loss: -13472.4531\n",
      "Epoch [6/10], Step [22800/22921], Loss: -16075.7363\n",
      "Epoch [6/10], Step [22900/22921], Loss: -19201.6523\n",
      "Epoch [6/10], Training Accuracy: 0.4014\n",
      "Epoch [7/10], Step [100/22921], Loss: -18180.1895\n",
      "Epoch [7/10], Step [200/22921], Loss: -20792.2402\n",
      "Epoch [7/10], Step [300/22921], Loss: -14564.6826\n",
      "Epoch [7/10], Step [400/22921], Loss: -15615.4238\n",
      "Epoch [7/10], Step [500/22921], Loss: -15627.5293\n",
      "Epoch [7/10], Step [600/22921], Loss: -17724.7012\n",
      "Epoch [7/10], Step [700/22921], Loss: -9911.8086\n",
      "Epoch [7/10], Step [800/22921], Loss: -7308.8071\n",
      "Epoch [7/10], Step [900/22921], Loss: -11493.2842\n",
      "Epoch [7/10], Step [1000/22921], Loss: -20389.6445\n",
      "Epoch [7/10], Step [1100/22921], Loss: -20403.7344\n",
      "Epoch [7/10], Step [1200/22921], Loss: -15706.6299\n",
      "Epoch [7/10], Step [1300/22921], Loss: -6811.2002\n",
      "Epoch [7/10], Step [1400/22921], Loss: -23070.0098\n",
      "Epoch [7/10], Step [1500/22921], Loss: -15740.5283\n",
      "Epoch [7/10], Step [1600/22921], Loss: -17851.6562\n",
      "Epoch [7/10], Step [1700/22921], Loss: -17863.6914\n",
      "Epoch [7/10], Step [1800/22921], Loss: -22608.6172\n",
      "Epoch [7/10], Step [1900/22921], Loss: -20521.4004\n",
      "Epoch [7/10], Step [2000/22921], Loss: -14743.9375\n",
      "Epoch [7/10], Step [2100/22921], Loss: -26346.5254\n",
      "Epoch [7/10], Step [2200/22921], Loss: -20565.0449\n",
      "Epoch [7/10], Step [2300/22921], Loss: -12664.3730\n",
      "Epoch [7/10], Step [2400/22921], Loss: -10560.7402\n",
      "Epoch [7/10], Step [2500/22921], Loss: -6340.7974\n",
      "Epoch [7/10], Step [2600/22921], Loss: -21678.5312\n",
      "Epoch [7/10], Step [2700/22921], Loss: -15344.1562\n",
      "Epoch [7/10], Step [2800/22921], Loss: -18002.9277\n",
      "Epoch [7/10], Step [2900/22921], Loss: -19604.9102\n",
      "Epoch [7/10], Step [3000/22921], Loss: -14846.7188\n",
      "Epoch [7/10], Step [3100/22921], Loss: -26000.4883\n",
      "Epoch [7/10], Step [3200/22921], Loss: -11681.8428\n",
      "Epoch [7/10], Step [3300/22921], Loss: -19660.6680\n",
      "Epoch [7/10], Step [3400/22921], Loss: -16484.4160\n",
      "Epoch [7/10], Step [3500/22921], Loss: -14367.6621\n",
      "Epoch [7/10], Step [3600/22921], Loss: -19170.9629\n",
      "Epoch [7/10], Step [3700/22921], Loss: -15454.0312\n",
      "Epoch [7/10], Step [3800/22921], Loss: -10131.6924\n",
      "Epoch [7/10], Step [3900/22921], Loss: -17610.0215\n",
      "Epoch [7/10], Step [4000/22921], Loss: -9078.1758\n",
      "Epoch [7/10], Step [4100/22921], Loss: -32598.0820\n",
      "Epoch [7/10], Step [4200/22921], Loss: -11230.4658\n",
      "Epoch [7/10], Step [4300/22921], Loss: -18195.2832\n",
      "Epoch [7/10], Step [4400/22921], Loss: -13388.6074\n",
      "Epoch [7/10], Step [4500/22921], Loss: -22508.8965\n",
      "Epoch [7/10], Step [4600/22921], Loss: -24669.6758\n",
      "Epoch [7/10], Step [4700/22921], Loss: -18247.4004\n",
      "Epoch [7/10], Step [4800/22921], Loss: -19333.8730\n",
      "Epoch [7/10], Step [4900/22921], Loss: -28483.7617\n",
      "Epoch [7/10], Step [5000/22921], Loss: -30117.1758\n",
      "Epoch [7/10], Step [5100/22921], Loss: -10225.3301\n",
      "Epoch [7/10], Step [5200/22921], Loss: -28003.4492\n",
      "Epoch [7/10], Step [5300/22921], Loss: -11855.6953\n",
      "Epoch [7/10], Step [5400/22921], Loss: -24806.2754\n",
      "Epoch [7/10], Step [5500/22921], Loss: -22665.6758\n",
      "Epoch [7/10], Step [5600/22921], Loss: -17280.1680\n",
      "Epoch [7/10], Step [5700/22921], Loss: -16211.6504\n",
      "Epoch [7/10], Step [5800/22921], Loss: -14059.8340\n",
      "Epoch [7/10], Step [5900/22921], Loss: -22187.0332\n",
      "Epoch [7/10], Step [6000/22921], Loss: -14620.7314\n",
      "Epoch [7/10], Step [6100/22921], Loss: -15172.9092\n",
      "Epoch [7/10], Step [6200/22921], Loss: -31994.5430\n",
      "Epoch [7/10], Step [6300/22921], Loss: -16279.6016\n",
      "Epoch [7/10], Step [6400/22921], Loss: -15747.3799\n",
      "Epoch [7/10], Step [6500/22921], Loss: -20105.9727\n",
      "Epoch [7/10], Step [6600/22921], Loss: -11419.5479\n",
      "Epoch [7/10], Step [6700/22921], Loss: -15236.3730\n",
      "Epoch [7/10], Step [6800/22921], Loss: -20692.7480\n",
      "Epoch [7/10], Step [6900/22921], Loss: -14713.2402\n",
      "Epoch [7/10], Step [7000/22921], Loss: -17450.5254\n",
      "Epoch [7/10], Step [7100/22921], Loss: -13096.5684\n",
      "Epoch [7/10], Step [7200/22921], Loss: -8191.0732\n",
      "Epoch [7/10], Step [7300/22921], Loss: -19672.4258\n",
      "Epoch [7/10], Step [7400/22921], Loss: -25700.8008\n",
      "Epoch [7/10], Step [7500/22921], Loss: -17510.1328\n",
      "Epoch [7/10], Step [7600/22921], Loss: -18069.9277\n",
      "Epoch [7/10], Step [7700/22921], Loss: -13698.8857\n",
      "Epoch [7/10], Step [7800/22921], Loss: -15352.7061\n",
      "Epoch [7/10], Step [7900/22921], Loss: -24691.5000\n",
      "Epoch [7/10], Step [8000/22921], Loss: -13177.4375\n",
      "Epoch [7/10], Step [8100/22921], Loss: -24725.4844\n",
      "Epoch [7/10], Step [8200/22921], Loss: -18144.6680\n",
      "Epoch [7/10], Step [8300/22921], Loss: -9903.9746\n",
      "Epoch [7/10], Step [8400/22921], Loss: -28630.4414\n",
      "Epoch [7/10], Step [8500/22921], Loss: -36915.4219\n",
      "Epoch [7/10], Step [8600/22921], Loss: -21502.4531\n",
      "Epoch [7/10], Step [8700/22921], Loss: -17654.8301\n",
      "Epoch [7/10], Step [8800/22921], Loss: -23740.0352\n",
      "Epoch [7/10], Step [8900/22921], Loss: -28728.1094\n",
      "Epoch [7/10], Step [9000/22921], Loss: -22114.0078\n",
      "Epoch [7/10], Step [9100/22921], Loss: -8851.7363\n",
      "Epoch [7/10], Step [9200/22921], Loss: -14393.8535\n",
      "Epoch [7/10], Step [9300/22921], Loss: -22159.2383\n",
      "Epoch [7/10], Step [9400/22921], Loss: -14967.7480\n",
      "Epoch [7/10], Step [9500/22921], Loss: -7211.5391\n",
      "Epoch [7/10], Step [9600/22921], Loss: -15541.6699\n",
      "Epoch [7/10], Step [9700/22921], Loss: -14441.5811\n",
      "Epoch [7/10], Step [9800/22921], Loss: -16119.0938\n",
      "Epoch [7/10], Step [9900/22921], Loss: -23916.3965\n",
      "Epoch [7/10], Step [10000/22921], Loss: -12800.9404\n",
      "Epoch [7/10], Step [10100/22921], Loss: -15593.8936\n",
      "Epoch [7/10], Step [10200/22921], Loss: -15046.6738\n",
      "Epoch [7/10], Step [10300/22921], Loss: -21191.8555\n",
      "Epoch [7/10], Step [10400/22921], Loss: -24554.9043\n",
      "Epoch [7/10], Step [10500/22921], Loss: -18428.4141\n",
      "Epoch [7/10], Step [10600/22921], Loss: -32971.1094\n",
      "Epoch [7/10], Step [10700/22921], Loss: -33552.4570\n",
      "Epoch [7/10], Step [10800/22921], Loss: -10072.4111\n",
      "Epoch [7/10], Step [10900/22921], Loss: -29677.6934\n",
      "Epoch [7/10], Step [11000/22921], Loss: -19611.5898\n",
      "Epoch [7/10], Step [11100/22921], Loss: -34763.7852\n",
      "Epoch [7/10], Step [11200/22921], Loss: -24687.7617\n",
      "Epoch [7/10], Step [11300/22921], Loss: -14597.6855\n",
      "Epoch [7/10], Step [11400/22921], Loss: -14607.3750\n",
      "Epoch [7/10], Step [11500/22921], Loss: -19676.8027\n",
      "Epoch [7/10], Step [11600/22921], Loss: -25879.0977\n",
      "Epoch [7/10], Step [11700/22921], Loss: -18578.2676\n",
      "Epoch [7/10], Step [11800/22921], Loss: -18590.3691\n",
      "Epoch [7/10], Step [11900/22921], Loss: -18039.2773\n",
      "Epoch [7/10], Step [12000/22921], Loss: -18051.3887\n",
      "Epoch [7/10], Step [12100/22921], Loss: -19191.8398\n",
      "Epoch [7/10], Step [12200/22921], Loss: -21464.2441\n",
      "Epoch [7/10], Step [12300/22921], Loss: -9043.7803\n",
      "Epoch [7/10], Step [12400/22921], Loss: -16968.5586\n",
      "Epoch [7/10], Step [12500/22921], Loss: -17545.5195\n",
      "Epoch [7/10], Step [12600/22921], Loss: -17557.3711\n",
      "Epoch [7/10], Step [12700/22921], Loss: -22670.4688\n",
      "Epoch [7/10], Step [12800/22921], Loss: -12476.8887\n",
      "Epoch [7/10], Step [12900/22921], Loss: -27239.7812\n",
      "Epoch [7/10], Step [13000/22921], Loss: -23283.8066\n",
      "Epoch [7/10], Step [13100/22921], Loss: -15342.9707\n",
      "Epoch [7/10], Step [13200/22921], Loss: -23313.8008\n",
      "Epoch [7/10], Step [13300/22921], Loss: -22759.8145\n",
      "Epoch [7/10], Step [13400/22921], Loss: -25052.0195\n",
      "Epoch [7/10], Step [13500/22921], Loss: -7406.6030\n",
      "Epoch [7/10], Step [13600/22921], Loss: -15392.4971\n",
      "Epoch [7/10], Step [13700/22921], Loss: -15973.0186\n",
      "Epoch [7/10], Step [13800/22921], Loss: -42813.2383\n",
      "Epoch [7/10], Step [13900/22921], Loss: -11995.7793\n",
      "Epoch [7/10], Step [14000/22921], Loss: -16576.2695\n",
      "Epoch [7/10], Step [14100/22921], Loss: -10295.0342\n",
      "Epoch [7/10], Step [14200/22921], Loss: -11446.2109\n",
      "Epoch [7/10], Step [14300/22921], Loss: -11453.4111\n",
      "Epoch [7/10], Step [14400/22921], Loss: -19483.5898\n",
      "Epoch [7/10], Step [14500/22921], Loss: -16055.9033\n",
      "Epoch [7/10], Step [14600/22921], Loss: -19509.3594\n",
      "Epoch [7/10], Step [14700/22921], Loss: -7464.1118\n",
      "Epoch [7/10], Step [14800/22921], Loss: -14938.2168\n",
      "Epoch [7/10], Step [14900/22921], Loss: -574.9277\n",
      "Epoch [7/10], Step [15000/22921], Loss: -16107.9395\n",
      "Epoch [7/10], Step [15100/22921], Loss: -27630.8086\n",
      "Epoch [7/10], Step [15200/22921], Loss: -13824.1123\n",
      "Epoch [7/10], Step [15300/22921], Loss: -19021.1445\n",
      "Epoch [7/10], Step [15400/22921], Loss: -24801.8438\n",
      "Epoch [7/10], Step [15500/22921], Loss: -16160.6016\n",
      "Epoch [7/10], Step [15600/22921], Loss: -11550.9902\n",
      "Epoch [7/10], Step [15700/22921], Loss: -9246.8418\n",
      "Epoch [7/10], Step [15800/22921], Loss: -29493.3125\n",
      "Epoch [7/10], Step [15900/22921], Loss: -12152.1113\n",
      "Epoch [7/10], Step [16000/22921], Loss: -9843.3506\n",
      "Epoch [7/10], Step [16100/22921], Loss: -11008.5703\n",
      "Epoch [7/10], Step [16200/22921], Loss: -26090.6094\n",
      "Epoch [7/10], Step [16300/22921], Loss: -10443.0166\n",
      "Epoch [7/10], Step [16400/22921], Loss: -20318.6191\n",
      "Epoch [7/10], Step [16500/22921], Loss: -16265.5371\n",
      "Epoch [7/10], Step [16600/22921], Loss: -7556.7134\n",
      "Epoch [7/10], Step [16700/22921], Loss: -19776.6699\n",
      "Epoch [7/10], Step [16800/22921], Loss: -9894.6240\n",
      "Epoch [7/10], Step [16900/22921], Loss: -18054.8828\n",
      "Epoch [7/10], Step [17000/22921], Loss: -19814.2129\n",
      "Epoch [7/10], Step [17100/22921], Loss: -25075.6348\n",
      "Epoch [7/10], Step [17200/22921], Loss: -15754.8125\n",
      "Epoch [7/10], Step [17300/22921], Loss: -24523.8477\n",
      "Epoch [7/10], Step [17400/22921], Loss: -27460.9121\n",
      "Epoch [7/10], Step [17500/22921], Loss: -32155.2461\n",
      "Epoch [7/10], Step [17600/22921], Loss: -22230.6465\n",
      "Epoch [7/10], Step [17700/22921], Loss: -14049.2939\n",
      "Epoch [7/10], Step [17800/22921], Loss: -26358.9902\n",
      "Epoch [7/10], Step [17900/22921], Loss: -18756.5918\n",
      "Epoch [7/10], Step [18000/22921], Loss: -17595.8398\n",
      "Epoch [7/10], Step [18100/22921], Loss: -18780.9121\n",
      "Epoch [7/10], Step [18200/22921], Loss: -7047.3022\n",
      "Epoch [7/10], Step [18300/22921], Loss: -18217.4727\n",
      "Epoch [7/10], Step [18400/22921], Loss: -12348.8906\n",
      "Epoch [7/10], Step [18500/22921], Loss: -14710.3105\n",
      "Epoch [7/10], Step [18600/22921], Loss: -13542.0361\n",
      "Epoch [7/10], Step [18700/22921], Loss: -37118.0859\n",
      "Epoch [7/10], Step [18800/22921], Loss: -12969.7695\n",
      "Epoch [7/10], Step [18900/22921], Loss: -24776.2754\n",
      "Epoch [7/10], Step [19000/22921], Loss: -31875.6934\n",
      "Epoch [7/10], Step [19100/22921], Loss: -15947.8252\n",
      "Epoch [7/10], Step [19200/22921], Loss: -21867.8086\n",
      "Epoch [7/10], Step [19300/22921], Loss: -13602.3857\n",
      "Epoch [7/10], Step [19400/22921], Loss: -19528.7266\n",
      "Epoch [7/10], Step [19500/22921], Loss: -31384.2715\n",
      "Epoch [7/10], Step [19600/22921], Loss: -20739.3496\n",
      "Epoch [7/10], Step [19700/22921], Loss: -10672.8115\n",
      "Epoch [7/10], Step [19800/22921], Loss: -19579.5176\n",
      "Epoch [7/10], Step [19900/22921], Loss: -11874.0547\n",
      "Epoch [7/10], Step [20000/22921], Loss: -11287.7988\n",
      "Epoch [7/10], Step [20100/22921], Loss: -5350.1143\n",
      "Epoch [7/10], Step [20200/22921], Loss: -16654.9785\n",
      "Epoch [7/10], Step [20300/22921], Loss: -19641.4805\n",
      "Epoch [7/10], Step [20400/22921], Loss: -27396.3164\n",
      "Epoch [7/10], Step [20500/22921], Loss: -19666.2871\n",
      "Epoch [7/10], Step [20600/22921], Loss: -21467.3223\n",
      "Epoch [7/10], Step [20700/22921], Loss: -16707.7852\n",
      "Epoch [7/10], Step [20800/22921], Loss: -19106.6523\n",
      "Epoch [7/10], Step [20900/22921], Loss: -26288.0215\n",
      "Epoch [7/10], Step [21000/22921], Loss: -9565.4678\n",
      "Epoch [7/10], Step [21100/22921], Loss: -26321.1562\n",
      "Epoch [7/10], Step [21200/22921], Loss: -21548.8984\n",
      "Epoch [7/10], Step [21300/22921], Loss: -18567.7930\n",
      "Epoch [7/10], Step [21400/22921], Loss: -25172.1230\n",
      "Epoch [7/10], Step [21500/22921], Loss: -21590.1836\n",
      "Epoch [7/10], Step [21600/22921], Loss: -13802.2324\n",
      "Epoch [7/10], Step [21700/22921], Loss: -12009.4922\n",
      "Epoch [7/10], Step [21800/22921], Loss: -11415.9912\n",
      "Epoch [7/10], Step [21900/22921], Loss: -19239.2617\n",
      "Epoch [7/10], Step [22000/22921], Loss: -6016.0166\n",
      "Epoch [7/10], Step [22100/22921], Loss: -17457.1113\n",
      "Epoch [7/10], Step [22200/22921], Loss: -21683.8633\n",
      "Epoch [7/10], Step [22300/22921], Loss: 602.7180\n",
      "Epoch [7/10], Step [22400/22921], Loss: -16282.8311\n",
      "Epoch [7/10], Step [22500/22921], Loss: -15690.1846\n",
      "Epoch [7/10], Step [22600/22921], Loss: -19926.6035\n",
      "Epoch [7/10], Step [22700/22921], Loss: -32626.9316\n",
      "Epoch [7/10], Step [22800/22921], Loss: -17532.6035\n",
      "Epoch [7/10], Step [22900/22921], Loss: -10284.0098\n",
      "Epoch [7/10], Training Accuracy: 0.4014\n",
      "Epoch [8/10], Step [100/22921], Loss: -20583.9531\n",
      "Epoch [8/10], Step [200/22921], Loss: -20596.2773\n",
      "Epoch [8/10], Step [300/22921], Loss: -26670.8633\n",
      "Epoch [8/10], Step [400/22921], Loss: -16376.3438\n",
      "Epoch [8/10], Step [500/22921], Loss: -15779.7285\n",
      "Epoch [8/10], Step [600/22921], Loss: -12753.3047\n",
      "Epoch [8/10], Step [700/22921], Loss: -10330.2510\n",
      "Epoch [8/10], Step [800/22921], Loss: -22498.0840\n",
      "Epoch [8/10], Step [900/22921], Loss: -15819.4873\n",
      "Epoch [8/10], Step [1000/22921], Loss: -22526.5371\n",
      "Epoch [8/10], Step [1100/22921], Loss: -19494.6758\n",
      "Epoch [8/10], Step [1200/22921], Loss: -27430.7812\n",
      "Epoch [8/10], Step [1300/22921], Loss: -26836.7715\n",
      "Epoch [8/10], Step [1400/22921], Loss: -20139.5781\n",
      "Epoch [8/10], Step [1500/22921], Loss: -32975.5664\n",
      "Epoch [8/10], Step [1600/22921], Loss: -34218.4336\n",
      "Epoch [8/10], Step [1700/22921], Loss: -19565.5781\n",
      "Epoch [8/10], Step [1800/22921], Loss: -24472.3984\n",
      "Epoch [8/10], Step [1900/22921], Loss: -23263.3379\n",
      "Epoch [8/10], Step [2000/22921], Loss: -12863.8203\n",
      "Epoch [8/10], Step [2100/22921], Loss: -17161.9531\n",
      "Epoch [8/10], Step [2200/22921], Loss: -26371.6465\n",
      "Epoch [8/10], Step [2300/22921], Loss: -6136.6860\n",
      "Epoch [8/10], Step [2400/22921], Loss: -22105.4961\n",
      "Epoch [8/10], Step [2500/22921], Loss: -10445.2871\n",
      "Epoch [8/10], Step [2600/22921], Loss: -25206.7539\n",
      "Epoch [8/10], Step [2700/22921], Loss: -25836.6406\n",
      "Epoch [8/10], Step [2800/22921], Loss: -24621.0039\n",
      "Epoch [8/10], Step [2900/22921], Loss: -17861.5508\n",
      "Epoch [8/10], Step [3000/22921], Loss: -27733.2539\n",
      "Epoch [8/10], Step [3100/22921], Loss: -20350.2871\n",
      "Epoch [8/10], Step [3200/22921], Loss: -21596.2754\n",
      "Epoch [8/10], Step [3300/22921], Loss: -17287.3555\n",
      "Epoch [8/10], Step [3400/22921], Loss: -19768.7461\n",
      "Epoch [8/10], Step [3500/22921], Loss: -8654.0439\n",
      "Epoch [8/10], Step [3600/22921], Loss: -31543.9336\n",
      "Epoch [8/10], Step [3700/22921], Loss: -24755.7754\n",
      "Epoch [8/10], Step [3800/22921], Loss: -22293.7852\n",
      "Epoch [8/10], Step [3900/22921], Loss: -19209.6445\n",
      "Epoch [8/10], Step [4000/22921], Loss: -18600.7930\n",
      "Epoch [8/10], Step [4100/22921], Loss: -8685.5254\n",
      "Epoch [8/10], Step [4200/22921], Loss: -26693.3281\n",
      "Epoch [8/10], Step [4300/22921], Loss: -19876.6914\n",
      "Epoch [8/10], Step [4400/22921], Loss: -14916.6309\n",
      "Epoch [8/10], Step [4500/22921], Loss: -32337.6562\n",
      "Epoch [8/10], Step [4600/22921], Loss: -37335.7500\n",
      "Epoch [8/10], Step [4700/22921], Loss: -16189.5879\n",
      "Epoch [8/10], Step [4800/22921], Loss: -14330.1768\n",
      "Epoch [8/10], Step [4900/22921], Loss: -22444.0430\n",
      "Epoch [8/10], Step [5000/22921], Loss: -21209.4336\n",
      "Epoch [8/10], Step [5100/22921], Loss: -11859.2686\n",
      "Epoch [8/10], Step [5200/22921], Loss: -19360.4883\n",
      "Epoch [8/10], Step [5300/22921], Loss: -11873.2080\n",
      "Epoch [8/10], Step [5400/22921], Loss: -12505.5889\n",
      "Epoch [8/10], Step [5500/22921], Loss: -8133.5430\n",
      "Epoch [8/10], Step [5600/22921], Loss: -18780.6133\n",
      "Epoch [8/10], Step [5700/22921], Loss: -20043.6934\n",
      "Epoch [8/10], Step [5800/22921], Loss: -22562.1738\n",
      "Epoch [8/10], Step [5900/22921], Loss: -27592.0723\n",
      "Epoch [8/10], Step [6000/22921], Loss: -20706.3691\n",
      "Epoch [8/10], Step [6100/22921], Loss: -22603.0430\n",
      "Epoch [8/10], Step [6200/22921], Loss: -11308.2578\n",
      "Epoch [8/10], Step [6300/22921], Loss: -24516.3867\n",
      "Epoch [8/10], Step [6400/22921], Loss: -11321.8369\n",
      "Epoch [8/10], Step [6500/22921], Loss: -30838.3027\n",
      "Epoch [8/10], Step [6600/22921], Loss: -27708.5586\n",
      "Epoch [8/10], Step [6700/22921], Loss: -11342.1855\n",
      "Epoch [8/10], Step [6800/22921], Loss: -34047.0664\n",
      "Epoch [8/10], Step [6900/22921], Loss: -8201.5547\n",
      "Epoch [8/10], Step [7000/22921], Loss: -23356.2148\n",
      "Epoch [8/10], Step [7100/22921], Loss: -10106.2998\n",
      "Epoch [8/10], Step [7200/22921], Loss: -29706.4746\n",
      "Epoch [8/10], Step [7300/22921], Loss: -22135.3398\n",
      "Epoch [8/10], Step [7400/22921], Loss: -15820.2402\n",
      "Epoch [8/10], Step [7500/22921], Loss: -29759.7559\n",
      "Epoch [8/10], Step [7600/22921], Loss: -12670.6055\n",
      "Epoch [8/10], Step [7700/22921], Loss: -27892.1445\n",
      "Epoch [8/10], Step [7800/22921], Loss: -8245.8770\n",
      "Epoch [8/10], Step [7900/22921], Loss: -13328.1660\n",
      "Epoch [8/10], Step [8000/22921], Loss: -13971.4893\n",
      "Epoch [8/10], Step [8100/22921], Loss: -36219.3828\n",
      "Epoch [8/10], Step [8200/22921], Loss: -23524.2949\n",
      "Epoch [8/10], Step [8300/22921], Loss: -36896.7266\n",
      "Epoch [8/10], Step [8400/22921], Loss: -14640.3721\n",
      "Epoch [8/10], Step [8500/22921], Loss: -26750.1465\n",
      "Epoch [8/10], Step [8600/22921], Loss: -15932.3252\n",
      "Epoch [8/10], Step [8700/22921], Loss: -15941.3652\n",
      "Epoch [8/10], Step [8800/22921], Loss: -30626.0840\n",
      "Epoch [8/10], Step [8900/22921], Loss: -24898.7852\n",
      "Epoch [8/10], Step [9000/22921], Loss: -21081.1035\n",
      "Epoch [8/10], Step [9100/22921], Loss: -26847.0938\n",
      "Epoch [8/10], Step [9200/22921], Loss: -30060.4961\n",
      "Epoch [8/10], Step [9300/22921], Loss: -26877.6191\n",
      "Epoch [8/10], Step [9400/22921], Loss: -28814.5977\n",
      "Epoch [8/10], Step [9500/22921], Loss: -11532.6270\n",
      "Epoch [8/10], Step [9600/22921], Loss: -17308.8438\n",
      "Epoch [8/10], Step [9700/22921], Loss: -17318.4336\n",
      "Epoch [8/10], Step [9800/22921], Loss: -17328.9023\n",
      "Epoch [8/10], Step [9900/22921], Loss: -16054.4873\n",
      "Epoch [8/10], Step [10000/22921], Loss: -27629.6973\n",
      "Epoch [8/10], Step [10100/22921], Loss: -28289.2305\n",
      "Epoch [8/10], Step [10200/22921], Loss: -21229.5273\n",
      "Epoch [8/10], Step [10300/22921], Loss: -23172.2871\n",
      "Epoch [8/10], Step [10400/22921], Loss: -28337.4004\n",
      "Epoch [8/10], Step [10500/22921], Loss: -23842.5840\n",
      "Epoch [8/10], Step [10600/22921], Loss: -9026.6797\n",
      "Epoch [8/10], Step [10700/22921], Loss: -24515.0996\n",
      "Epoch [8/10], Step [10800/22921], Loss: -19365.0195\n",
      "Epoch [8/10], Step [10900/22921], Loss: -23251.3242\n",
      "Epoch [8/10], Step [11000/22921], Loss: -10986.2207\n",
      "Epoch [8/10], Step [11100/22921], Loss: -16165.7910\n",
      "Epoch [8/10], Step [11200/22921], Loss: -12293.2402\n",
      "Epoch [8/10], Step [11300/22921], Loss: -18127.2852\n",
      "Epoch [8/10], Step [11400/22921], Loss: -19433.9766\n",
      "Epoch [8/10], Step [11500/22921], Loss: -22038.2520\n",
      "Epoch [8/10], Step [11600/22921], Loss: -43453.1953\n",
      "Epoch [8/10], Step [11700/22921], Loss: -22064.2930\n",
      "Epoch [8/10], Step [11800/22921], Loss: -26622.4844\n",
      "Epoch [8/10], Step [11900/22921], Loss: -7146.8291\n",
      "Epoch [8/10], Step [12000/22921], Loss: -14951.7090\n",
      "Epoch [8/10], Step [12100/22921], Loss: -14960.2402\n",
      "Epoch [8/10], Step [12200/22921], Loss: -22127.1777\n",
      "Epoch [8/10], Step [12300/22921], Loss: -26046.7227\n",
      "Epoch [8/10], Step [12400/22921], Loss: -25409.4961\n",
      "Epoch [8/10], Step [12500/22921], Loss: -32594.3711\n",
      "Epoch [8/10], Step [12600/22921], Loss: -26091.6680\n",
      "Epoch [8/10], Step [12700/22921], Loss: -27411.4434\n",
      "Epoch [8/10], Step [12800/22921], Loss: -20243.8398\n",
      "Epoch [8/10], Step [12900/22921], Loss: -32670.2129\n",
      "Epoch [8/10], Step [13000/22921], Loss: -24843.5566\n",
      "Epoch [8/10], Step [13100/22921], Loss: -20933.0684\n",
      "Epoch [8/10], Step [13200/22921], Loss: -16363.2500\n",
      "Epoch [8/10], Step [13300/22921], Loss: -20301.9902\n",
      "Epoch [8/10], Step [13400/22921], Loss: -22279.1582\n",
      "Epoch [8/10], Step [13500/22921], Loss: -13768.9355\n",
      "Epoch [8/10], Step [13600/22921], Loss: -22304.8164\n",
      "Epoch [8/10], Step [13700/22921], Loss: -35446.8750\n",
      "Epoch [8/10], Step [13800/22921], Loss: -15106.6924\n",
      "Epoch [8/10], Step [13900/22921], Loss: -31545.2188\n",
      "Epoch [8/10], Step [14000/22921], Loss: -12493.7051\n",
      "Epoch [8/10], Step [14100/22921], Loss: -13817.0576\n",
      "Epoch [8/10], Step [14200/22921], Loss: -4608.4697\n",
      "Epoch [8/10], Step [14300/22921], Loss: -17126.4961\n",
      "Epoch [8/10], Step [14400/22921], Loss: -10545.4727\n",
      "Epoch [8/10], Step [14500/22921], Loss: -20443.3535\n",
      "Epoch [8/10], Step [14600/22921], Loss: -19135.5137\n",
      "Epoch [8/10], Step [14700/22921], Loss: -28390.0527\n",
      "Epoch [8/10], Step [14800/22921], Loss: -19817.9336\n",
      "Epoch [8/10], Step [14900/22921], Loss: -19167.7832\n",
      "Epoch [8/10], Step [15000/22921], Loss: -27775.3750\n",
      "Epoch [8/10], Step [15100/22921], Loss: -27129.2227\n",
      "Epoch [8/10], Step [15200/22921], Loss: -21847.8340\n",
      "Epoch [8/10], Step [15300/22921], Loss: -24510.8320\n",
      "Epoch [8/10], Step [15400/22921], Loss: -35793.7578\n",
      "Epoch [8/10], Step [15500/22921], Loss: -12601.0732\n",
      "Epoch [8/10], Step [15600/22921], Loss: -26543.0723\n",
      "Epoch [8/10], Step [15700/22921], Loss: -15270.7598\n",
      "Epoch [8/10], Step [15800/22921], Loss: -20593.6133\n",
      "Epoch [8/10], Step [15900/22921], Loss: -23263.6055\n",
      "Epoch [8/10], Step [16000/22921], Loss: -31923.0254\n",
      "Epoch [8/10], Step [16100/22921], Loss: -9316.1309\n",
      "Epoch [8/10], Step [16200/22921], Loss: -24634.4375\n",
      "Epoch [8/10], Step [16300/22921], Loss: -31310.1777\n",
      "Epoch [8/10], Step [16400/22921], Loss: -11997.6484\n",
      "Epoch [8/10], Step [16500/22921], Loss: -22007.5781\n",
      "Epoch [8/10], Step [16600/22921], Loss: -6005.4575\n",
      "Epoch [8/10], Step [16700/22921], Loss: -42728.6211\n",
      "Epoch [8/10], Step [16800/22921], Loss: -8683.9697\n",
      "Epoch [8/10], Step [16900/22921], Loss: -26735.7070\n",
      "Epoch [8/10], Step [17000/22921], Loss: -32100.1094\n",
      "Epoch [8/10], Step [17100/22921], Loss: -12044.4453\n",
      "Epoch [8/10], Step [17200/22921], Loss: -26110.9062\n",
      "Epoch [8/10], Step [17300/22921], Loss: -16077.3564\n",
      "Epoch [8/10], Step [17400/22921], Loss: -37534.0391\n",
      "Epoch [8/10], Step [17500/22921], Loss: -13412.4814\n",
      "Epoch [8/10], Step [17600/22921], Loss: -25497.8379\n",
      "Epoch [8/10], Step [17700/22921], Loss: -27525.6621\n",
      "Epoch [8/10], Step [17800/22921], Loss: -22167.3867\n",
      "Epoch [8/10], Step [17900/22921], Loss: -48393.2227\n",
      "Epoch [8/10], Step [18000/22921], Loss: -22865.3906\n",
      "Epoch [8/10], Step [18100/22921], Loss: -21532.4082\n",
      "Epoch [8/10], Step [18200/22921], Loss: -30970.3242\n",
      "Epoch [8/10], Step [18300/22921], Loss: -12799.2607\n",
      "Epoch [8/10], Step [18400/22921], Loss: -16850.3730\n",
      "Epoch [8/10], Step [18500/22921], Loss: -9441.5635\n",
      "Epoch [8/10], Step [18600/22921], Loss: -17543.8418\n",
      "Epoch [8/10], Step [18700/22921], Loss: -22279.5059\n",
      "Epoch [8/10], Step [18800/22921], Loss: -16212.3643\n",
      "Epoch [8/10], Step [18900/22921], Loss: -29738.6836\n",
      "Epoch [8/10], Step [19000/22921], Loss: -27726.8848\n",
      "Epoch [8/10], Step [19100/22921], Loss: -26389.2188\n",
      "Epoch [8/10], Step [19200/22921], Loss: -10155.2275\n",
      "Epoch [8/10], Step [19300/22921], Loss: -16934.6602\n",
      "Epoch [8/10], Step [19400/22921], Loss: -11521.8652\n",
      "Epoch [8/10], Step [19500/22921], Loss: -26448.2871\n",
      "Epoch [8/10], Step [19600/22921], Loss: -16285.0342\n",
      "Epoch [8/10], Step [19700/22921], Loss: -22403.9531\n",
      "Epoch [8/10], Step [19800/22921], Loss: -33963.5547\n",
      "Epoch [8/10], Step [19900/22921], Loss: -30585.4629\n",
      "Epoch [8/10], Step [20000/22921], Loss: -14281.7637\n",
      "Epoch [8/10], Step [20100/22921], Loss: -25177.4414\n",
      "Epoch [8/10], Step [20200/22921], Loss: -18383.2812\n",
      "Epoch [8/10], Step [20300/22921], Loss: -19756.6680\n",
      "Epoch [8/10], Step [20400/22921], Loss: -27265.3379\n",
      "Epoch [8/10], Step [20500/22921], Loss: -19096.6934\n",
      "Epoch [8/10], Step [20600/22921], Loss: -18424.7383\n",
      "Epoch [8/10], Step [20700/22921], Loss: -13655.6064\n",
      "Epoch [8/10], Step [20800/22921], Loss: -31424.2500\n",
      "Epoch [8/10], Step [20900/22921], Loss: -16404.2812\n",
      "Epoch [8/10], Step [21000/22921], Loss: -25987.1934\n",
      "Epoch [8/10], Step [21100/22921], Loss: -21211.7832\n",
      "Epoch [8/10], Step [21200/22921], Loss: -19169.7578\n",
      "Epoch [8/10], Step [21300/22921], Loss: -28085.2598\n",
      "Epoch [8/10], Step [21400/22921], Loss: -23302.2148\n",
      "Epoch [8/10], Step [21500/22921], Loss: -10971.3799\n",
      "Epoch [8/10], Step [21600/22921], Loss: -24699.3105\n",
      "Epoch [8/10], Step [21700/22921], Loss: -12356.3477\n",
      "Epoch [8/10], Step [21800/22921], Loss: -24039.1836\n",
      "Epoch [8/10], Step [21900/22921], Loss: -17180.5312\n",
      "Epoch [8/10], Step [22000/22921], Loss: -17877.1035\n",
      "Epoch [8/10], Step [22100/22921], Loss: -23391.2402\n",
      "Epoch [8/10], Step [22200/22921], Loss: -4130.0127\n",
      "Epoch [8/10], Step [22300/22921], Loss: -4820.9907\n",
      "Epoch [8/10], Step [22400/22921], Loss: -12403.5488\n",
      "Epoch [8/10], Step [22500/22921], Loss: -19994.2461\n",
      "Epoch [8/10], Step [22600/22921], Loss: -31041.1992\n",
      "Epoch [8/10], Step [22700/22921], Loss: -6901.9077\n",
      "Epoch [8/10], Step [22800/22921], Loss: -24169.3867\n",
      "Epoch [8/10], Step [22900/22921], Loss: -22109.8652\n",
      "Epoch [8/10], Training Accuracy: 0.4014\n",
      "Epoch [9/10], Step [100/22921], Loss: -22815.8711\n",
      "Epoch [9/10], Step [200/22921], Loss: 0.0000\n",
      "Epoch [9/10], Step [300/22921], Loss: -27684.9414\n",
      "Epoch [9/10], Step [400/22921], Loss: -22160.4844\n",
      "Epoch [9/10], Step [500/22921], Loss: -25636.9824\n",
      "Epoch [9/10], Step [600/22921], Loss: -13865.2441\n",
      "Epoch [9/10], Step [700/22921], Loss: -27052.1465\n",
      "Epoch [9/10], Step [800/22921], Loss: -21514.4258\n",
      "Epoch [9/10], Step [900/22921], Loss: -13193.8018\n",
      "Epoch [9/10], Step [1000/22921], Loss: -29180.4160\n",
      "Epoch [9/10], Step [1100/22921], Loss: -15293.7578\n",
      "Epoch [9/10], Step [1200/22921], Loss: -31995.8379\n",
      "Epoch [9/10], Step [1300/22921], Loss: -44539.5430\n",
      "Epoch [9/10], Step [1400/22921], Loss: -16015.1953\n",
      "Epoch [9/10], Step [1500/22921], Loss: -20900.3027\n",
      "Epoch [9/10], Step [1600/22921], Loss: -29972.9102\n",
      "Epoch [9/10], Step [1700/22921], Loss: -20923.2852\n",
      "Epoch [9/10], Step [1800/22921], Loss: -21631.9629\n",
      "Epoch [9/10], Step [1900/22921], Loss: -26531.4531\n",
      "Epoch [9/10], Step [2000/22921], Loss: -19559.6445\n",
      "Epoch [9/10], Step [2100/22921], Loss: -19569.8164\n",
      "Epoch [9/10], Step [2200/22921], Loss: -17482.3887\n",
      "Epoch [9/10], Step [2300/22921], Loss: -34283.8438\n",
      "Epoch [9/10], Step [2400/22921], Loss: -24501.5820\n",
      "Epoch [9/10], Step [2500/22921], Loss: -12607.3809\n",
      "Epoch [9/10], Step [2600/22921], Loss: -5605.9897\n",
      "Epoch [9/10], Step [2700/22921], Loss: -28745.7148\n",
      "Epoch [9/10], Step [2800/22921], Loss: -23850.4648\n",
      "Epoch [9/10], Step [2900/22921], Loss: -18248.5527\n",
      "Epoch [9/10], Step [3000/22921], Loss: -25983.5039\n",
      "Epoch [9/10], Step [3100/22921], Loss: -4215.7520\n",
      "Epoch [9/10], Step [3200/22921], Loss: -26714.6680\n",
      "Epoch [9/10], Step [3300/22921], Loss: -7033.9424\n",
      "Epoch [9/10], Step [3400/22921], Loss: -35189.7109\n",
      "Epoch [9/10], Step [3500/22921], Loss: -25350.2754\n",
      "Epoch [9/10], Step [3600/22921], Loss: -21136.2617\n",
      "Epoch [9/10], Step [3700/22921], Loss: -9868.9941\n",
      "Epoch [9/10], Step [3800/22921], Loss: -29623.3750\n",
      "Epoch [9/10], Step [3900/22921], Loss: -16936.3809\n",
      "Epoch [9/10], Step [4000/22921], Loss: -13415.2969\n",
      "Epoch [9/10], Step [4100/22921], Loss: -28964.4629\n",
      "Epoch [9/10], Step [4200/22921], Loss: -26152.8789\n",
      "Epoch [9/10], Step [4300/22921], Loss: -16972.9023\n",
      "Epoch [9/10], Step [4400/22921], Loss: -8490.7266\n",
      "Epoch [9/10], Step [4500/22921], Loss: -15574.2051\n",
      "Epoch [9/10], Step [4600/22921], Loss: -9916.3965\n",
      "Epoch [9/10], Step [4700/22921], Loss: -23386.8574\n",
      "Epoch [9/10], Step [4800/22921], Loss: -31198.9629\n",
      "Epoch [9/10], Step [4900/22921], Loss: -44693.8633\n",
      "Epoch [9/10], Step [5000/22921], Loss: -4258.7500\n",
      "Epoch [9/10], Step [5100/22921], Loss: -26987.0312\n",
      "Epoch [9/10], Step [5200/22921], Loss: -23448.7324\n",
      "Epoch [9/10], Step [5300/22921], Loss: -24172.0195\n",
      "Epoch [9/10], Step [5400/22921], Loss: -22762.2305\n",
      "Epoch [9/10], Step [5500/22921], Loss: -31314.6758\n",
      "Epoch [9/10], Step [5600/22921], Loss: -28483.5059\n",
      "Epoch [9/10], Step [5700/22921], Loss: -27073.6914\n",
      "Epoch [9/10], Step [5800/22921], Loss: -12118.4551\n",
      "Epoch [9/10], Step [5900/22921], Loss: -24249.0625\n",
      "Epoch [9/10], Step [6000/22921], Loss: -16412.5977\n",
      "Epoch [9/10], Step [6100/22921], Loss: -22846.7949\n",
      "Epoch [9/10], Step [6200/22921], Loss: -22858.8555\n",
      "Epoch [9/10], Step [6300/22921], Loss: -17868.2578\n",
      "Epoch [9/10], Step [6400/22921], Loss: -24313.7129\n",
      "Epoch [9/10], Step [6500/22921], Loss: -21463.7070\n",
      "Epoch [9/10], Step [6600/22921], Loss: -30064.7285\n",
      "Epoch [9/10], Step [6700/22921], Loss: -13607.9248\n",
      "Epoch [9/10], Step [6800/22921], Loss: -18631.4199\n",
      "Epoch [9/10], Step [6900/22921], Loss: -29396.2383\n",
      "Epoch [9/10], Step [7000/22921], Loss: -17933.5098\n",
      "Epoch [9/10], Step [7100/22921], Loss: -31579.6836\n",
      "Epoch [9/10], Step [7200/22921], Loss: -26569.4258\n",
      "Epoch [9/10], Step [7300/22921], Loss: -32332.0566\n",
      "Epoch [9/10], Step [7400/22921], Loss: -13658.3965\n",
      "Epoch [9/10], Step [7500/22921], Loss: -25892.5918\n",
      "Epoch [9/10], Step [7600/22921], Loss: -18709.6914\n",
      "Epoch [9/10], Step [7700/22921], Loss: -28799.8184\n",
      "Epoch [9/10], Step [7800/22921], Loss: -42501.2227\n",
      "Epoch [9/10], Step [7900/22921], Loss: -31712.2656\n",
      "Epoch [9/10], Step [8000/22921], Loss: -20912.0195\n",
      "Epoch [9/10], Step [8100/22921], Loss: -24531.1562\n",
      "Epoch [9/10], Step [8200/22921], Loss: -24543.3848\n",
      "Epoch [9/10], Step [8300/22921], Loss: -33944.4414\n",
      "Epoch [9/10], Step [8400/22921], Loss: -22400.3398\n",
      "Epoch [9/10], Step [8500/22921], Loss: -23857.3047\n",
      "Epoch [9/10], Step [8600/22921], Loss: -37612.2461\n",
      "Epoch [9/10], Step [8700/22921], Loss: -19539.6250\n",
      "Epoch [9/10], Step [8800/22921], Loss: -39823.1289\n",
      "Epoch [9/10], Step [8900/22921], Loss: -31150.4473\n",
      "Epoch [9/10], Step [9000/22921], Loss: -20294.9219\n",
      "Epoch [9/10], Step [9100/22921], Loss: -12328.1504\n",
      "Epoch [9/10], Step [9200/22921], Loss: -33375.5234\n",
      "Epoch [9/10], Step [9300/22921], Loss: -16696.2148\n",
      "Epoch [9/10], Step [9400/22921], Loss: -27599.4492\n",
      "Epoch [9/10], Step [9500/22921], Loss: -16713.5938\n",
      "Epoch [9/10], Step [9600/22921], Loss: -39261.1719\n",
      "Epoch [9/10], Step [9700/22921], Loss: -25460.1816\n",
      "Epoch [9/10], Step [9800/22921], Loss: -26927.7969\n",
      "Epoch [9/10], Step [9900/22921], Loss: -24757.4355\n",
      "Epoch [9/10], Step [10000/22921], Loss: -13113.6143\n",
      "Epoch [9/10], Step [10100/22921], Loss: -21138.3203\n",
      "Epoch [9/10], Step [10200/22921], Loss: -24795.4004\n",
      "Epoch [9/10], Step [10300/22921], Loss: -26266.7930\n",
      "Epoch [9/10], Step [10400/22921], Loss: -21899.9238\n",
      "Epoch [9/10], Step [10500/22921], Loss: -22641.8652\n",
      "Epoch [9/10], Step [10600/22921], Loss: -16807.3691\n",
      "Epoch [9/10], Step [10700/22921], Loss: -22665.4004\n",
      "Epoch [9/10], Step [10800/22921], Loss: -10241.2910\n",
      "Epoch [9/10], Step [10900/22921], Loss: -45377.2461\n",
      "Epoch [9/10], Step [11000/22921], Loss: -19771.2969\n",
      "Epoch [9/10], Step [11100/22921], Loss: -19781.7910\n",
      "Epoch [9/10], Step [11200/22921], Loss: -19059.4258\n",
      "Epoch [9/10], Step [11300/22921], Loss: -19802.7168\n",
      "Epoch [9/10], Step [11400/22921], Loss: -20546.5508\n",
      "Epoch [9/10], Step [11500/22921], Loss: -39645.5859\n",
      "Epoch [9/10], Step [11600/22921], Loss: -30851.9316\n",
      "Epoch [9/10], Step [11700/22921], Loss: -24988.6562\n",
      "Epoch [9/10], Step [11800/22921], Loss: -14707.0205\n",
      "Epoch [9/10], Step [11900/22921], Loss: -41199.8477\n",
      "Epoch [9/10], Step [12000/22921], Loss: -24290.8809\n",
      "Epoch [9/10], Step [12100/22921], Loss: -29458.0039\n",
      "Epoch [9/10], Step [12200/22921], Loss: -20631.8652\n",
      "Epoch [9/10], Step [12300/22921], Loss: -27276.9473\n",
      "Epoch [9/10], Step [12400/22921], Loss: -5900.7529\n",
      "Epoch [9/10], Step [12500/22921], Loss: -35422.6836\n",
      "Epoch [9/10], Step [12600/22921], Loss: -18458.7969\n",
      "Epoch [9/10], Step [12700/22921], Loss: -16251.8574\n",
      "Epoch [9/10], Step [12800/22921], Loss: -32520.6211\n",
      "Epoch [9/10], Step [12900/22921], Loss: -23663.4277\n",
      "Epoch [9/10], Step [13000/22921], Loss: -17016.3867\n",
      "Epoch [9/10], Step [13100/22921], Loss: -30349.1250\n",
      "Epoch [9/10], Step [13200/22921], Loss: -11849.5332\n",
      "Epoch [9/10], Step [13300/22921], Loss: -23711.1680\n",
      "Epoch [9/10], Step [13400/22921], Loss: -23722.9727\n",
      "Epoch [9/10], Step [13500/22921], Loss: -24476.6719\n",
      "Epoch [9/10], Step [13600/22921], Loss: -17810.3008\n",
      "Epoch [9/10], Step [13700/22921], Loss: -21531.1289\n",
      "Epoch [9/10], Step [13800/22921], Loss: -17828.1875\n",
      "Epoch [9/10], Step [13900/22921], Loss: -18580.5488\n",
      "Epoch [9/10], Step [14000/22921], Loss: -23051.1680\n",
      "Epoch [9/10], Step [14100/22921], Loss: -16367.0938\n",
      "Epoch [9/10], Step [14200/22921], Loss: -8187.8076\n",
      "Epoch [9/10], Step [14300/22921], Loss: -47662.0859\n",
      "Epoch [9/10], Step [14400/22921], Loss: -34274.3945\n",
      "Epoch [9/10], Step [14500/22921], Loss: -5963.7451\n",
      "Epoch [9/10], Step [14600/22921], Loss: -17154.4336\n",
      "Epoch [9/10], Step [14700/22921], Loss: -23132.5566\n",
      "Epoch [9/10], Step [14800/22921], Loss: -21651.4492\n",
      "Epoch [9/10], Step [14900/22921], Loss: -22409.4473\n",
      "Epoch [9/10], Step [15000/22921], Loss: -29895.0430\n",
      "Epoch [9/10], Step [15100/22921], Loss: -23927.7773\n",
      "Epoch [9/10], Step [15200/22921], Loss: -20947.6172\n",
      "Epoch [9/10], Step [15300/22921], Loss: -25448.6973\n",
      "Epoch [9/10], Step [15400/22921], Loss: -31452.7070\n",
      "Epoch [9/10], Step [15500/22921], Loss: -26222.9102\n",
      "Epoch [9/10], Step [15600/22921], Loss: -34481.4180\n",
      "Epoch [9/10], Step [15700/22921], Loss: -14998.9189\n",
      "Epoch [9/10], Step [15800/22921], Loss: -9754.0684\n",
      "Epoch [9/10], Step [15900/22921], Loss: -30027.1777\n",
      "Epoch [9/10], Step [16000/22921], Loss: -14270.1777\n",
      "Epoch [9/10], Step [16100/22921], Loss: -25549.2695\n",
      "Epoch [9/10], Step [16200/22921], Loss: -20299.4668\n",
      "Epoch [9/10], Step [16300/22921], Loss: -24070.5879\n",
      "Epoch [9/10], Step [16400/22921], Loss: -21071.9590\n",
      "Epoch [9/10], Step [16500/22921], Loss: -6023.6655\n",
      "Epoch [9/10], Step [16600/22921], Loss: -36160.0195\n",
      "Epoch [9/10], Step [16700/22921], Loss: -15827.5000\n",
      "Epoch [9/10], Step [16800/22921], Loss: -33178.2109\n",
      "Epoch [9/10], Step [16900/22921], Loss: -33948.4766\n",
      "Epoch [9/10], Step [17000/22921], Loss: -24153.1562\n",
      "Epoch [9/10], Step [17100/22921], Loss: -29450.9062\n",
      "Epoch [9/10], Step [17200/22921], Loss: -21910.7969\n",
      "Epoch [9/10], Step [17300/22921], Loss: -21921.1387\n",
      "Epoch [9/10], Step [17400/22921], Loss: -21931.6758\n",
      "Epoch [9/10], Step [17500/22921], Loss: -24969.1602\n",
      "Epoch [9/10], Step [17600/22921], Loss: -37093.8984\n",
      "Epoch [9/10], Step [17700/22921], Loss: -28023.9121\n",
      "Epoch [9/10], Step [17800/22921], Loss: -41678.6172\n",
      "Epoch [9/10], Step [17900/22921], Loss: -8339.8027\n",
      "Epoch [9/10], Step [18000/22921], Loss: -18963.4883\n",
      "Epoch [9/10], Step [18100/22921], Loss: -34909.6602\n",
      "Epoch [9/10], Step [18200/22921], Loss: -23538.0332\n",
      "Epoch [9/10], Step [18300/22921], Loss: -16712.9395\n",
      "Epoch [9/10], Step [18400/22921], Loss: -17481.0820\n",
      "Epoch [9/10], Step [18500/22921], Loss: -25094.0625\n",
      "Epoch [9/10], Step [18600/22921], Loss: -31953.7852\n",
      "Epoch [9/10], Step [18700/22921], Loss: -24357.3359\n",
      "Epoch [9/10], Step [18800/22921], Loss: -27416.1133\n",
      "Epoch [9/10], Step [18900/22921], Loss: -22096.1406\n",
      "Epoch [9/10], Step [19000/22921], Loss: -25155.7793\n",
      "Epoch [9/10], Step [19100/22921], Loss: -25930.9102\n",
      "Epoch [9/10], Step [19200/22921], Loss: -37389.8125\n",
      "Epoch [9/10], Step [19300/22921], Loss: -25193.2344\n",
      "Epoch [9/10], Step [19400/22921], Loss: -45064.0000\n",
      "Epoch [9/10], Step [19500/22921], Loss: -20632.8359\n",
      "Epoch [9/10], Step [19600/22921], Loss: -29053.6406\n",
      "Epoch [9/10], Step [19700/22921], Loss: -32892.2578\n",
      "Epoch [9/10], Step [19800/22921], Loss: -28316.3223\n",
      "Epoch [9/10], Step [19900/22921], Loss: -21438.5508\n",
      "Epoch [9/10], Step [20000/22921], Loss: -48259.8828\n",
      "Epoch [9/10], Step [20100/22921], Loss: -25291.6680\n",
      "Epoch [9/10], Step [20200/22921], Loss: -26071.3770\n",
      "Epoch [9/10], Step [20300/22921], Loss: -32989.5117\n",
      "Epoch [9/10], Step [20400/22921], Loss: -6140.5840\n",
      "Epoch [9/10], Step [20500/22921], Loss: -27645.2617\n",
      "Epoch [9/10], Step [20600/22921], Loss: -29963.5000\n",
      "Epoch [9/10], Step [20700/22921], Loss: -24597.8398\n",
      "Epoch [9/10], Step [20800/22921], Loss: -23840.2930\n",
      "Epoch [9/10], Step [20900/22921], Loss: -28468.3223\n",
      "Epoch [9/10], Step [21000/22921], Loss: -5388.6772\n",
      "Epoch [9/10], Step [21100/22921], Loss: -25415.8242\n",
      "Epoch [9/10], Step [21200/22921], Loss: -32362.8398\n",
      "Epoch [9/10], Step [21300/22921], Loss: -34691.3867\n",
      "Epoch [9/10], Step [21400/22921], Loss: -30080.6465\n",
      "Epoch [9/10], Step [21500/22921], Loss: -4629.9932\n",
      "Epoch [9/10], Step [21600/22921], Loss: -37830.3242\n",
      "Epoch [9/10], Step [21700/22921], Loss: -26262.9023\n",
      "Epoch [9/10], Step [21800/22921], Loss: -22411.3418\n",
      "Epoch [9/10], Step [21900/22921], Loss: -30927.3711\n",
      "Epoch [9/10], Step [22000/22921], Loss: -38677.0859\n",
      "Epoch [9/10], Step [22100/22921], Loss: -18573.4590\n",
      "Epoch [9/10], Step [22200/22921], Loss: -10839.9629\n",
      "Epoch [9/10], Step [22300/22921], Loss: -28662.9492\n",
      "Epoch [9/10], Step [22400/22921], Loss: -30227.4531\n",
      "Epoch [9/10], Step [22500/22921], Loss: -34896.1523\n",
      "Epoch [9/10], Step [22600/22921], Loss: -40344.5273\n",
      "Epoch [9/10], Step [22700/22921], Loss: -27167.7070\n",
      "Epoch [9/10], Step [22800/22921], Loss: -6212.7075\n",
      "Epoch [9/10], Step [22900/22921], Loss: -12431.2734\n",
      "Epoch [9/10], Training Accuracy: 0.4014\n",
      "Epoch [10/10], Step [100/22921], Loss: -27986.6367\n",
      "Epoch [10/10], Step [200/22921], Loss: -27222.2559\n",
      "Epoch [10/10], Step [300/22921], Loss: -23344.2266\n",
      "Epoch [10/10], Step [400/22921], Loss: -25691.3125\n",
      "Epoch [10/10], Step [500/22921], Loss: -17914.7852\n",
      "Epoch [10/10], Step [600/22921], Loss: -30391.7930\n",
      "Epoch [10/10], Step [700/22921], Loss: -40542.8750\n",
      "Epoch [10/10], Step [800/22921], Loss: -28081.9941\n",
      "Epoch [10/10], Step [900/22921], Loss: -17169.7422\n",
      "Epoch [10/10], Step [1000/22921], Loss: -24985.8711\n",
      "Epoch [10/10], Step [1100/22921], Loss: -19529.6621\n",
      "Epoch [10/10], Step [1200/22921], Loss: -35169.9219\n",
      "Epoch [10/10], Step [1300/22921], Loss: -22676.1309\n",
      "Epoch [10/10], Step [1400/22921], Loss: -32074.5566\n",
      "Epoch [10/10], Step [1500/22921], Loss: -17219.0898\n",
      "Epoch [10/10], Step [1600/22921], Loss: -20359.5664\n",
      "Epoch [10/10], Step [1700/22921], Loss: -10967.9678\n",
      "Epoch [10/10], Step [1800/22921], Loss: -34487.4922\n",
      "Epoch [10/10], Step [1900/22921], Loss: -35288.4492\n",
      "Epoch [10/10], Step [2000/22921], Loss: -30598.4336\n",
      "Epoch [10/10], Step [2100/22921], Loss: -44742.1016\n",
      "Epoch [10/10], Step [2200/22921], Loss: -16491.1758\n",
      "Epoch [10/10], Step [2300/22921], Loss: -23570.1719\n",
      "Epoch [10/10], Step [2400/22921], Loss: -18864.9961\n",
      "Epoch [10/10], Step [2500/22921], Loss: -11009.7549\n",
      "Epoch [10/10], Step [2600/22921], Loss: -15735.4404\n",
      "Epoch [10/10], Step [2700/22921], Loss: -30698.4941\n",
      "Epoch [10/10], Step [2800/22921], Loss: -25200.3535\n",
      "Epoch [10/10], Step [2900/22921], Loss: -26787.8242\n",
      "Epoch [10/10], Step [3000/22921], Loss: -36259.2734\n",
      "Epoch [10/10], Step [3100/22921], Loss: -23659.4727\n",
      "Epoch [10/10], Step [3200/22921], Loss: -29983.7871\n",
      "Epoch [10/10], Step [3300/22921], Loss: -31576.8633\n",
      "Epoch [10/10], Step [3400/22921], Loss: -24484.4805\n",
      "Epoch [10/10], Step [3500/22921], Loss: -18174.2695\n",
      "Epoch [10/10], Step [3600/22921], Loss: -24506.7422\n",
      "Epoch [10/10], Step [3700/22921], Loss: -44292.1562\n",
      "Epoch [10/10], Step [3800/22921], Loss: -10286.8779\n",
      "Epoch [10/10], Step [3900/22921], Loss: -28500.0098\n",
      "Epoch [10/10], Step [4000/22921], Loss: -13464.3730\n",
      "Epoch [10/10], Step [4100/22921], Loss: -25356.1562\n",
      "Epoch [10/10], Step [4200/22921], Loss: -9513.1289\n",
      "Epoch [10/10], Step [4300/22921], Loss: -19828.1367\n",
      "Epoch [10/10], Step [4400/22921], Loss: -24599.1309\n",
      "Epoch [10/10], Step [4500/22921], Loss: -41283.6484\n",
      "Epoch [10/10], Step [4600/22921], Loss: -16680.7070\n",
      "Epoch [10/10], Step [4700/22921], Loss: -17483.3730\n",
      "Epoch [10/10], Step [4800/22921], Loss: -16696.4336\n",
      "Epoch [10/10], Step [4900/22921], Loss: -27839.5098\n",
      "Epoch [10/10], Step [5000/22921], Loss: -26260.9844\n",
      "Epoch [10/10], Step [5100/22921], Loss: -9553.9551\n",
      "Epoch [10/10], Step [5200/22921], Loss: -37437.7891\n",
      "Epoch [10/10], Step [5300/22921], Loss: -31876.9375\n",
      "Epoch [10/10], Step [5400/22921], Loss: -28702.2402\n",
      "Epoch [10/10], Step [5500/22921], Loss: -31906.3594\n",
      "Epoch [10/10], Step [5600/22921], Loss: -39103.4727\n",
      "Epoch [10/10], Step [5700/22921], Loss: -27944.6465\n",
      "Epoch [10/10], Step [5800/22921], Loss: -39939.4648\n",
      "Epoch [10/10], Step [5900/22921], Loss: -26372.7617\n",
      "Epoch [10/10], Step [6000/22921], Loss: -30383.0938\n",
      "Epoch [10/10], Step [6100/22921], Loss: -50395.7344\n",
      "Epoch [10/10], Step [6200/22921], Loss: -24810.0703\n",
      "Epoch [10/10], Step [6300/22921], Loss: -27224.2500\n",
      "Epoch [10/10], Step [6400/22921], Loss: -28037.3164\n",
      "Epoch [10/10], Step [6500/22921], Loss: -15227.1738\n",
      "Epoch [10/10], Step [6600/22921], Loss: -5612.7432\n",
      "Epoch [10/10], Step [6700/22921], Loss: -16845.6777\n",
      "Epoch [10/10], Step [6800/22921], Loss: -32904.9492\n",
      "Epoch [10/10], Step [6900/22921], Loss: -35330.1914\n",
      "Epoch [10/10], Step [7000/22921], Loss: -15263.3418\n",
      "Epoch [10/10], Step [7100/22921], Loss: -20895.9688\n",
      "Epoch [10/10], Step [7200/22921], Loss: -24926.3809\n",
      "Epoch [10/10], Step [7300/22921], Loss: -18502.2930\n",
      "Epoch [10/10], Step [7400/22921], Loss: -19315.8359\n",
      "Epoch [10/10], Step [7500/22921], Loss: -30597.5410\n",
      "Epoch [10/10], Step [7600/22921], Loss: -31417.0820\n",
      "Epoch [10/10], Step [7700/22921], Loss: -29819.6094\n",
      "Epoch [10/10], Step [7800/22921], Loss: -23383.0293\n",
      "Epoch [10/10], Step [7900/22921], Loss: -32267.7246\n",
      "Epoch [10/10], Step [8000/22921], Loss: -20177.0723\n",
      "Epoch [10/10], Step [8100/22921], Loss: -21801.6699\n",
      "Epoch [10/10], Step [8200/22921], Loss: -20195.8145\n",
      "Epoch [10/10], Step [8300/22921], Loss: -18588.6250\n",
      "Epoch [10/10], Step [8400/22921], Loss: -22640.0723\n",
      "Epoch [10/10], Step [8500/22921], Loss: -33976.3984\n",
      "Epoch [10/10], Step [8600/22921], Loss: -22661.9512\n",
      "Epoch [10/10], Step [8700/22921], Loss: -23482.1504\n",
      "Epoch [10/10], Step [8800/22921], Loss: -25113.5664\n",
      "Epoch [10/10], Step [8900/22921], Loss: -21073.3965\n",
      "Epoch [10/10], Step [9000/22921], Loss: -33246.9844\n",
      "Epoch [10/10], Step [9100/22921], Loss: -17847.9238\n",
      "Epoch [10/10], Step [9200/22921], Loss: -9739.6279\n",
      "Epoch [10/10], Step [9300/22921], Loss: -30044.5000\n",
      "Epoch [10/10], Step [9400/22921], Loss: -46305.8359\n",
      "Epoch [10/10], Step [9500/22921], Loss: -19505.8594\n",
      "Epoch [10/10], Step [9600/22921], Loss: -22766.7012\n",
      "Epoch [10/10], Step [9700/22921], Loss: -37419.9180\n",
      "Epoch [10/10], Step [9800/22921], Loss: -28485.5586\n",
      "Epoch [10/10], Step [9900/22921], Loss: -20356.2656\n",
      "Epoch [10/10], Step [10000/22921], Loss: -31770.5820\n",
      "Epoch [10/10], Step [10100/22921], Loss: -13854.7441\n",
      "Epoch [10/10], Step [10200/22921], Loss: -30167.7129\n",
      "Epoch [10/10], Step [10300/22921], Loss: -26918.6055\n",
      "Epoch [10/10], Step [10400/22921], Loss: -22850.9297\n",
      "Epoch [10/10], Step [10500/22921], Loss: -25310.7754\n",
      "Epoch [10/10], Step [10600/22921], Loss: -44110.3984\n",
      "Epoch [10/10], Step [10700/22921], Loss: -16344.6221\n",
      "Epoch [10/10], Step [10800/22921], Loss: -26163.2656\n",
      "Epoch [10/10], Step [10900/22921], Loss: -23720.8301\n",
      "Epoch [10/10], Step [11000/22921], Loss: -11456.7461\n",
      "Epoch [10/10], Step [11100/22921], Loss: -35204.0195\n",
      "Epoch [10/10], Step [11200/22921], Loss: -33581.7812\n",
      "Epoch [10/10], Step [11300/22921], Loss: -7375.0635\n",
      "Epoch [10/10], Step [11400/22921], Loss: -7378.5234\n",
      "Epoch [10/10], Step [11500/22921], Loss: -18864.9883\n",
      "Epoch [10/10], Step [11600/22921], Loss: -18874.0312\n",
      "Epoch [10/10], Step [11700/22921], Loss: -19703.8477\n",
      "Epoch [10/10], Step [11800/22921], Loss: -16427.4648\n",
      "Epoch [10/10], Step [11900/22921], Loss: -18900.8965\n",
      "Epoch [10/10], Step [12000/22921], Loss: -31241.5684\n",
      "Epoch [10/10], Step [12100/22921], Loss: -23030.5352\n",
      "Epoch [10/10], Step [12200/22921], Loss: -30447.5117\n",
      "Epoch [10/10], Step [12300/22921], Loss: -42810.0391\n",
      "Epoch [10/10], Step [12400/22921], Loss: -8236.5332\n",
      "Epoch [10/10], Step [12500/22921], Loss: -22248.5117\n",
      "Epoch [10/10], Step [12600/22921], Loss: -24731.4609\n",
      "Epoch [10/10], Step [12700/22921], Loss: -33815.0898\n",
      "Epoch [10/10], Step [12800/22921], Loss: -32180.6250\n",
      "Epoch [10/10], Step [12900/22921], Loss: -19812.6543\n",
      "Epoch [10/10], Step [13000/22921], Loss: -41295.2734\n",
      "Epoch [10/10], Step [13100/22921], Loss: -38009.0234\n",
      "Epoch [10/10], Step [13200/22921], Loss: -33065.4141\n",
      "Epoch [10/10], Step [13300/22921], Loss: -25637.1504\n",
      "Epoch [10/10], Step [13400/22921], Loss: -9101.4531\n",
      "Epoch [10/10], Step [13500/22921], Loss: -34767.0625\n",
      "Epoch [10/10], Step [13600/22921], Loss: -6625.2476\n",
      "Epoch [10/10], Step [13700/22921], Loss: -43082.4883\n",
      "Epoch [10/10], Step [13800/22921], Loss: -18235.3398\n",
      "Epoch [10/10], Step [13900/22921], Loss: -24048.2285\n",
      "Epoch [10/10], Step [14000/22921], Loss: -29036.8477\n",
      "Epoch [10/10], Step [14100/22921], Loss: -36520.2734\n",
      "Epoch [10/10], Step [14200/22921], Loss: -20759.5332\n",
      "Epoch [10/10], Step [14300/22921], Loss: -16615.0723\n",
      "Epoch [10/10], Step [14400/22921], Loss: -32413.9492\n",
      "Epoch [10/10], Step [14500/22921], Loss: -16629.9902\n",
      "Epoch [10/10], Step [14600/22921], Loss: -15805.7754\n",
      "Epoch [10/10], Step [14700/22921], Loss: -31625.3633\n",
      "Epoch [10/10], Step [14800/22921], Loss: -36635.2930\n",
      "Epoch [10/10], Step [14900/22921], Loss: -9162.9404\n",
      "Epoch [10/10], Step [15000/22921], Loss: -28334.8555\n",
      "Epoch [10/10], Step [15100/22921], Loss: -22511.5117\n",
      "Epoch [10/10], Step [15200/22921], Loss: -26692.3594\n",
      "Epoch [10/10], Step [15300/22921], Loss: -24200.6953\n",
      "Epoch [10/10], Step [15400/22921], Loss: -24211.3574\n",
      "Epoch [10/10], Step [15500/22921], Loss: -30904.5781\n",
      "Epoch [10/10], Step [15600/22921], Loss: -12534.4453\n",
      "Epoch [10/10], Step [15700/22921], Loss: -25080.7363\n",
      "Epoch [10/10], Step [15800/22921], Loss: -25092.3320\n",
      "Epoch [10/10], Step [15900/22921], Loss: -23430.1680\n",
      "Epoch [10/10], Step [16000/22921], Loss: -29301.2754\n",
      "Epoch [10/10], Step [16100/22921], Loss: -37689.2578\n",
      "Epoch [10/10], Step [16200/22921], Loss: -29326.5195\n",
      "Epoch [10/10], Step [16300/22921], Loss: -25987.3633\n",
      "Epoch [10/10], Step [16400/22921], Loss: -12580.2422\n",
      "Epoch [10/10], Step [16500/22921], Loss: -15103.1348\n",
      "Epoch [10/10], Step [16600/22921], Loss: -41132.6016\n",
      "Epoch [10/10], Step [16700/22921], Loss: -32753.0586\n",
      "Epoch [10/10], Step [16800/22921], Loss: -30246.8184\n",
      "Epoch [10/10], Step [16900/22921], Loss: -36984.8516\n",
      "Epoch [10/10], Step [17000/22921], Loss: -22705.5703\n",
      "Epoch [10/10], Step [17100/22921], Loss: -10096.0918\n",
      "Epoch [10/10], Step [17200/22921], Loss: -35351.3242\n",
      "Epoch [10/10], Step [17300/22921], Loss: -9262.6680\n",
      "Epoch [10/10], Step [17400/22921], Loss: -18533.2207\n",
      "Epoch [10/10], Step [17500/22921], Loss: -27811.9375\n",
      "Epoch [10/10], Step [17600/22921], Loss: -19392.8398\n",
      "Epoch [10/10], Step [17700/22921], Loss: -37115.9688\n",
      "Epoch [10/10], Step [17800/22921], Loss: -37975.1758\n",
      "Epoch [10/10], Step [17900/22921], Loss: -25328.6875\n",
      "Epoch [10/10], Step [18000/22921], Loss: -16893.3398\n",
      "Epoch [10/10], Step [18100/22921], Loss: -14365.4268\n",
      "Epoch [10/10], Step [18200/22921], Loss: -6763.1548\n",
      "Epoch [10/10], Step [18300/22921], Loss: -43979.4336\n",
      "Epoch [10/10], Step [18400/22921], Loss: -24537.5098\n",
      "Epoch [10/10], Step [18500/22921], Loss: -44017.2734\n",
      "Epoch [10/10], Step [18600/22921], Loss: -10162.3301\n",
      "Epoch [10/10], Step [18700/22921], Loss: -32195.4375\n",
      "Epoch [10/10], Step [18800/22921], Loss: -15257.1904\n",
      "Epoch [10/10], Step [18900/22921], Loss: -16959.9883\n",
      "Epoch [10/10], Step [19000/22921], Loss: -27148.1094\n",
      "Epoch [10/10], Step [19100/22921], Loss: -32252.7246\n",
      "Epoch [10/10], Step [19200/22921], Loss: -33964.5742\n",
      "Epoch [10/10], Step [19300/22921], Loss: -27183.6191\n",
      "Epoch [10/10], Step [19400/22921], Loss: -34844.2812\n",
      "Epoch [10/10], Step [19500/22921], Loss: -20405.8496\n",
      "Epoch [10/10], Step [19600/22921], Loss: -51887.6055\n",
      "Epoch [10/10], Step [19700/22921], Loss: -33189.4297\n",
      "Epoch [10/10], Step [19800/22921], Loss: -20433.8438\n",
      "Epoch [10/10], Step [19900/22921], Loss: -15332.3809\n",
      "Epoch [10/10], Step [20000/22921], Loss: -17895.4277\n",
      "Epoch [10/10], Step [20100/22921], Loss: -17050.5234\n",
      "Epoch [10/10], Step [20200/22921], Loss: -35821.8906\n",
      "Epoch [10/10], Step [20300/22921], Loss: -22185.2383\n",
      "Epoch [10/10], Step [20400/22921], Loss: -11097.4951\n",
      "Epoch [10/10], Step [20500/22921], Loss: -23058.7305\n",
      "Epoch [10/10], Step [20600/22921], Loss: -27341.0059\n",
      "Epoch [10/10], Step [20700/22921], Loss: -41883.9766\n",
      "Epoch [10/10], Step [20800/22921], Loss: -35061.3008\n",
      "Epoch [10/10], Step [20900/22921], Loss: -19677.6152\n",
      "Epoch [10/10], Step [21000/22921], Loss: -14550.6143\n",
      "Epoch [10/10], Step [21100/22921], Loss: -7706.5498\n",
      "Epoch [10/10], Step [21200/22921], Loss: -23130.2695\n",
      "Epoch [10/10], Step [21300/22921], Loss: -32568.2148\n",
      "Epoch [10/10], Step [21400/22921], Loss: -13718.5889\n",
      "Epoch [10/10], Step [21500/22921], Loss: -18013.5312\n",
      "Epoch [10/10], Step [21600/22921], Loss: -21453.9531\n",
      "Epoch [10/10], Step [21700/22921], Loss: -35200.2773\n",
      "Epoch [10/10], Step [21800/22921], Loss: -13742.4404\n",
      "Epoch [10/10], Step [21900/22921], Loss: -36089.1602\n",
      "Epoch [10/10], Step [22000/22921], Loss: -24070.3926\n",
      "Epoch [10/10], Step [22100/22921], Loss: -36981.8672\n",
      "Epoch [10/10], Step [22200/22921], Loss: -13766.9639\n",
      "Epoch [10/10], Step [22300/22921], Loss: -20659.1738\n",
      "Epoch [10/10], Step [22400/22921], Loss: -25835.2500\n",
      "Epoch [10/10], Step [22500/22921], Loss: -8615.4834\n",
      "Epoch [10/10], Step [22600/22921], Loss: -38786.2969\n",
      "Epoch [10/10], Step [22700/22921], Loss: -32766.7695\n",
      "Epoch [10/10], Step [22800/22921], Loss: -22429.0195\n",
      "Epoch [10/10], Step [22900/22921], Loss: -37110.1680\n",
      "Epoch [10/10], Training Accuracy: 0.4014\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(text_model.parameters(), lr=0.01)\n",
    "num_correct = 0\n",
    "num_total = 0\n",
    "input_size = 10\n",
    "\n",
    "for textdata, labeldata in trainloader:\n",
    "    labeldata = labeldata.float()\n",
    "    m2 = text_model(textofsentiment)\n",
    "    output = text_model(textofsentiment)\n",
    "    predicted = torch.round(output)\n",
    "    for i in predicted:\n",
    "        y = i + 2\n",
    "        print(i)\n",
    "    num_correct += (predicted == labeldata.unsqueeze(1)).sum().item()\n",
    "    num_total += labeldata.size(0)\n",
    "\n",
    "accuracy = num_correct / num_total\n",
    "print(f\"Test accuracy: {accuracy/100:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
